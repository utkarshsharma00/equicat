{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel, VarianceThreshold\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from time import time\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded embeddings for 507 entities\n",
      "Sample keys from embeddings: ['100_vi', '102_i', '102_vi', '103_vi', '104_vi', '105_i', '105_vi', '106_i', '106_vi', '107_i', '108_i', '108_vi', '109_i', '109_vi', '10_vi', '110_i', '110_vi', '111_vi', '112_i', '112_vi', '114_i', '114_vi', '115_i', '115_vi', '116_i', '117_i', '117_vi', '118_vi', '119_i', '119_vi', '11_i', '11_vi', '120_i', '121_i', '122_vi', '123_i', '123_vi', '124_vi', '125_i', '125_vi', '127_vi', '128_vi', '129_i', '129_vi', '12_i', '130_i', '130_vi', '132_i', '133_vi', '134_vi', '135_i', '136_vi', '137_i', '137_vi', '139_i', '139_vi', '13_vi', '140_i', '141_i', '142_i', '142_vi', '143_i', '143_vi', '144_i', '146_i', '147_i', '148_i', '14_i', '150_i', '150_vi', '152_vi', '153_i', '153_vi', '154_i', '155_i', '155_vi', '156_i', '157_i', '157_vi', '158_i', '159_i', '159_vi', '15_i', '15_vi', '160_vi', '163_vi', '164_i', '164_vi', '165_i', '165_vi', '166_i', '166_vi', '167_i', '167_vi', '168_i', '168_vi', '169_i', '16_i', '16_vi', '170_vi', '171_vi', '173_i', '173_vi', '174_i', '175_vi', '176_i', '177_i', '17_vi', '181_vi', '182_vi', '185_i', '185_vi', '186_vi', '188_i', '189_i', '189_vi', '18_i', '18_vi', '190_i', '190_vi', '191_i', '191_vi', '192_vi', '193_i', '194_i', '194_vi', '195_i', '195_vi', '197_vi', '198_vi', '199_vi', '19_i', '1_i', '200_i', '201_i', '202_i', '202_vi', '203_i', '205_i', '205_vi', '206_i', '207_vi', '208_i', '208_vi', '209_vi', '20_vi', '210_i', '211_i', '211_vi', '212_i', '212_vi', '213_i', '214_i', '214_vi', '215_i', '215_vi', '216_i', '216_vi', '217_i', '217_vi', '218_vi', '219_vi', '21_i', '220_i', '221_i', '221_vi', '222_i', '222_vi', '223_i', '223_vi', '224_i', '225_i', '225_vi', '226_i', '226_vi', '227_i', '22_i', '22_vi', '230_i', '230_vi', '231_i', '231_vi', '232_i', '232_vi', '233_i', '233_vi', '234_i', '234_vi', '235_vi', '236_i', '238_vi', '239_i', '239_vi', '240_i', '242_vi', '243_vi', '244_i', '245_i', '245_vi', '247_i', '247_vi', '248_vi', '249_i', '249_vi', '24_i', '24_vi', '250_i', '253_i', '253_vi', '254_i', '254_vi', '255_i', '256_i', '257_vi', '258_i', '259_i', '25_i', '25_vi', '260_vi', '261_i', '262_i', '262_vi', '263_i', '264_i', '264_vi', '265_i', '266_vi', '267_vi', '268_vi', '269_i', '26_i', '271_vi', '272_i', '272_vi', '273_vi', '274_i', '276_i', '276_vi', '277_i', '277_vi', '278_i', '278_vi', '279_i', '279_vi', '27_i', '27_vi', '280_i', '280_vi', '281_i', '282_i', '282_vi', '283_vi', '284_i', '284_vi', '285_i', '285_vi', '286_i', '288_vi', '289_i', '289_vi', '28_vi', '290_i', '291_i', '291_vi', '292_i', '292_vi', '293_vi', '294_vi', '296_i', '296_vi', '297_vi', '298_i', '298_vi', '299_i', '299_vi', '29_i', '29_vi', '300_vi', '302_i', '303_i', '304_i', '306_i', '307_i', '307_vi', '308_i', '308_vi', '309_i', '30_vi', '310_i', '310_vi', '311_i', '312_vi', '313_i', '313_vi', '314_i', '314_vi', '315_i', '315_vi', '316_vi', '317_i', '317_vi', '318_i', '318_vi', '319_vi', '31_i', '320_i', '321_i', '321_vi', '322_i', '322_vi', '323_vi', '324_i', '326_i', '326_vi', '327_i', '328_i', '329_i', '329_vi', '32_i', '32_vi', '330_i', '331_i', '331_vi', '333_i', '333_vi', '335_vi', '337_i', '337_vi', '338_i', '339_vi', '340_i', '340_vi', '341_i', '341_vi', '342_i', '343_i', '343_vi', '344_i', '344_vi', '346_vi', '347_i', '348_i', '348_vi', '349_i', '349_vi', '34_i', '351_i', '351_vi', '354_i', '354_vi', '355_i', '355_vi', '356_i', '358_i', '358_vi', '359_i', '35_i', '35_vi', '360_i', '360_vi', '362_i', '362_vi', '363_i', '364_i', '365_i', '365_vi', '366_vi', '367_i', '367_vi', '369_i', '369_vi', '36_i', '370_vi', '371_i', '371_vi', '372_i', '372_vi', '373_i', '373_vi', '374_vi', '375_i', '375_vi', '376_i', '376_vi', '378_i', '379_i', '379_vi', '381_i', '382_i', '383_i', '384_i', '384_vi', '385_vi', '386_i', '386_vi', '387_vi', '389_vi', '390_i', '390_vi', '391_i', '391_vi', '392_vi', '393_i', '393_vi', '395_i', '395_vi', '396_i', '396_vi', '397_vi', '398_vi', '399_i', '399_vi', '39_i', '3_vi', '400_vi', '401_i', '401_vi', '402_i', '402_vi', '403_i', '404_i', '404_vi', '405_vi', '406_i', '406_vi', '407_vi', '408_i', '408_vi', '409_vi', '40_vi', '410_i', '410_vi', '41_i', '41_vi', '42_i', '42_vi', '43_i', '45_i', '46_i', '47_i', '47_vi', '48_i', '49_i', '4_vi', '50_i', '50_vi', '51_i', '52_vi', '53_i', '54_vi', '55_i', '56_i', '57_vi', '58_vi', '59_vi', '5_i', '5_vi', '61_i', '62_i', '64_i', '64_vi', '66_vi', '68_i', '69_vi', '6_vi', '70_i', '70_vi', '71_i', '71_vi', '72_i', '72_vi', '73_vi', '74_i', '75_vi', '76_vi', '77_i', '77_vi', '78_vi', '7_i', '80_i', '81_i', '82_vi', '83_i', '84_i', '85_i', '85_vi', '86_i', '86_vi', '87_vi', '88_vi', '89_vi', '8_i', '8_vi', '90_i', '90_vi', '91_vi', '92_i', '92_vi', '93_i', '94_i', '95_vi', '96_i', '96_vi', '97_vi', '98_i', '98_vi', '9_i']\n",
      "Loaded Y data with 1075 rows\n",
      "Sample rows from Y_df:\n",
      "  reaction_handle catalyst_id imine_id thiol_id product_id  \\\n",
      "0         1_i_1_A         1_i        1        A        1_A   \n",
      "1         1_i_1_B         1_i        1        B        1_B   \n",
      "2         1_i_1_C         1_i        1        C        1_C   \n",
      "3         1_i_1_D         1_i        1        D        1_D   \n",
      "4         1_i_1_E         1_i        1        E        1_E   \n",
      "\n",
      "   selectivity_ee_percent  selectivity_ddGact_kcal  \n",
      "0                      76                 1.180364  \n",
      "1                      40                 0.501960  \n",
      "2                      50                 0.650844  \n",
      "3                      78                 1.238605  \n",
      "4                      80                 1.301689  \n",
      "Number of missing IDs: 49\n",
      "Sample of missing IDs: ['E', '1_A', 'C', '5_D', '286_vi', '242_i', '3_A', '5_A', '2_D', '2_B']\n",
      "All embeddings have consistent size: (192,)\n",
      "\n",
      "Summary:\n",
      "Total embeddings loaded: 507\n",
      "Total rows in Y_df: 1075\n",
      "Total missing IDs: 49\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Function to load embeddings from HDF5 file\n",
    "def load_embeddings(file_path):\n",
    "    embeddings = {}\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        for key in f.keys():\n",
    "            embeddings[key] = np.array(f[key])\n",
    "    return embeddings\n",
    "\n",
    "# Load embeddings\n",
    "try:\n",
    "    embeddings = load_embeddings('/Users/utkarsh/MMLI/equicat/develop_op/final_embeddings/embeddings.h5')\n",
    "    print(f\"Loaded embeddings for {len(embeddings)} entities\")\n",
    "    print(\"Sample keys from embeddings:\", list(embeddings.keys()))\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'embeddings.h5' file not found. Please ensure it's in the correct directory.\")\n",
    "    embeddings = {}\n",
    "except Exception as e:\n",
    "    print(f\"Error loading embeddings: {str(e)}\")\n",
    "    embeddings = {}\n",
    "\n",
    "# Load Y data\n",
    "try:\n",
    "    Y_df = pd.read_csv('/Users/utkarsh/MMLI/equicat/science/Y_DATA.csv', dtype={\n",
    "        'catalyst_id': str,\n",
    "        'imine_id': str,\n",
    "        'thiol_id': str,\n",
    "        'product_id': str\n",
    "    })\n",
    "    print(f\"Loaded Y data with {len(Y_df)} rows\")\n",
    "    print(\"Sample rows from Y_df:\")\n",
    "    print(Y_df.head())\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'Y_DATA.csv' file not found. Please ensure it's in the correct directory.\")\n",
    "    Y_df = pd.DataFrame()\n",
    "\n",
    "# Check for missing IDs\n",
    "missing_ids = set()\n",
    "for _, row in Y_df.iterrows():\n",
    "    for id_type in ['catalyst_id', 'imine_id', 'thiol_id', 'product_id']:\n",
    "        if row[id_type] not in embeddings:\n",
    "            missing_ids.add(row[id_type])\n",
    "\n",
    "print(f\"Number of missing IDs: {len(missing_ids)}\")\n",
    "print(\"Sample of missing IDs:\", list(missing_ids)[:10] if missing_ids else \"None\")\n",
    "\n",
    "# Additional checks\n",
    "if embeddings:\n",
    "    # Check for consistency in embedding dimensions\n",
    "    embedding_sizes = set(emb.shape for emb in embeddings.values())\n",
    "    if len(embedding_sizes) > 1:\n",
    "        print(\"Warning: Inconsistent embedding sizes detected.\")\n",
    "        print(\"Unique embedding sizes:\", embedding_sizes)\n",
    "    else:\n",
    "        print(f\"All embeddings have consistent size: {next(iter(embedding_sizes))}\")\n",
    "\n",
    "    # Check for any potential data issues\n",
    "    nan_keys = [key for key, emb in embeddings.items() if np.isnan(emb).any()]\n",
    "    inf_keys = [key for key, emb in embeddings.items() if np.isinf(emb).any()]\n",
    "    \n",
    "    if nan_keys:\n",
    "        print(f\"Warning: NaN values found in embeddings for keys: {nan_keys[:10]}\")\n",
    "    if inf_keys:\n",
    "        print(f\"Warning: Inf values found in embeddings for keys: {inf_keys[:10]}\")\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nSummary:\")\n",
    "print(f\"Total embeddings loaded: {len(embeddings)}\")\n",
    "print(f\"Total rows in Y_df: {len(Y_df)}\")\n",
    "print(f\"Total missing IDs: {len(missing_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing embedding for reaction: 181_i_1_A - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_1_B - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_1_C - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_1_D - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_1_E - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_2_A - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_2_B - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_2_C - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_2_D - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_2_E - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_3_A - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_3_B - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_3_C - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_3_D - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_3_E - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_4_A - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_4_B - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_4_C - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_4_D - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_4_E - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_5_A - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_5_B - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_5_C - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_5_D - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_5_E - Missing IDs: ['181_i']\n",
      "Created dataset with 1050 samples and 768 features\n",
      "Sample rows from X_df:\n",
      "        0        1         2         3         4         5         6    \\\n",
      "0  0.211279 -0.23665 -0.074142 -0.169454  0.350294  0.026651 -0.224017   \n",
      "1  0.211279 -0.23665 -0.074142 -0.169454  0.350294  0.026651 -0.224017   \n",
      "2  0.211279 -0.23665 -0.074142 -0.169454  0.350294  0.026651 -0.224017   \n",
      "3  0.211279 -0.23665 -0.074142 -0.169454  0.350294  0.026651 -0.224017   \n",
      "4  0.211279 -0.23665 -0.074142 -0.169454  0.350294  0.026651 -0.224017   \n",
      "\n",
      "        7         8        9         10        11        12        13   \\\n",
      "0  0.100611 -0.605542 -0.22891 -0.046255 -0.172672  0.139716 -0.245372   \n",
      "1  0.100611 -0.605542 -0.22891 -0.046255 -0.172672  0.139716 -0.245372   \n",
      "2  0.100611 -0.605542 -0.22891 -0.046255 -0.172672  0.139716 -0.245372   \n",
      "3  0.100611 -0.605542 -0.22891 -0.046255 -0.172672  0.139716 -0.245372   \n",
      "4  0.100611 -0.605542 -0.22891 -0.046255 -0.172672  0.139716 -0.245372   \n",
      "\n",
      "        14        15        16        17        18        19        20   \\\n",
      "0 -0.316654  0.327997  0.277749 -0.161315  0.215904 -0.219207  0.242625   \n",
      "1 -0.316654  0.327997  0.277749 -0.161315  0.215904 -0.219207  0.242625   \n",
      "2 -0.316654  0.327997  0.277749 -0.161315  0.215904 -0.219207  0.242625   \n",
      "3 -0.316654  0.327997  0.277749 -0.161315  0.215904 -0.219207  0.242625   \n",
      "4 -0.316654  0.327997  0.277749 -0.161315  0.215904 -0.219207  0.242625   \n",
      "\n",
      "        21        22        23        24        25        26        27   \\\n",
      "0  0.291695  0.094724  0.126358 -0.277162 -0.447778 -0.176678 -0.165707   \n",
      "1  0.291695  0.094724  0.126358 -0.277162 -0.447778 -0.176678 -0.165707   \n",
      "2  0.291695  0.094724  0.126358 -0.277162 -0.447778 -0.176678 -0.165707   \n",
      "3  0.291695  0.094724  0.126358 -0.277162 -0.447778 -0.176678 -0.165707   \n",
      "4  0.291695  0.094724  0.126358 -0.277162 -0.447778 -0.176678 -0.165707   \n",
      "\n",
      "       28        29        30       31        32        33        34   \\\n",
      "0 -0.24948 -0.582123  0.066055  0.05184 -0.013013 -0.246496 -0.483415   \n",
      "1 -0.24948 -0.582123  0.066055  0.05184 -0.013013 -0.246496 -0.483415   \n",
      "2 -0.24948 -0.582123  0.066055  0.05184 -0.013013 -0.246496 -0.483415   \n",
      "3 -0.24948 -0.582123  0.066055  0.05184 -0.013013 -0.246496 -0.483415   \n",
      "4 -0.24948 -0.582123  0.066055  0.05184 -0.013013 -0.246496 -0.483415   \n",
      "\n",
      "        35        36        37        38        39        40        41   \\\n",
      "0 -0.042834 -0.283944 -0.170659 -0.041228 -0.114332 -0.007776 -0.142174   \n",
      "1 -0.042834 -0.283944 -0.170659 -0.041228 -0.114332 -0.007776 -0.142174   \n",
      "2 -0.042834 -0.283944 -0.170659 -0.041228 -0.114332 -0.007776 -0.142174   \n",
      "3 -0.042834 -0.283944 -0.170659 -0.041228 -0.114332 -0.007776 -0.142174   \n",
      "4 -0.042834 -0.283944 -0.170659 -0.041228 -0.114332 -0.007776 -0.142174   \n",
      "\n",
      "        42        43        44        45        46       47        48   \\\n",
      "0  0.195078  0.149042 -0.030283 -0.339144 -0.151966 -0.14576  0.061168   \n",
      "1  0.195078  0.149042 -0.030283 -0.339144 -0.151966 -0.14576  0.061168   \n",
      "2  0.195078  0.149042 -0.030283 -0.339144 -0.151966 -0.14576  0.061168   \n",
      "3  0.195078  0.149042 -0.030283 -0.339144 -0.151966 -0.14576  0.061168   \n",
      "4  0.195078  0.149042 -0.030283 -0.339144 -0.151966 -0.14576  0.061168   \n",
      "\n",
      "        49        50        51        52       53        54        55   \\\n",
      "0  0.211681 -0.374592  0.225655  0.358378 -0.09571  0.327907  0.278238   \n",
      "1  0.211681 -0.374592  0.225655  0.358378 -0.09571  0.327907  0.278238   \n",
      "2  0.211681 -0.374592  0.225655  0.358378 -0.09571  0.327907  0.278238   \n",
      "3  0.211681 -0.374592  0.225655  0.358378 -0.09571  0.327907  0.278238   \n",
      "4  0.211681 -0.374592  0.225655  0.358378 -0.09571  0.327907  0.278238   \n",
      "\n",
      "        56        57        58        59        60        61        62   \\\n",
      "0  0.130521  0.185962  0.305956 -0.119355 -0.071689 -0.584615  0.212226   \n",
      "1  0.130521  0.185962  0.305956 -0.119355 -0.071689 -0.584615  0.212226   \n",
      "2  0.130521  0.185962  0.305956 -0.119355 -0.071689 -0.584615  0.212226   \n",
      "3  0.130521  0.185962  0.305956 -0.119355 -0.071689 -0.584615  0.212226   \n",
      "4  0.130521  0.185962  0.305956 -0.119355 -0.071689 -0.584615  0.212226   \n",
      "\n",
      "        63        64        65        66        67        68        69   \\\n",
      "0 -0.065521  0.272254  0.347165  0.032485 -0.371425 -0.105579 -0.288092   \n",
      "1 -0.065521  0.272254  0.347165  0.032485 -0.371425 -0.105579 -0.288092   \n",
      "2 -0.065521  0.272254  0.347165  0.032485 -0.371425 -0.105579 -0.288092   \n",
      "3 -0.065521  0.272254  0.347165  0.032485 -0.371425 -0.105579 -0.288092   \n",
      "4 -0.065521  0.272254  0.347165  0.032485 -0.371425 -0.105579 -0.288092   \n",
      "\n",
      "        70        71        72        73        74        75        76   \\\n",
      "0 -0.149737 -0.081189  0.320118 -0.175678  0.424433  0.286039  0.091252   \n",
      "1 -0.149737 -0.081189  0.320118 -0.175678  0.424433  0.286039  0.091252   \n",
      "2 -0.149737 -0.081189  0.320118 -0.175678  0.424433  0.286039  0.091252   \n",
      "3 -0.149737 -0.081189  0.320118 -0.175678  0.424433  0.286039  0.091252   \n",
      "4 -0.149737 -0.081189  0.320118 -0.175678  0.424433  0.286039  0.091252   \n",
      "\n",
      "        77       78       79        80        81        82        83   \\\n",
      "0 -0.008941  0.19753  0.29277  0.294107  0.082921 -0.164047 -0.151789   \n",
      "1 -0.008941  0.19753  0.29277  0.294107  0.082921 -0.164047 -0.151789   \n",
      "2 -0.008941  0.19753  0.29277  0.294107  0.082921 -0.164047 -0.151789   \n",
      "3 -0.008941  0.19753  0.29277  0.294107  0.082921 -0.164047 -0.151789   \n",
      "4 -0.008941  0.19753  0.29277  0.294107  0.082921 -0.164047 -0.151789   \n",
      "\n",
      "        84        85       86        87        88        89        90   \\\n",
      "0  0.077263 -0.219328  0.39118  0.183489  0.009178 -0.075827  0.215539   \n",
      "1  0.077263 -0.219328  0.39118  0.183489  0.009178 -0.075827  0.215539   \n",
      "2  0.077263 -0.219328  0.39118  0.183489  0.009178 -0.075827  0.215539   \n",
      "3  0.077263 -0.219328  0.39118  0.183489  0.009178 -0.075827  0.215539   \n",
      "4  0.077263 -0.219328  0.39118  0.183489  0.009178 -0.075827  0.215539   \n",
      "\n",
      "        91        92       93        94        95        96        97   \\\n",
      "0  0.011955  0.009339  0.12398  0.047192 -0.456377 -0.182192 -0.309106   \n",
      "1  0.011955  0.009339  0.12398  0.047192 -0.456377 -0.182192 -0.309106   \n",
      "2  0.011955  0.009339  0.12398  0.047192 -0.456377 -0.182192 -0.309106   \n",
      "3  0.011955  0.009339  0.12398  0.047192 -0.456377 -0.182192 -0.309106   \n",
      "4  0.011955  0.009339  0.12398  0.047192 -0.456377 -0.182192 -0.309106   \n",
      "\n",
      "        98        99        100       101       102       103       104  \\\n",
      "0 -0.380496 -0.013013 -0.128984 -0.173753  0.465467  0.152981  0.367414   \n",
      "1 -0.380496 -0.013013 -0.128984 -0.173753  0.465467  0.152981  0.367414   \n",
      "2 -0.380496 -0.013013 -0.128984 -0.173753  0.465467  0.152981  0.367414   \n",
      "3 -0.380496 -0.013013 -0.128984 -0.173753  0.465467  0.152981  0.367414   \n",
      "4 -0.380496 -0.013013 -0.128984 -0.173753  0.465467  0.152981  0.367414   \n",
      "\n",
      "        105      106       107       108       109       110       111  \\\n",
      "0 -0.036518 -0.15241 -0.369074 -0.262174  0.126232 -0.233363  0.003406   \n",
      "1 -0.036518 -0.15241 -0.369074 -0.262174  0.126232 -0.233363  0.003406   \n",
      "2 -0.036518 -0.15241 -0.369074 -0.262174  0.126232 -0.233363  0.003406   \n",
      "3 -0.036518 -0.15241 -0.369074 -0.262174  0.126232 -0.233363  0.003406   \n",
      "4 -0.036518 -0.15241 -0.369074 -0.262174  0.126232 -0.233363  0.003406   \n",
      "\n",
      "        112       113       114       115       116       117       118  \\\n",
      "0  0.349067  0.145786 -0.178426 -0.051538  0.163267 -0.249415 -0.274156   \n",
      "1  0.349067  0.145786 -0.178426 -0.051538  0.163267 -0.249415 -0.274156   \n",
      "2  0.349067  0.145786 -0.178426 -0.051538  0.163267 -0.249415 -0.274156   \n",
      "3  0.349067  0.145786 -0.178426 -0.051538  0.163267 -0.249415 -0.274156   \n",
      "4  0.349067  0.145786 -0.178426 -0.051538  0.163267 -0.249415 -0.274156   \n",
      "\n",
      "        119       120       121       122       123       124       125  \\\n",
      "0  0.383404 -0.018145 -0.009083 -0.097193  0.111334  0.542272  0.147978   \n",
      "1  0.383404 -0.018145 -0.009083 -0.097193  0.111334  0.542272  0.147978   \n",
      "2  0.383404 -0.018145 -0.009083 -0.097193  0.111334  0.542272  0.147978   \n",
      "3  0.383404 -0.018145 -0.009083 -0.097193  0.111334  0.542272  0.147978   \n",
      "4  0.383404 -0.018145 -0.009083 -0.097193  0.111334  0.542272  0.147978   \n",
      "\n",
      "        126       127       128       129       130       131       132  \\\n",
      "0  0.489855 -0.616682  0.033556  0.094383 -0.166389 -0.280675 -0.340019   \n",
      "1  0.489855 -0.616682  0.033556  0.094383 -0.166389 -0.280675 -0.340019   \n",
      "2  0.489855 -0.616682  0.033556  0.094383 -0.166389 -0.280675 -0.340019   \n",
      "3  0.489855 -0.616682  0.033556  0.094383 -0.166389 -0.280675 -0.340019   \n",
      "4  0.489855 -0.616682  0.033556  0.094383 -0.166389 -0.280675 -0.340019   \n",
      "\n",
      "        133       134       135       136       137      138       139  \\\n",
      "0 -0.215758 -0.300112 -0.175041 -0.175452 -0.210639  0.22471  0.466572   \n",
      "1 -0.215758 -0.300112 -0.175041 -0.175452 -0.210639  0.22471  0.466572   \n",
      "2 -0.215758 -0.300112 -0.175041 -0.175452 -0.210639  0.22471  0.466572   \n",
      "3 -0.215758 -0.300112 -0.175041 -0.175452 -0.210639  0.22471  0.466572   \n",
      "4 -0.215758 -0.300112 -0.175041 -0.175452 -0.210639  0.22471  0.466572   \n",
      "\n",
      "        140       141       142       143       144       145       146  \\\n",
      "0 -0.378856 -0.018881 -0.166741 -0.003177 -0.078164 -0.366118 -0.316509   \n",
      "1 -0.378856 -0.018881 -0.166741 -0.003177 -0.078164 -0.366118 -0.316509   \n",
      "2 -0.378856 -0.018881 -0.166741 -0.003177 -0.078164 -0.366118 -0.316509   \n",
      "3 -0.378856 -0.018881 -0.166741 -0.003177 -0.078164 -0.366118 -0.316509   \n",
      "4 -0.378856 -0.018881 -0.166741 -0.003177 -0.078164 -0.366118 -0.316509   \n",
      "\n",
      "        147       148       149       150      151       152       153  \\\n",
      "0  0.054376 -0.051194  0.379524 -0.079433  0.29338  0.042283  0.319854   \n",
      "1  0.054376 -0.051194  0.379524 -0.079433  0.29338  0.042283  0.319854   \n",
      "2  0.054376 -0.051194  0.379524 -0.079433  0.29338  0.042283  0.319854   \n",
      "3  0.054376 -0.051194  0.379524 -0.079433  0.29338  0.042283  0.319854   \n",
      "4  0.054376 -0.051194  0.379524 -0.079433  0.29338  0.042283  0.319854   \n",
      "\n",
      "        154       155       156       157      158       159       160  \\\n",
      "0 -0.505457 -0.370027 -0.227914  0.258236 -0.05715  0.442162  0.201137   \n",
      "1 -0.505457 -0.370027 -0.227914  0.258236 -0.05715  0.442162  0.201137   \n",
      "2 -0.505457 -0.370027 -0.227914  0.258236 -0.05715  0.442162  0.201137   \n",
      "3 -0.505457 -0.370027 -0.227914  0.258236 -0.05715  0.442162  0.201137   \n",
      "4 -0.505457 -0.370027 -0.227914  0.258236 -0.05715  0.442162  0.201137   \n",
      "\n",
      "        161       162       163       164       165       166       167  \\\n",
      "0 -0.251974 -0.401058 -0.402539 -0.303716  0.231926 -0.590898  0.344175   \n",
      "1 -0.251974 -0.401058 -0.402539 -0.303716  0.231926 -0.590898  0.344175   \n",
      "2 -0.251974 -0.401058 -0.402539 -0.303716  0.231926 -0.590898  0.344175   \n",
      "3 -0.251974 -0.401058 -0.402539 -0.303716  0.231926 -0.590898  0.344175   \n",
      "4 -0.251974 -0.401058 -0.402539 -0.303716  0.231926 -0.590898  0.344175   \n",
      "\n",
      "        168       169       170       171       172       173       174  \\\n",
      "0  0.235639 -0.296994  0.187987 -0.280386 -0.127269  0.207497  0.383049   \n",
      "1  0.235639 -0.296994  0.187987 -0.280386 -0.127269  0.207497  0.383049   \n",
      "2  0.235639 -0.296994  0.187987 -0.280386 -0.127269  0.207497  0.383049   \n",
      "3  0.235639 -0.296994  0.187987 -0.280386 -0.127269  0.207497  0.383049   \n",
      "4  0.235639 -0.296994  0.187987 -0.280386 -0.127269  0.207497  0.383049   \n",
      "\n",
      "        175       176      177       178       179       180       181  \\\n",
      "0  0.497736 -0.084957  0.12638 -0.362655  0.112393  0.117154  0.255755   \n",
      "1  0.497736 -0.084957  0.12638 -0.362655  0.112393  0.117154  0.255755   \n",
      "2  0.497736 -0.084957  0.12638 -0.362655  0.112393  0.117154  0.255755   \n",
      "3  0.497736 -0.084957  0.12638 -0.362655  0.112393  0.117154  0.255755   \n",
      "4  0.497736 -0.084957  0.12638 -0.362655  0.112393  0.117154  0.255755   \n",
      "\n",
      "        182       183       184       185       186       187       188  \\\n",
      "0 -0.129763 -0.389149  0.131879 -0.581971 -0.285502 -0.128086 -0.297748   \n",
      "1 -0.129763 -0.389149  0.131879 -0.581971 -0.285502 -0.128086 -0.297748   \n",
      "2 -0.129763 -0.389149  0.131879 -0.581971 -0.285502 -0.128086 -0.297748   \n",
      "3 -0.129763 -0.389149  0.131879 -0.581971 -0.285502 -0.128086 -0.297748   \n",
      "4 -0.129763 -0.389149  0.131879 -0.581971 -0.285502 -0.128086 -0.297748   \n",
      "\n",
      "        189       190       191      192       193       194       195  \\\n",
      "0  0.385974  0.250512 -0.046149 -0.48582  0.024365  0.095295 -0.281285   \n",
      "1  0.385974  0.250512 -0.046149 -0.48582  0.024365  0.095295 -0.281285   \n",
      "2  0.385974  0.250512 -0.046149 -0.48582  0.024365  0.095295 -0.281285   \n",
      "3  0.385974  0.250512 -0.046149 -0.48582  0.024365  0.095295 -0.281285   \n",
      "4  0.385974  0.250512 -0.046149 -0.48582  0.024365  0.095295 -0.281285   \n",
      "\n",
      "        196       197       198       199      200       201      202  \\\n",
      "0 -0.191443 -0.026521  0.200363 -0.269945 -0.56968 -0.068861  0.03599   \n",
      "1 -0.191443 -0.026521  0.200363 -0.269945 -0.56968 -0.068861  0.03599   \n",
      "2 -0.191443 -0.026521  0.200363 -0.269945 -0.56968 -0.068861  0.03599   \n",
      "3 -0.191443 -0.026521  0.200363 -0.269945 -0.56968 -0.068861  0.03599   \n",
      "4 -0.191443 -0.026521  0.200363 -0.269945 -0.56968 -0.068861  0.03599   \n",
      "\n",
      "        203       204       205       206       207       208       209  \\\n",
      "0 -0.213725 -0.266383 -0.077986  0.177555  0.165906 -0.233518 -0.218294   \n",
      "1 -0.213725 -0.266383 -0.077986  0.177555  0.165906 -0.233518 -0.218294   \n",
      "2 -0.213725 -0.266383 -0.077986  0.177555  0.165906 -0.233518 -0.218294   \n",
      "3 -0.213725 -0.266383 -0.077986  0.177555  0.165906 -0.233518 -0.218294   \n",
      "4 -0.213725 -0.266383 -0.077986  0.177555  0.165906 -0.233518 -0.218294   \n",
      "\n",
      "        210       211       212       213       214       215       216  \\\n",
      "0  0.271361  0.340321 -0.224755  0.508523  0.003037  0.102606 -0.390172   \n",
      "1  0.271361  0.340321 -0.224755  0.508523  0.003037  0.102606 -0.390172   \n",
      "2  0.271361  0.340321 -0.224755  0.508523  0.003037  0.102606 -0.390172   \n",
      "3  0.271361  0.340321 -0.224755  0.508523  0.003037  0.102606 -0.390172   \n",
      "4  0.271361  0.340321 -0.224755  0.508523  0.003037  0.102606 -0.390172   \n",
      "\n",
      "        217       218       219       220       221       222       223  \\\n",
      "0 -0.172488 -0.514069  0.163189  0.054578 -0.265232  0.144068  0.481106   \n",
      "1 -0.172488 -0.514069  0.163189  0.054578 -0.265232  0.144068  0.481106   \n",
      "2 -0.172488 -0.514069  0.163189  0.054578 -0.265232  0.144068  0.481106   \n",
      "3 -0.172488 -0.514069  0.163189  0.054578 -0.265232  0.144068  0.481106   \n",
      "4 -0.172488 -0.514069  0.163189  0.054578 -0.265232  0.144068  0.481106   \n",
      "\n",
      "        224       225       226       227       228       229       230  \\\n",
      "0  0.086798 -0.022336 -0.117419 -0.091144 -0.009456  0.119873 -0.224686   \n",
      "1  0.086798 -0.022336 -0.117419 -0.091144 -0.009456  0.119873 -0.224686   \n",
      "2  0.086798 -0.022336 -0.117419 -0.091144 -0.009456  0.119873 -0.224686   \n",
      "3  0.086798 -0.022336 -0.117419 -0.091144 -0.009456  0.119873 -0.224686   \n",
      "4  0.086798 -0.022336 -0.117419 -0.091144 -0.009456  0.119873 -0.224686   \n",
      "\n",
      "       231       232       233      234       235       236      237  \\\n",
      "0  0.54558 -0.225275 -0.019843 -0.27956 -0.461933 -0.134682  0.07565   \n",
      "1  0.54558 -0.225275 -0.019843 -0.27956 -0.461933 -0.134682  0.07565   \n",
      "2  0.54558 -0.225275 -0.019843 -0.27956 -0.461933 -0.134682  0.07565   \n",
      "3  0.54558 -0.225275 -0.019843 -0.27956 -0.461933 -0.134682  0.07565   \n",
      "4  0.54558 -0.225275 -0.019843 -0.27956 -0.461933 -0.134682  0.07565   \n",
      "\n",
      "        238       239       240       241       242       243       244  \\\n",
      "0 -0.122248  0.083591 -0.076728 -0.180306 -0.224817 -0.046457  0.299959   \n",
      "1 -0.122248  0.083591 -0.076728 -0.180306 -0.224817 -0.046457  0.299959   \n",
      "2 -0.122248  0.083591 -0.076728 -0.180306 -0.224817 -0.046457  0.299959   \n",
      "3 -0.122248  0.083591 -0.076728 -0.180306 -0.224817 -0.046457  0.299959   \n",
      "4 -0.122248  0.083591 -0.076728 -0.180306 -0.224817 -0.046457  0.299959   \n",
      "\n",
      "        245       246       247       248       249       250       251  \\\n",
      "0  0.044106 -0.030832  0.199749 -0.359374  0.282382 -0.131482  0.384034   \n",
      "1  0.044106 -0.030832  0.199749 -0.359374  0.282382 -0.131482  0.384034   \n",
      "2  0.044106 -0.030832  0.199749 -0.359374  0.282382 -0.131482  0.384034   \n",
      "3  0.044106 -0.030832  0.199749 -0.359374  0.282382 -0.131482  0.384034   \n",
      "4  0.044106 -0.030832  0.199749 -0.359374  0.282382 -0.131482  0.384034   \n",
      "\n",
      "        252       253       254       255       256       257       258  \\\n",
      "0  0.029014 -0.332164  0.137969 -0.240438  0.167529  0.214519  0.106633   \n",
      "1  0.029014 -0.332164  0.137969 -0.240438  0.167529  0.214519  0.106633   \n",
      "2  0.029014 -0.332164  0.137969 -0.240438  0.167529  0.214519  0.106633   \n",
      "3  0.029014 -0.332164  0.137969 -0.240438  0.167529  0.214519  0.106633   \n",
      "4  0.029014 -0.332164  0.137969 -0.240438  0.167529  0.214519  0.106633   \n",
      "\n",
      "        259       260       261       262       263       264       265  \\\n",
      "0  0.166187 -0.137058 -0.046046 -0.061498  0.266214  0.073872  0.115957   \n",
      "1  0.166187 -0.137058 -0.046046 -0.061498  0.266214  0.073872  0.115957   \n",
      "2  0.166187 -0.137058 -0.046046 -0.061498  0.266214  0.073872  0.115957   \n",
      "3  0.166187 -0.137058 -0.046046 -0.061498  0.266214  0.073872  0.115957   \n",
      "4  0.166187 -0.137058 -0.046046 -0.061498  0.266214  0.073872  0.115957   \n",
      "\n",
      "        266       267       268      269       270       271       272  \\\n",
      "0 -0.114089 -0.250607 -0.245225 -0.47245  0.072435  0.227217 -0.087917   \n",
      "1 -0.114089 -0.250607 -0.245225 -0.47245  0.072435  0.227217 -0.087917   \n",
      "2 -0.114089 -0.250607 -0.245225 -0.47245  0.072435  0.227217 -0.087917   \n",
      "3 -0.114089 -0.250607 -0.245225 -0.47245  0.072435  0.227217 -0.087917   \n",
      "4 -0.114089 -0.250607 -0.245225 -0.47245  0.072435  0.227217 -0.087917   \n",
      "\n",
      "       273      274       275       276       277       278       279  \\\n",
      "0  0.31472 -0.20059 -0.270201 -0.124441  0.299038  0.093517  0.333909   \n",
      "1  0.31472 -0.20059 -0.270201 -0.124441  0.299038  0.093517  0.333909   \n",
      "2  0.31472 -0.20059 -0.270201 -0.124441  0.299038  0.093517  0.333909   \n",
      "3  0.31472 -0.20059 -0.270201 -0.124441  0.299038  0.093517  0.333909   \n",
      "4  0.31472 -0.20059 -0.270201 -0.124441  0.299038  0.093517  0.333909   \n",
      "\n",
      "        280       281      282       283       284       285       286  \\\n",
      "0 -0.373833 -0.016801 -0.25441  0.147502 -0.211106 -0.398142  0.261131   \n",
      "1 -0.373833 -0.016801 -0.25441  0.147502 -0.211106 -0.398142  0.261131   \n",
      "2 -0.373833 -0.016801 -0.25441  0.147502 -0.211106 -0.398142  0.261131   \n",
      "3 -0.373833 -0.016801 -0.25441  0.147502 -0.211106 -0.398142  0.261131   \n",
      "4 -0.373833 -0.016801 -0.25441  0.147502 -0.211106 -0.398142  0.261131   \n",
      "\n",
      "        287       288       289      290       291       292      293  \\\n",
      "0 -0.093832  0.083415 -0.058924  0.12083  0.407166  0.032389 -0.20343   \n",
      "1 -0.093832  0.083415 -0.058924  0.12083  0.407166  0.032389 -0.20343   \n",
      "2 -0.093832  0.083415 -0.058924  0.12083  0.407166  0.032389 -0.20343   \n",
      "3 -0.093832  0.083415 -0.058924  0.12083  0.407166  0.032389 -0.20343   \n",
      "4 -0.093832  0.083415 -0.058924  0.12083  0.407166  0.032389 -0.20343   \n",
      "\n",
      "        294      295       296      297       298       299       300  \\\n",
      "0  0.119251  0.21343 -0.154595 -0.03111  0.069894 -0.143406 -0.420346   \n",
      "1  0.119251  0.21343 -0.154595 -0.03111  0.069894 -0.143406 -0.420346   \n",
      "2  0.119251  0.21343 -0.154595 -0.03111  0.069894 -0.143406 -0.420346   \n",
      "3  0.119251  0.21343 -0.154595 -0.03111  0.069894 -0.143406 -0.420346   \n",
      "4  0.119251  0.21343 -0.154595 -0.03111  0.069894 -0.143406 -0.420346   \n",
      "\n",
      "        301       302       303       304       305       306       307  \\\n",
      "0 -0.091248 -0.310805  0.142367 -0.034012  0.013748  0.281259  0.008312   \n",
      "1 -0.091248 -0.310805  0.142367 -0.034012  0.013748  0.281259  0.008312   \n",
      "2 -0.091248 -0.310805  0.142367 -0.034012  0.013748  0.281259  0.008312   \n",
      "3 -0.091248 -0.310805  0.142367 -0.034012  0.013748  0.281259  0.008312   \n",
      "4 -0.091248 -0.310805  0.142367 -0.034012  0.013748  0.281259  0.008312   \n",
      "\n",
      "        308       309      310       311       312       313       314  \\\n",
      "0  0.107207  0.345146 -0.05285  0.066808 -0.057267 -0.508928  0.011865   \n",
      "1  0.107207  0.345146 -0.05285  0.066808 -0.057267 -0.508928  0.011865   \n",
      "2  0.107207  0.345146 -0.05285  0.066808 -0.057267 -0.508928  0.011865   \n",
      "3  0.107207  0.345146 -0.05285  0.066808 -0.057267 -0.508928  0.011865   \n",
      "4  0.107207  0.345146 -0.05285  0.066808 -0.057267 -0.508928  0.011865   \n",
      "\n",
      "        315       316       317       318      319       320       321  \\\n",
      "0  0.037842  0.056347 -0.209492  0.078131 -0.32628  0.297424  0.075593   \n",
      "1  0.037842  0.056347 -0.209492  0.078131 -0.32628  0.297424  0.075593   \n",
      "2  0.037842  0.056347 -0.209492  0.078131 -0.32628  0.297424  0.075593   \n",
      "3  0.037842  0.056347 -0.209492  0.078131 -0.32628  0.297424  0.075593   \n",
      "4  0.037842  0.056347 -0.209492  0.078131 -0.32628  0.297424  0.075593   \n",
      "\n",
      "        322       323      324       325       326       327       328  \\\n",
      "0  0.201956 -0.482337  0.07935  0.296394 -0.336503  0.403085 -0.253856   \n",
      "1  0.201956 -0.482337  0.07935  0.296394 -0.336503  0.403085 -0.253856   \n",
      "2  0.201956 -0.482337  0.07935  0.296394 -0.336503  0.403085 -0.253856   \n",
      "3  0.201956 -0.482337  0.07935  0.296394 -0.336503  0.403085 -0.253856   \n",
      "4  0.201956 -0.482337  0.07935  0.296394 -0.336503  0.403085 -0.253856   \n",
      "\n",
      "        329       330       331       332       333       334      335  \\\n",
      "0 -0.213535 -0.219667  0.279972 -0.231952 -0.303199  0.246439 -0.02336   \n",
      "1 -0.213535 -0.219667  0.279972 -0.231952 -0.303199  0.246439 -0.02336   \n",
      "2 -0.213535 -0.219667  0.279972 -0.231952 -0.303199  0.246439 -0.02336   \n",
      "3 -0.213535 -0.219667  0.279972 -0.231952 -0.303199  0.246439 -0.02336   \n",
      "4 -0.213535 -0.219667  0.279972 -0.231952 -0.303199  0.246439 -0.02336   \n",
      "\n",
      "        336       337       338       339       340      341       342  \\\n",
      "0 -0.061744 -0.185342  0.211883  0.295692  0.254946 -0.24405 -0.084463   \n",
      "1 -0.061744 -0.185342  0.211883  0.295692  0.254946 -0.24405 -0.084463   \n",
      "2 -0.061744 -0.185342  0.211883  0.295692  0.254946 -0.24405 -0.084463   \n",
      "3 -0.061744 -0.185342  0.211883  0.295692  0.254946 -0.24405 -0.084463   \n",
      "4 -0.061744 -0.185342  0.211883  0.295692  0.254946 -0.24405 -0.084463   \n",
      "\n",
      "        343       344       345       346       347       348       349  \\\n",
      "0  0.144577 -0.311327 -0.280542 -0.000564 -0.236228  0.215137 -0.144639   \n",
      "1  0.144577 -0.311327 -0.280542 -0.000564 -0.236228  0.215137 -0.144639   \n",
      "2  0.144577 -0.311327 -0.280542 -0.000564 -0.236228  0.215137 -0.144639   \n",
      "3  0.144577 -0.311327 -0.280542 -0.000564 -0.236228  0.215137 -0.144639   \n",
      "4  0.144577 -0.311327 -0.280542 -0.000564 -0.236228  0.215137 -0.144639   \n",
      "\n",
      "        350      351       352       353       354       355       356  \\\n",
      "0 -0.209859 -0.47482  0.047334 -0.126752 -0.009646 -0.194392  0.193541   \n",
      "1 -0.209859 -0.47482  0.047334 -0.126752 -0.009646 -0.194392  0.193541   \n",
      "2 -0.209859 -0.47482  0.047334 -0.126752 -0.009646 -0.194392  0.193541   \n",
      "3 -0.209859 -0.47482  0.047334 -0.126752 -0.009646 -0.194392  0.193541   \n",
      "4 -0.209859 -0.47482  0.047334 -0.126752 -0.009646 -0.194392  0.193541   \n",
      "\n",
      "        357       358       359       360       361       362       363  \\\n",
      "0 -0.114479 -0.323251 -0.663135 -0.598043  0.223021 -0.438574  0.031626   \n",
      "1 -0.114479 -0.323251 -0.663135 -0.598043  0.223021 -0.438574  0.031626   \n",
      "2 -0.114479 -0.323251 -0.663135 -0.598043  0.223021 -0.438574  0.031626   \n",
      "3 -0.114479 -0.323251 -0.663135 -0.598043  0.223021 -0.438574  0.031626   \n",
      "4 -0.114479 -0.323251 -0.663135 -0.598043  0.223021 -0.438574  0.031626   \n",
      "\n",
      "        364       365       366       367       368       369       370  \\\n",
      "0  0.500164 -0.270267  0.030272 -0.011067 -0.095115  0.350293  0.054389   \n",
      "1  0.500164 -0.270267  0.030272 -0.011067 -0.095115  0.350293  0.054389   \n",
      "2  0.500164 -0.270267  0.030272 -0.011067 -0.095115  0.350293  0.054389   \n",
      "3  0.500164 -0.270267  0.030272 -0.011067 -0.095115  0.350293  0.054389   \n",
      "4  0.500164 -0.270267  0.030272 -0.011067 -0.095115  0.350293  0.054389   \n",
      "\n",
      "        371      372       373       374       375       376      377  \\\n",
      "0  0.031758 -0.12758 -0.092741 -0.378782 -0.173426  0.104485  0.34157   \n",
      "1  0.031758 -0.12758 -0.092741 -0.378782 -0.173426  0.104485  0.34157   \n",
      "2  0.031758 -0.12758 -0.092741 -0.378782 -0.173426  0.104485  0.34157   \n",
      "3  0.031758 -0.12758 -0.092741 -0.378782 -0.173426  0.104485  0.34157   \n",
      "4  0.031758 -0.12758 -0.092741 -0.378782 -0.173426  0.104485  0.34157   \n",
      "\n",
      "        378       379       380       381       382       383       384  \\\n",
      "0  0.144759  0.099169 -0.020757 -0.125436 -0.202225 -0.111146 -0.305429   \n",
      "1  0.144759  0.099169 -0.020757 -0.125436 -0.202225 -0.111146  0.110029   \n",
      "2  0.144759  0.099169 -0.020757 -0.125436 -0.202225 -0.111146 -0.050055   \n",
      "3  0.144759  0.099169 -0.020757 -0.125436 -0.202225 -0.111146 -0.179228   \n",
      "4  0.144759  0.099169 -0.020757 -0.125436 -0.202225 -0.111146  0.337553   \n",
      "\n",
      "        385       386       387       388       389       390       391  \\\n",
      "0 -0.195856  0.050723  0.122917 -0.047201  0.211321  0.286840  0.328589   \n",
      "1 -0.047425 -0.117910  0.133324  0.280799  0.203535 -0.091268  0.253599   \n",
      "2 -0.126352 -0.011387  0.103672 -0.304796 -0.348891  0.230900  0.184507   \n",
      "3 -0.045471  0.132694 -0.000103 -0.007578  0.506363  0.218473  0.050079   \n",
      "4  0.308567 -0.254550 -0.105098 -0.066543  0.300943  0.121203 -0.208856   \n",
      "\n",
      "        392       393       394       395       396       397       398  \\\n",
      "0  0.378620 -0.254915  0.071114 -0.079867  0.117521  0.065847  0.131767   \n",
      "1 -0.015631 -0.113387 -0.254033 -0.270297 -0.076146  0.127676  0.327069   \n",
      "2 -0.187676  0.056094 -0.255267  0.185250  0.087436 -0.114884  0.304676   \n",
      "3  0.131466  0.215812  0.277871  0.148312  0.121439  0.018696 -0.156923   \n",
      "4 -0.081836 -0.049078 -0.409064 -0.496477 -0.305297 -0.189066  0.062168   \n",
      "\n",
      "        399       400       401       402       403       404       405  \\\n",
      "0  0.470563 -0.013890 -0.364157  0.326812  0.331031 -0.327908  0.212605   \n",
      "1  0.406495  0.067686  0.131627 -0.311327  0.005676 -0.025287  0.228062   \n",
      "2  0.495679  0.049437  0.391902 -0.312068 -0.455073 -0.132672  0.147213   \n",
      "3  0.064237  0.496174  0.195634  0.118531  0.066247  0.033260  0.006344   \n",
      "4 -0.635277 -0.184032  0.203033 -0.106991 -0.635960  0.009593  0.079968   \n",
      "\n",
      "        406       407       408       409       410       411       412  \\\n",
      "0  0.251421  0.095511  0.178936  0.267515 -0.260521  0.149047  0.386130   \n",
      "1  0.100781  0.073753 -0.018003  0.350250  0.127176 -0.189299  0.262995   \n",
      "2 -0.253015  0.194386  0.042116 -0.164163  0.083915  0.183547 -0.205949   \n",
      "3 -0.060650 -0.019015 -0.193796  0.372556  0.092785 -0.383619  0.112539   \n",
      "4 -0.250676  0.380929 -0.036782  0.008241  0.200163 -0.094841  0.052351   \n",
      "\n",
      "        413       414       415       416       417       418       419  \\\n",
      "0 -0.259775 -0.160794 -0.144570 -0.207517  0.123067 -0.500168  0.088378   \n",
      "1  0.341349 -0.291221  0.161140  0.525662  0.078086 -0.361773 -0.147654   \n",
      "2  0.379089  0.066552 -0.089248 -0.164369  0.098077  0.068349  0.520978   \n",
      "3 -0.550953  0.242895 -0.027512 -0.193659  0.159576  0.243588  0.184516   \n",
      "4 -0.138081  0.019343  0.201678 -0.285779 -0.656490  0.120042  0.135203   \n",
      "\n",
      "        420       421       422       423       424       425       426  \\\n",
      "0  0.270612  0.378186 -0.298103  0.163272  0.150534  0.198190  0.384120   \n",
      "1  0.153079  0.476561  0.235000  0.098665  0.575066  0.288836 -0.431237   \n",
      "2  0.107283  0.175742  0.577565  0.111539  0.095762 -0.077892  0.326329   \n",
      "3  0.137389  0.138514 -0.300256  0.313762 -0.092799  0.124540 -0.194172   \n",
      "4 -0.128675  0.078115 -0.248629 -0.068869 -0.313938 -0.146910  0.357021   \n",
      "\n",
      "        427       428       429       430       431       432       433  \\\n",
      "0 -0.197360  0.169889  0.285654 -0.567715 -0.059608 -0.187451  0.028030   \n",
      "1  0.209411  0.062071 -0.188036  0.151640  0.071039  0.246898 -0.321244   \n",
      "2  0.157414 -0.022493  0.003053 -0.253905 -0.112747 -0.131832  0.380388   \n",
      "3  0.022251 -0.388086  0.152077  0.321820  0.020776  0.090219 -0.064115   \n",
      "4 -0.116521  0.217453  0.214733  0.028339  0.119621  0.055177 -0.080931   \n",
      "\n",
      "        434       435       436       437       438       439       440  \\\n",
      "0 -0.074833  0.009104  0.184352  0.252170  0.200571  0.084208 -0.025720   \n",
      "1  0.712300 -0.528477  0.007755  0.133328 -0.158451 -0.224014 -0.226186   \n",
      "2 -0.032143  0.083110  0.032751 -0.391427  0.514580  0.298197 -0.188600   \n",
      "3 -0.332663 -0.410490  0.445984  0.115542 -0.115046  0.309493  0.198305   \n",
      "4  0.073329 -0.145536 -0.281011 -0.258221 -0.185089  0.029190  0.289509   \n",
      "\n",
      "        441       442       443       444       445       446       447  \\\n",
      "0 -0.100105 -0.107760  0.309861  0.091212 -0.070045  0.266040 -0.458339   \n",
      "1  0.049977  0.091715 -0.145274 -0.250784  0.168122  0.524108 -0.455839   \n",
      "2 -0.050322 -0.076967  0.198653  0.365137  0.184868 -0.281465  0.040364   \n",
      "3  0.367086 -0.192083  0.188174  0.029654 -0.051817  0.001815  0.286903   \n",
      "4 -0.008234 -0.389353 -0.092810  0.161092  0.366209 -0.006621 -0.072075   \n",
      "\n",
      "        448       449       450       451       452       453       454  \\\n",
      "0 -0.152178 -0.058105  0.041870  0.237224 -0.163434 -0.170826 -0.015643   \n",
      "1  0.259889 -0.261835 -0.001708 -0.052592 -0.167860 -0.125889 -0.044904   \n",
      "2 -0.208563 -0.176055 -0.541638 -0.215989 -0.159667 -0.132015  0.375660   \n",
      "3 -0.141920 -0.090473 -0.247651 -0.224398  0.302792  0.123319  0.052757   \n",
      "4  0.285981 -0.131928  0.080362 -0.062624  0.277805 -0.726660  0.176702   \n",
      "\n",
      "        455       456       457       458       459       460       461  \\\n",
      "0 -0.326975 -0.224435 -0.017686  0.124773 -0.165225  0.135996  0.249342   \n",
      "1 -0.179355  0.003941 -0.505767 -0.022718  0.027351 -0.185057  0.384865   \n",
      "2 -0.087150  0.109848 -0.365342 -0.241066  0.165340  0.144739  0.397893   \n",
      "3 -0.367629  0.019886  0.434434 -0.394784  0.105565  0.023189  0.268746   \n",
      "4  0.042143  0.010350 -0.085118  0.064521 -0.400743  0.094124  0.023444   \n",
      "\n",
      "        462       463       464       465       466       467       468  \\\n",
      "0  0.311170 -0.051225  0.034848 -0.045029  0.012600  0.089669 -0.203079   \n",
      "1  0.020325 -0.218626  0.227505 -0.093484  0.139651  0.495466  0.317559   \n",
      "2  0.081041  0.067413  0.316340 -0.152447 -0.128471 -0.102084 -0.219029   \n",
      "3 -0.152334 -0.050968 -0.173245 -0.220322 -0.030848 -0.040593 -0.023649   \n",
      "4  0.037217 -0.174563 -0.020392 -0.191960  0.005897 -0.146904  0.109053   \n",
      "\n",
      "        469       470       471       472       473       474       475  \\\n",
      "0  0.151614  0.235827 -0.132118  0.074644 -0.222574  0.107660 -0.334315   \n",
      "1 -0.351094 -0.147923 -0.114614  0.081458  0.169985 -0.056208 -0.047499   \n",
      "2  0.151609  0.225778  0.028503 -0.169813 -0.136381 -0.365986 -0.022588   \n",
      "3 -0.080214  0.096596 -0.213661 -0.189757 -0.135511 -0.198087  0.155877   \n",
      "4  0.056958  0.061033 -0.230238 -0.022764 -0.078972 -0.002472 -0.244258   \n",
      "\n",
      "        476       477       478       479       480       481       482  \\\n",
      "0  0.054926 -0.003511  0.032533  0.012463 -0.024331  0.407002 -0.410953   \n",
      "1  0.146325  0.005576 -0.124370  0.302904  0.276244  0.043509  0.011059   \n",
      "2  0.115914 -0.077155 -0.032211  0.136755 -0.252154 -0.052932  0.026899   \n",
      "3  0.194770  0.235744  0.151642 -0.055752  0.338151 -0.165806 -0.344229   \n",
      "4 -0.078305 -0.241116 -0.111334 -0.054654 -0.082810  0.376362 -0.570348   \n",
      "\n",
      "        483       484       485       486       487       488       489  \\\n",
      "0 -0.183887 -0.056108  0.393339 -0.160410  0.074178 -0.143777  0.054233   \n",
      "1  0.162433 -0.253419  0.091947 -0.125933  0.006868  0.481282  0.142919   \n",
      "2 -0.401340  0.392552  0.088960  0.102041 -0.338693  0.134954  0.343914   \n",
      "3  0.224744  0.127607  0.050364  0.184367  0.152088 -0.105841  0.007700   \n",
      "4 -0.079688  0.203113  0.051552  0.197585  0.007046  0.024963 -0.336053   \n",
      "\n",
      "        490       491       492       493       494       495       496  \\\n",
      "0  0.131105  0.251412 -0.159886  0.194006  0.072112 -0.038581 -0.062968   \n",
      "1 -0.355102  0.092323  0.126945  0.227258  0.046461  0.261311 -0.022598   \n",
      "2  0.034133  0.182435 -0.005511 -0.323420  0.066111 -0.051425  0.051011   \n",
      "3 -0.083594 -0.121932  0.087832  0.111660  0.201150  0.072735  0.029485   \n",
      "4  0.169417 -0.111493 -0.420883 -0.377966 -0.023374  0.243617  0.003144   \n",
      "\n",
      "        497       498       499       500       501       502       503  \\\n",
      "0 -0.228008  0.108517 -0.271131  0.185130  0.136741 -0.072506 -0.082681   \n",
      "1  0.092743  0.007465  0.283195  0.616708  0.036508 -0.213377 -0.642859   \n",
      "2 -0.331383 -0.001432 -0.120852 -0.127469  0.377737 -0.172430 -0.171597   \n",
      "3  0.105426 -0.087079 -0.192834  0.159807 -0.081589  0.075069  0.280541   \n",
      "4 -0.083952  0.090266  0.126718  0.119221  0.221735  0.570481 -0.070449   \n",
      "\n",
      "        504       505       506       507       508       509       510  \\\n",
      "0  0.138134  0.111359 -0.030671  0.249798  0.109780  0.154256 -0.118602   \n",
      "1  0.160205 -0.398623 -0.066798 -0.275609 -0.438159  0.070501 -0.294387   \n",
      "2  0.270032 -0.048002 -0.205736  0.119396  0.025126  0.322570 -0.014585   \n",
      "3 -0.194047  0.207409  0.097411 -0.070507 -0.133405  0.025036 -0.081970   \n",
      "4 -0.061758  0.409857 -0.133105  0.217613  0.045705  0.095768 -0.182871   \n",
      "\n",
      "        511       512       513       514       515       516       517  \\\n",
      "0 -0.025370 -0.040016  0.115356  0.146256  0.016710  0.703211  0.180624   \n",
      "1  0.134854  0.151233 -0.190189 -0.021961  0.143597  0.338731 -0.327890   \n",
      "2  0.239469 -0.173491 -0.045664 -0.221810 -0.044944  0.199825  0.202953   \n",
      "3  0.017381 -0.147707  0.001445 -0.326065 -0.001609 -0.077991 -0.057135   \n",
      "4 -0.037191  0.415826  0.099752 -0.189288  0.236703  0.026762  0.172077   \n",
      "\n",
      "        518       519       520       521       522       523       524  \\\n",
      "0 -0.050804  0.162230  0.027303 -0.327683 -0.171041 -0.136722  0.462303   \n",
      "1  0.152009 -0.174678  0.099400 -0.184763 -0.129863 -0.442365  0.145722   \n",
      "2  0.308722  0.212249  0.133192 -0.180543 -0.057542 -0.060211  0.146851   \n",
      "3  0.607225 -0.111189  0.021947 -0.001477  0.099430 -0.365685  0.143843   \n",
      "4 -0.248222  0.228864 -0.160696 -0.024647  0.187595  0.110409  0.312419   \n",
      "\n",
      "        525       526       527       528       529       530       531  \\\n",
      "0  0.212022  0.017995  0.001156  0.016327  0.174364 -0.216371 -0.148025   \n",
      "1  0.279173 -0.042772 -0.293140  0.203777  0.054748 -0.208908  0.061380   \n",
      "2 -0.008656  0.212735  0.070917  0.011922 -0.237137  0.034263 -0.400637   \n",
      "3 -0.134805 -0.173982  0.211396 -0.344757  0.074327  0.089426  0.067371   \n",
      "4 -0.286479  0.097384  0.639238 -0.068569  0.047165 -0.053489 -0.117248   \n",
      "\n",
      "        532       533       534       535       536       537       538  \\\n",
      "0  0.225801  0.413698  0.074188  0.018487 -0.178899 -0.095243 -0.046244   \n",
      "1  0.317673  0.112443 -0.289652  0.359277  0.195791 -0.001597 -0.274777   \n",
      "2  0.394357  0.181062  0.180339 -0.168692  0.113668  0.245692  0.238078   \n",
      "3  0.011517  0.073639  0.090185  0.203173 -0.348406 -0.195204 -0.047772   \n",
      "4 -0.007743  0.089393  0.057427 -0.100787 -0.313563  0.529566 -0.017157   \n",
      "\n",
      "        539       540       541       542       543       544       545  \\\n",
      "0 -0.050604 -0.120137 -0.231712 -0.235402  0.179034  0.531006  0.077607   \n",
      "1 -0.224152  0.326121  0.000573 -0.016879 -0.014275  0.247637 -0.188277   \n",
      "2 -0.399200  0.009428 -0.323450  0.046250 -0.196543  0.279585 -0.000755   \n",
      "3  0.172177 -0.172499  0.324110 -0.051649  0.121499 -0.168668  0.216142   \n",
      "4 -0.078465  0.152815 -0.072466 -0.131533  0.147685  0.067948 -0.039985   \n",
      "\n",
      "        546       547       548       549       550       551       552  \\\n",
      "0 -0.121633  0.383653  0.004132 -0.048549 -0.131026 -0.243041  0.056668   \n",
      "1 -0.262763 -0.214108 -0.285019 -0.237707  0.232789  0.391858 -0.162838   \n",
      "2  0.327180  0.119279 -0.176466  0.465127 -0.127313  0.093083 -0.025760   \n",
      "3 -0.149172 -0.231029  0.165180 -0.287596 -0.077783 -0.061533  0.454989   \n",
      "4  0.134148 -0.023526  0.111908 -0.538851  0.279047 -0.146046  0.320298   \n",
      "\n",
      "        553       554       555       556       557       558       559  \\\n",
      "0  0.150722  0.037071  0.020903 -0.071421 -0.039519  0.321659  0.251948   \n",
      "1  0.124526  0.137756  0.415405 -0.298176  0.088338  0.005252  0.373866   \n",
      "2  0.457490 -0.175095 -0.184373 -0.091065 -0.087326 -0.185098 -0.435533   \n",
      "3 -0.180673  0.098252  0.051854 -0.085480 -0.273723  0.225002  0.489923   \n",
      "4 -0.066249 -0.116382  0.029029 -0.384147  0.019585  0.173771  0.039826   \n",
      "\n",
      "        560       561       562       563       564       565       566  \\\n",
      "0 -0.196337  0.001778 -0.067161  0.074039  0.185616 -0.079977 -0.185519   \n",
      "1 -0.151285 -0.118669  0.143220 -0.120881  0.018455 -0.369765  0.093926   \n",
      "2 -0.246665 -0.245788  0.404830  0.044348 -0.051809  0.320264 -0.120852   \n",
      "3 -0.127308 -0.375761  0.062495 -0.130142 -0.078676 -0.014077 -0.359824   \n",
      "4 -0.361461  0.274361 -0.094373 -0.160293 -0.246129 -0.447208 -0.084152   \n",
      "\n",
      "        567       568       569       570       571       572       573  \\\n",
      "0 -0.080807  0.251166 -0.246549  0.161455  0.009611  0.237456 -0.092290   \n",
      "1  0.334708 -0.183212 -0.189448 -0.143112 -0.313719 -0.011800  0.186472   \n",
      "2 -0.466400 -0.239082 -0.013344 -0.113920  0.320190  0.183458  0.301989   \n",
      "3 -0.043187 -0.177705 -0.322193  0.188435  0.420406 -0.077246  0.264505   \n",
      "4  0.060834 -0.130811 -0.166906  0.147454 -0.304329 -0.151641  0.085457   \n",
      "\n",
      "        574       575       576       577       578       579       580  \\\n",
      "0  0.198130  0.152576  0.022380 -0.138142 -0.030471 -0.287488  0.228396   \n",
      "1  0.150840  0.055911  0.193191 -0.021541 -0.061544 -0.197457 -0.252352   \n",
      "2 -0.002786  0.313503 -0.097591 -0.212485 -0.091371  0.286986 -0.348262   \n",
      "3 -0.178652  0.289570 -0.091386  0.245796  0.201477 -0.010353  0.141252   \n",
      "4 -0.314016  0.030397 -0.251060 -0.008215  0.116926  0.237185 -0.491299   \n",
      "\n",
      "        581       582       583       584       585       586       587  \\\n",
      "0 -0.371209 -0.011048 -0.203476 -0.139848 -0.117514 -0.044234 -0.352531   \n",
      "1  0.339633  0.010897  0.265136 -0.155351 -0.195536  0.052221  0.233278   \n",
      "2  0.161858  0.096509  0.145893 -0.151262  0.224707  0.219414  0.010711   \n",
      "3  0.192410  0.039187  0.243185 -0.231605 -0.038654  0.082299 -0.377462   \n",
      "4 -0.004878  0.595051  0.039021  0.353004 -0.437084 -0.369383 -0.175671   \n",
      "\n",
      "        588       589       590       591       592       593       594  \\\n",
      "0 -0.135219  0.158430  0.109666  0.082344  0.372478  0.087440 -0.168950   \n",
      "1  0.111396  0.233667  0.142215  0.286861 -0.143250  0.003262  0.438649   \n",
      "2  0.106096 -0.366234 -0.407164  0.015729 -0.026201  0.046588 -0.007163   \n",
      "3 -0.003488 -0.041283  0.190201  0.326705  0.076762  0.288665  0.190424   \n",
      "4 -0.161008  0.050599 -0.044216 -0.137863  0.436205 -0.185593  0.060396   \n",
      "\n",
      "        595       596       597       598       599       600       601  \\\n",
      "0 -0.107334 -0.296379 -0.172141  0.053740  0.061644  0.081486  0.071036   \n",
      "1  0.299212 -0.258609  0.380969 -0.148897 -0.360839 -0.201916  0.020214   \n",
      "2  0.108660  0.186960 -0.093102 -0.179769 -0.484794 -0.035536  0.091590   \n",
      "3 -0.237751 -0.137534  0.252799  0.147681  0.150354 -0.106221 -0.107371   \n",
      "4  0.072297  0.024411 -0.034831  0.246870 -0.004926 -0.242988  0.261373   \n",
      "\n",
      "        602       603       604       605       606       607       608  \\\n",
      "0  0.119022 -0.327668  0.173888 -0.059550 -0.372844  0.098199 -0.092451   \n",
      "1  0.007793 -0.372861 -0.130439 -0.206616 -0.207095 -0.032065  0.342495   \n",
      "2 -0.083580  0.506681  0.242499  0.096827 -0.134215 -0.146862  0.108004   \n",
      "3  0.409305 -0.195802  0.201271 -0.026930 -0.024012 -0.359638  0.499919   \n",
      "4  0.157222  0.710301  0.112231  0.361196 -0.110863 -0.138876  0.319231   \n",
      "\n",
      "        609       610       611       612       613       614       615  \\\n",
      "0 -0.353249  0.822732  0.358751 -0.082721  0.040271  0.144460  0.050708   \n",
      "1  0.124860 -0.165317  0.042500 -0.110436  0.199707 -0.013766 -0.320600   \n",
      "2 -0.115572 -0.161782  0.082120  0.113235  0.036585  0.086014  0.065123   \n",
      "3  0.361260 -0.442610 -0.086012  0.205963  0.110824 -0.087438  0.316717   \n",
      "4 -0.153850 -0.024239  0.256858  0.342923 -0.025310  0.150237  0.168265   \n",
      "\n",
      "        616       617       618       619       620       621       622  \\\n",
      "0  0.008039  0.258055 -0.098273 -0.107215 -0.367340  0.114307 -0.185139   \n",
      "1  0.026004  0.180046  0.039058 -0.154969 -0.213365 -0.324854 -0.128750   \n",
      "2 -0.491375  0.090875  0.181232 -0.264418  0.153168 -0.038947  0.034189   \n",
      "3  0.190927  0.070694  0.314509 -0.009294  0.013804 -0.204165  0.401810   \n",
      "4 -0.273734  0.108492  0.177367  0.046768  0.253365 -0.134006  0.026817   \n",
      "\n",
      "        623       624       625       626       627       628       629  \\\n",
      "0 -0.058758  0.006815 -0.033270 -0.235508  0.501098  0.170961  0.270882   \n",
      "1 -0.009245  0.505932 -0.009457  0.103279  0.138911  0.028812  0.146643   \n",
      "2 -0.156974  0.160354  0.231217  0.003678  0.080507 -0.180430  0.374388   \n",
      "3 -0.220813  0.049523 -0.297519 -0.068308  0.115219  0.145847 -0.009570   \n",
      "4  0.072879 -0.000525 -0.136987 -0.364358  0.080747 -0.158681  0.153404   \n",
      "\n",
      "        630       631       632       633       634       635       636  \\\n",
      "0  0.112918 -0.123599  0.173754 -0.021811  0.357806  0.046488 -0.230817   \n",
      "1  0.016952  0.032771 -0.512462  0.019670 -0.204421 -0.207785 -0.392274   \n",
      "2 -0.162213  0.118987  0.048959 -0.265358  0.342249  0.103675 -0.292750   \n",
      "3  0.007509  0.298960 -0.010027  0.292029  0.191754  0.119680  0.248420   \n",
      "4  0.084423  0.063312  0.398960 -0.020359 -0.177739 -0.032552  0.212534   \n",
      "\n",
      "        637       638       639       640       641       642       643  \\\n",
      "0  0.138195  0.540964 -0.112848 -0.161892 -0.044201  0.054989 -0.174213   \n",
      "1 -0.097371  0.257160  0.239782 -0.111698  0.233149 -0.013287 -0.289770   \n",
      "2 -0.394305  0.083522 -0.114595  0.352197 -0.327376 -0.329345 -0.182257   \n",
      "3  0.059134  0.151053 -0.225800  0.044763 -0.012574  0.060797  0.255526   \n",
      "4  0.330304 -0.228717 -0.078251  0.213780  0.187976  0.395227 -0.361634   \n",
      "\n",
      "        644       645       646       647       648       649       650  \\\n",
      "0  0.330749  0.315267 -0.033956 -0.027343 -0.102151  0.051997 -0.183171   \n",
      "1 -0.000598 -0.193297  0.100841  0.154346  0.259128  0.310611 -0.157343   \n",
      "2 -0.002063 -0.119428 -0.113180  0.200048  0.288242  0.180703 -0.309030   \n",
      "3  0.071424 -0.479748  0.263778  0.029620  0.099193 -0.194811  0.176700   \n",
      "4 -0.260142  0.054025 -0.095022  0.120842 -0.213432  0.065902  0.187732   \n",
      "\n",
      "        651       652       653       654       655       656       657  \\\n",
      "0 -0.644568  0.353375  0.084629 -0.079936 -0.065130 -0.078137 -0.134263   \n",
      "1  0.127558  0.473410  0.051271  0.457642  0.078002  0.169108 -0.328726   \n",
      "2  0.143959  0.021174 -0.471334  0.155972 -0.027240  0.308972  0.220736   \n",
      "3 -0.075952  0.380289  0.197925 -0.009179 -0.051199  0.016204  0.299664   \n",
      "4  0.375813 -0.222687 -0.195569  0.169032  0.170699  0.145367 -0.046562   \n",
      "\n",
      "        658       659       660       661       662       663       664  \\\n",
      "0  0.252200  0.098116  0.051355 -0.100248 -0.254710  0.012716 -0.062630   \n",
      "1  0.144758 -0.326354  0.277318 -0.174593  0.193963  0.172515  0.092538   \n",
      "2  0.009225  0.037701 -0.100896 -0.040397  0.140237  0.278473 -0.007128   \n",
      "3  0.037220  0.265893 -0.168298  0.158501 -0.403720 -0.426523  0.095037   \n",
      "4  0.113120 -0.154671  0.095164 -0.035156 -0.249667 -0.302443  0.149764   \n",
      "\n",
      "        665       666       667       668       669       670       671  \\\n",
      "0  0.220575 -0.228089 -0.092301  0.410166  0.132059  0.070516  0.003541   \n",
      "1  0.155121 -0.028630  0.079029 -0.379595  0.448429  0.395240 -0.021991   \n",
      "2 -0.092488  0.067010  0.305762  0.135257 -0.240709 -0.110029  0.084699   \n",
      "3 -0.171405  0.311506 -0.001276  0.167930 -0.049273  0.451604  0.024962   \n",
      "4 -0.321087  0.110892 -0.130659 -0.215019  0.164353 -0.166866 -0.213241   \n",
      "\n",
      "        672       673       674       675       676       677       678  \\\n",
      "0  0.452086  0.171609 -0.079803  0.055139  0.004778 -0.102671 -0.052272   \n",
      "1  0.254623 -0.030875 -0.078206  0.168163 -0.165329  0.037486  0.022762   \n",
      "2 -0.029942  0.128215  0.160159 -0.207086  0.217801 -0.302712 -0.324976   \n",
      "3 -0.130577  0.044423  0.079740  0.146813  0.019124  0.223936 -0.006688   \n",
      "4 -0.659104  0.264443 -0.212828  0.188797  0.205181  0.163400  0.511329   \n",
      "\n",
      "        679       680       681       682       683       684       685  \\\n",
      "0 -0.013585 -0.212014 -0.220012  0.028108 -0.061258 -0.219196 -0.247867   \n",
      "1  0.049596 -0.066634 -0.250403 -0.004969  0.074765  0.162118 -0.012919   \n",
      "2 -0.000909  0.132405 -0.202668  0.146298 -0.123777  0.146726  0.210634   \n",
      "3  0.163707 -0.115882  0.124769 -0.245764  0.351160  0.350255 -0.088717   \n",
      "4  0.579791  0.054428  0.292156 -0.008240  0.156674 -0.175289  0.383638   \n",
      "\n",
      "        686       687       688       689       690       691       692  \\\n",
      "0 -0.006736 -0.119079  0.140628 -0.068434  0.088924 -0.059329 -0.007767   \n",
      "1 -0.193384  0.080014  0.264947  0.036262  0.029661  0.389888  0.281408   \n",
      "2  0.099477  0.027172 -0.219329 -0.086846  0.127597 -0.056512 -0.205080   \n",
      "3  0.128597 -0.089143  0.152104  0.005200  0.303028 -0.161923 -0.192797   \n",
      "4  0.146248 -0.130873  0.264479  0.171270 -0.015284  0.476252 -0.164951   \n",
      "\n",
      "        693       694       695       696       697       698       699  \\\n",
      "0  0.042114 -0.067270  0.174163 -0.169694  0.049716  0.406348  0.112242   \n",
      "1  0.110879 -0.072259  0.148936 -0.430370  0.099566 -0.176255 -0.131982   \n",
      "2  0.206439 -0.133047 -0.302293 -0.207504  0.075321 -0.046823 -0.059939   \n",
      "3  0.187286 -0.092812 -0.103971 -0.033766  0.116015  0.051520 -0.253056   \n",
      "4  0.083941  0.086153  0.020205 -0.201804 -0.131500 -0.386305  0.264596   \n",
      "\n",
      "        700       701       702       703       704       705       706  \\\n",
      "0 -0.101025 -0.448254  0.202366  0.253301  0.015548 -0.010526  0.117493   \n",
      "1 -0.279874 -0.295917 -0.152840 -0.334313 -0.228567  0.547303 -0.581462   \n",
      "2  0.205633  0.488413  0.064141 -0.012059 -0.004077  0.101675 -0.569620   \n",
      "3  0.153529  0.060947 -0.022770 -0.067006 -0.096760 -0.098976 -0.084954   \n",
      "4 -0.022453  0.443395  0.023796 -0.176376 -0.268102  0.187552 -0.250585   \n",
      "\n",
      "        707       708       709       710       711       712       713  \\\n",
      "0  0.223090  0.021624  0.158919  0.185718 -0.184856  0.132647 -0.191001   \n",
      "1 -0.055603  0.064609  0.184470  0.204911  0.081888  0.008037  0.141719   \n",
      "2  0.129874 -0.491417 -0.003476 -0.211112  0.187738 -0.166938 -0.042565   \n",
      "3 -0.080504  0.093510 -0.486199  0.201493  0.054587 -0.310955 -0.258970   \n",
      "4 -0.427968  0.150685  0.269932 -0.053421  0.325992  0.101846  0.069106   \n",
      "\n",
      "        714       715       716       717       718       719       720  \\\n",
      "0 -0.222918 -0.205216 -0.469404 -0.398530 -0.131911  0.139060  0.053643   \n",
      "1 -0.060391 -0.029400  0.036403 -0.041980  0.236674 -0.043936  0.058968   \n",
      "2 -0.523321 -0.240062  0.073126 -0.140759 -0.361063 -0.532606  0.021755   \n",
      "3 -0.183652 -0.213592  0.034167 -0.090260 -0.145839 -0.332708 -0.317452   \n",
      "4  0.140818  0.245264  0.167378  0.327021 -0.041222 -0.395011  0.447004   \n",
      "\n",
      "        721       722       723       724       725       726       727  \\\n",
      "0  0.042171  0.166297 -0.256767 -0.104300  0.066290 -0.194333  0.088790   \n",
      "1  0.128886  0.270470 -0.134896  0.162501  0.378885  0.188817  0.093798   \n",
      "2 -0.132048  0.107852  0.257778  0.052093 -0.150950  0.147174 -0.033683   \n",
      "3 -0.271369 -0.080325 -0.046246 -0.200131  0.085176 -0.028367  0.125840   \n",
      "4  0.432034  0.318794  0.371807  0.078077 -0.494751  0.304846 -0.069192   \n",
      "\n",
      "        728       729       730       731       732       733       734  \\\n",
      "0 -0.163625  0.116421 -0.327260 -0.057500  0.055764 -0.101104  0.024591   \n",
      "1 -0.109176  0.284090  0.132571 -0.237776  0.085698 -0.066912  0.057225   \n",
      "2  0.059027 -0.092095 -0.079555  0.105524  0.024136 -0.390563  0.335421   \n",
      "3  0.397919 -0.052953  0.013228  0.102840  0.006359 -0.225220 -0.077474   \n",
      "4 -0.003307 -0.004715 -0.209099  0.263934  0.119913  0.778254  0.046329   \n",
      "\n",
      "        735       736       737       738       739       740       741  \\\n",
      "0 -0.240103 -0.222138  0.208280  0.078694  0.104925  0.256811 -0.034338   \n",
      "1 -0.033974  0.003949 -0.243508 -0.173706 -0.087990  0.094148 -0.090905   \n",
      "2  0.090006 -0.180609 -0.555235  0.426301 -0.007440  0.090012 -0.281750   \n",
      "3 -0.123396  0.370524  0.334870  0.146492 -0.221571 -0.074384 -0.086047   \n",
      "4  0.545926  0.028527 -0.085063  0.297926  0.301323  0.089675  0.154701   \n",
      "\n",
      "        742       743       744       745       746       747       748  \\\n",
      "0  0.064534  0.076138 -0.208592 -0.133812  0.030032 -0.103034 -0.068861   \n",
      "1  0.225477 -0.259727 -0.250395 -0.285274 -0.246585 -0.187205 -0.303011   \n",
      "2  0.043319  0.433795  0.019170 -0.259713  0.010364  0.219126 -0.062866   \n",
      "3  0.325838  0.200077 -0.141923  0.061599  0.133854 -0.225025  0.005006   \n",
      "4 -0.125402  0.584407  0.256602 -0.154708 -0.208121 -0.074630  0.030316   \n",
      "\n",
      "        749       750       751       752       753       754       755  \\\n",
      "0 -0.279218 -0.491950  0.219222 -0.078840 -0.074826  0.120940  0.148579   \n",
      "1 -0.192719  0.170888  0.006538 -0.064325 -0.129480 -0.016122 -0.188868   \n",
      "2  0.094972 -0.204094 -0.007993 -0.281496  0.233434 -0.194744 -0.363665   \n",
      "3  0.533817 -0.036039  0.066814  0.356839 -0.162818 -0.134117 -0.045717   \n",
      "4 -0.013027 -0.630744 -0.207815 -0.107991  0.039715  0.104799  0.141585   \n",
      "\n",
      "        756       757       758       759       760       761       762  \\\n",
      "0 -0.453542  0.020448 -0.124063 -0.048203  0.048329 -0.485126 -0.260421   \n",
      "1  0.155280 -0.136216  0.131919  0.328351  0.325369 -0.277231 -0.068271   \n",
      "2 -0.095698  0.424255  0.024169 -0.193330  0.052059 -0.193610 -0.042976   \n",
      "3  0.173617  0.195515  0.045051 -0.026459 -0.088909 -0.314534 -0.225162   \n",
      "4  0.457567  0.236158 -0.100379  0.015832 -0.289388  0.009492 -0.385550   \n",
      "\n",
      "        763       764       765       766       767  \n",
      "0  0.063325 -0.363359  0.016967  0.093612  0.085406  \n",
      "1  0.183043 -0.269338 -0.129341 -0.076344 -0.289846  \n",
      "2 -0.165861 -0.139419 -0.106531 -0.179026  0.161140  \n",
      "3 -0.118786 -0.226423 -0.013980 -0.084358  0.254197  \n",
      "4 -0.111259  0.181878 -0.534939  0.191894 -0.253740  \n"
     ]
    }
   ],
   "source": [
    "# Create X data using embeddings for catalyst, imine, thiol, and product\n",
    "X_data = []\n",
    "Y_data = []\n",
    "\n",
    "for _, row in Y_df.iterrows():\n",
    "    catalyst_id = row['catalyst_id']\n",
    "    imine_id = row['imine_id']\n",
    "    thiol_id = row['thiol_id']\n",
    "    product_id = row['product_id']\n",
    "    \n",
    "    if all(id in embeddings for id in [catalyst_id, imine_id, thiol_id, product_id]):\n",
    "        combined_embedding = np.concatenate([\n",
    "            embeddings[catalyst_id],\n",
    "            embeddings[imine_id],\n",
    "            embeddings[thiol_id],\n",
    "            embeddings[product_id]\n",
    "        ])\n",
    "        X_data.append(combined_embedding)\n",
    "        Y_data.append(row['selectivity_ddGact_kcal'])\n",
    "    else:\n",
    "        print(f\"Missing embedding for reaction: {row['reaction_handle']} - Missing IDs: {[id for id in [catalyst_id, imine_id, thiol_id, product_id] if id not in embeddings]}\")\n",
    "\n",
    "X_df = pd.DataFrame(X_data)\n",
    "Y_series = pd.Series(Y_data)\n",
    "\n",
    "print(f\"Created dataset with {len(X_df)} samples and {X_df.shape[1]} features\")\n",
    "print(\"Sample rows from X_df:\")\n",
    "print(X_df.head())\n",
    "\n",
    "if len(X_df) == 0:\n",
    "    print(\"Error: No matching data found. Please check if the IDs in Y_DATA.csv match the keys in the embeddings file.\")\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting started...\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[CV 1/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.7777777777777777, model__learning_rate=0.3792690190732246, model__max_depth=5, model__min_child_weight=10.0, model__n_estimators=300, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.198) r2: (test=0.860) total time=  16.9s\n",
      "[CV 4/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.7777777777777777, model__learning_rate=0.3792690190732246, model__max_depth=5, model__min_child_weight=10.0, model__n_estimators=300, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.202) r2: (test=0.838) total time= 1.1min\n",
      "[CV 2/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.7777777777777777, model__learning_rate=0.3792690190732246, model__max_depth=5, model__min_child_weight=10.0, model__n_estimators=300, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.178) r2: (test=0.870) total time= 1.1min\n",
      "[CV 3/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.7777777777777777, model__learning_rate=0.3792690190732246, model__max_depth=5, model__min_child_weight=10.0, model__n_estimators=300, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.190) r2: (test=0.889) total time= 1.1min\n",
      "[CV 5/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.7777777777777777, model__learning_rate=0.3792690190732246, model__max_depth=5, model__min_child_weight=10.0, model__n_estimators=300, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.189) r2: (test=0.866) total time= 1.1min\n",
      "[CV 1/5] END model__colsample_bytree=0.5, model__gamma=0.1111111111111111, model__learning_rate=0.03359818286283781, model__max_depth=4, model__min_child_weight=10.0, model__n_estimators=700, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.152) r2: (test=0.903) total time= 1.2min\n",
      "[CV 5/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.0, model__learning_rate=0.0001623776739188721, model__max_depth=4, model__min_child_weight=8.0, model__n_estimators=600, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.515) r2: (test=0.106) total time= 1.2min\n",
      "[CV 2/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.0, model__learning_rate=0.0001623776739188721, model__max_depth=4, model__min_child_weight=8.0, model__n_estimators=600, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.517) r2: (test=0.104) total time= 1.2min\n",
      "[CV 1/5] END model__colsample_bytree=0.2, model__gamma=0.6666666666666666, model__learning_rate=0.0006951927961775605, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=800, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.388) r2: (test=0.477) total time= 1.3min\n",
      "[CV 4/5] END model__colsample_bytree=0.2, model__gamma=0.6666666666666666, model__learning_rate=0.0006951927961775605, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=800, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.394) r2: (test=0.468) total time= 1.3min\n",
      "[CV 2/5] END model__colsample_bytree=0.2, model__gamma=0.6666666666666666, model__learning_rate=0.0006951927961775605, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=800, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.387) r2: (test=0.490) total time= 1.3min\n",
      "[CV 1/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.0, model__learning_rate=0.0001623776739188721, model__max_depth=4, model__min_child_weight=8.0, model__n_estimators=600, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.529) r2: (test=0.090) total time= 1.3min\n",
      "[CV 5/5] END model__colsample_bytree=0.2, model__gamma=0.6666666666666666, model__learning_rate=0.0006951927961775605, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=800, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.374) r2: (test=0.503) total time= 1.3min\n",
      "[CV 2/5] END model__colsample_bytree=0.5, model__gamma=0.1111111111111111, model__learning_rate=0.03359818286283781, model__max_depth=4, model__min_child_weight=10.0, model__n_estimators=700, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.145) r2: (test=0.906) total time= 1.3min\n",
      "[CV 3/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.0, model__learning_rate=0.0001623776739188721, model__max_depth=4, model__min_child_weight=8.0, model__n_estimators=600, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.569) r2: (test=0.113) total time= 1.3min\n",
      "[CV 3/5] END model__colsample_bytree=0.2, model__gamma=0.6666666666666666, model__learning_rate=0.0006951927961775605, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=800, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.428) r2: (test=0.480) total time= 1.3min\n",
      "[CV 4/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.0, model__learning_rate=0.0001623776739188721, model__max_depth=4, model__min_child_weight=8.0, model__n_estimators=600, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.527) r2: (test=0.106) total time= 1.4min\n",
      "[CV 3/5] END model__colsample_bytree=0.6, model__gamma=0.0, model__learning_rate=0.0001623776739188721, model__max_depth=None, model__min_child_weight=6.0, model__n_estimators=300, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.586) r2: (test=0.065) total time= 1.4min\n",
      "[CV 3/5] END model__colsample_bytree=0.5, model__gamma=0.1111111111111111, model__learning_rate=0.03359818286283781, model__max_depth=4, model__min_child_weight=10.0, model__n_estimators=700, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.158) r2: (test=0.916) total time= 2.2min\n",
      "[CV 1/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.5555555555555556, model__learning_rate=0.007847599703514606, model__max_depth=9, model__min_child_weight=1.0, model__n_estimators=400, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.183) r2: (test=0.871) total time= 2.5min\n",
      "[CV 2/5] END model__colsample_bytree=0.6, model__gamma=0.0, model__learning_rate=0.0001623776739188721, model__max_depth=None, model__min_child_weight=6.0, model__n_estimators=300, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.530) r2: (test=0.057) total time= 3.4min\n",
      "[CV 4/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.5555555555555556, model__learning_rate=0.007847599703514606, model__max_depth=9, model__min_child_weight=1.0, model__n_estimators=400, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.193) r2: (test=0.846) total time= 3.9min\n",
      "[CV 2/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.5555555555555556, model__learning_rate=0.007847599703514606, model__max_depth=9, model__min_child_weight=1.0, model__n_estimators=400, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.166) r2: (test=0.887) total time= 3.9min\n",
      "[CV 1/5] END model__colsample_bytree=0.6, model__gamma=0.6666666666666666, model__learning_rate=0.23357214690901212, model__max_depth=9, model__min_child_weight=3.0, model__n_estimators=700, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.182) r2: (test=0.874) total time= 3.7min\n",
      "[CV 4/5] END model__colsample_bytree=0.8, model__gamma=0.1111111111111111, model__learning_rate=0.03359818286283781, model__max_depth=None, model__min_child_weight=8.0, model__n_estimators=200, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.167) r2: (test=0.875) total time= 3.8min\n",
      "[CV 1/5] END model__colsample_bytree=0.6, model__gamma=0.0, model__learning_rate=0.0001623776739188721, model__max_depth=None, model__min_child_weight=6.0, model__n_estimators=300, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.540) r2: (test=0.057) total time= 3.9min\n",
      "[CV 3/5] END model__colsample_bytree=0.8, model__gamma=0.1111111111111111, model__learning_rate=0.03359818286283781, model__max_depth=None, model__min_child_weight=8.0, model__n_estimators=200, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.165) r2: (test=0.912) total time= 3.8min\n",
      "[CV 2/5] END model__colsample_bytree=0.6, model__gamma=0.6666666666666666, model__learning_rate=0.23357214690901212, model__max_depth=9, model__min_child_weight=3.0, model__n_estimators=700, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.157) r2: (test=0.897) total time= 3.8min\n",
      "[CV 5/5] END model__colsample_bytree=0.5, model__gamma=0.1111111111111111, model__learning_rate=0.03359818286283781, model__max_depth=4, model__min_child_weight=10.0, model__n_estimators=700, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.152) r2: (test=0.903) total time= 3.8min\n",
      "[CV 3/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.7777777777777777, model__learning_rate=0.0006951927961775605, model__max_depth=6, model__min_child_weight=9.0, model__n_estimators=200, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.553) r2: (test=0.158) total time= 3.7min\n",
      "[CV 1/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.1111111111111111, model__learning_rate=0.3792690190732246, model__max_depth=8, model__min_child_weight=4.0, model__n_estimators=500, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.157) r2: (test=0.900) total time= 3.7min\n",
      "[CV 3/5] END model__colsample_bytree=0.7000000000000001, model__gamma=1.0, model__learning_rate=0.14384498882876628, model__max_depth=9, model__min_child_weight=3.0, model__n_estimators=200, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.205) r2: (test=0.875) total time= 3.8min\n",
      "[CV 4/5] END model__colsample_bytree=0.6, model__gamma=0.6666666666666666, model__learning_rate=0.23357214690901212, model__max_depth=9, model__min_child_weight=3.0, model__n_estimators=700, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.182) r2: (test=0.857) total time= 3.8min\n",
      "[CV 5/5] END model__colsample_bytree=0.8, model__gamma=0.1111111111111111, model__learning_rate=0.03359818286283781, model__max_depth=None, model__min_child_weight=8.0, model__n_estimators=200, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.154) r2: (test=0.903) total time= 3.9min\n",
      "[CV 5/5] END model__colsample_bytree=0.6, model__gamma=0.7777777777777777, model__learning_rate=0.0001, model__max_depth=3, model__min_child_weight=2.0, model__n_estimators=500, model__subsample=1.0; neg_mean_absolute_error: (test=-0.534) r2: (test=0.043) total time= 3.7min\n",
      "[CV 5/5] END model__colsample_bytree=0.6, model__gamma=0.0, model__learning_rate=0.0001623776739188721, model__max_depth=None, model__min_child_weight=6.0, model__n_estimators=300, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.529) r2: (test=0.065) total time= 3.8min\n",
      "[CV 4/5] END model__colsample_bytree=0.7000000000000001, model__gamma=1.0, model__learning_rate=0.14384498882876628, model__max_depth=9, model__min_child_weight=3.0, model__n_estimators=200, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.199) r2: (test=0.847) total time= 3.8min\n",
      "[CV 2/5] END model__colsample_bytree=0.1, model__gamma=0.2222222222222222, model__learning_rate=0.14384498882876628, model__max_depth=5, model__min_child_weight=10.0, model__n_estimators=100, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.157) r2: (test=0.900) total time= 3.4min\n",
      "[CV 5/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.7777777777777777, model__learning_rate=0.0006951927961775605, model__max_depth=6, model__min_child_weight=9.0, model__n_estimators=200, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.499) r2: (test=0.162) total time= 3.7min\n",
      "[CV 1/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.2222222222222222, model__learning_rate=1.0, model__max_depth=5, model__min_child_weight=9.0, model__n_estimators=600, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.184) r2: (test=0.859) total time= 3.7min\n",
      "[CV 3/5] END model__colsample_bytree=0.6, model__gamma=0.7777777777777777, model__learning_rate=0.0001, model__max_depth=3, model__min_child_weight=2.0, model__n_estimators=500, model__subsample=1.0; neg_mean_absolute_error: (test=-0.590) r2: (test=0.049) total time= 3.7min\n",
      "[CV 4/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.7777777777777777, model__learning_rate=0.0006951927961775605, model__max_depth=6, model__min_child_weight=9.0, model__n_estimators=200, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.509) r2: (test=0.156) total time= 3.7min\n",
      "[CV 5/5] END model__colsample_bytree=0.7000000000000001, model__gamma=1.0, model__learning_rate=0.14384498882876628, model__max_depth=9, model__min_child_weight=3.0, model__n_estimators=200, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.177) r2: (test=0.879) total time= 3.8min\n",
      "[CV 4/5] END model__colsample_bytree=0.6, model__gamma=0.0, model__learning_rate=0.0001623776739188721, model__max_depth=None, model__min_child_weight=6.0, model__n_estimators=300, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.539) r2: (test=0.063) total time= 3.8min\n",
      "[CV 3/5] END model__colsample_bytree=0.6, model__gamma=0.6666666666666666, model__learning_rate=0.23357214690901212, model__max_depth=9, model__min_child_weight=3.0, model__n_estimators=700, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.182) r2: (test=0.900) total time= 3.8min\n",
      "[CV 2/5] END model__colsample_bytree=0.6, model__gamma=0.7777777777777777, model__learning_rate=0.0001, model__max_depth=3, model__min_child_weight=2.0, model__n_estimators=500, model__subsample=1.0; neg_mean_absolute_error: (test=-0.536) r2: (test=0.036) total time= 3.7min\n",
      "[CV 5/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.5555555555555556, model__learning_rate=0.007847599703514606, model__max_depth=9, model__min_child_weight=1.0, model__n_estimators=400, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.173) r2: (test=0.883) total time= 4.0min\n",
      "[CV 5/5] END model__colsample_bytree=0.6, model__gamma=0.6666666666666666, model__learning_rate=0.23357214690901212, model__max_depth=9, model__min_child_weight=3.0, model__n_estimators=700, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.172) r2: (test=0.885) total time= 3.7min\n",
      "[CV 2/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.7777777777777777, model__learning_rate=0.0006951927961775605, model__max_depth=6, model__min_child_weight=9.0, model__n_estimators=200, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.502) r2: (test=0.153) total time= 3.8min\n",
      "[CV 5/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.1111111111111111, model__learning_rate=0.3792690190732246, model__max_depth=8, model__min_child_weight=4.0, model__n_estimators=500, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.160) r2: (test=0.899) total time= 3.3min\n",
      "[CV 1/5] END model__colsample_bytree=0.5, model__gamma=0.4444444444444444, model__learning_rate=0.03359818286283781, model__max_depth=7, model__min_child_weight=8.0, model__n_estimators=300, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.176) r2: (test=0.881) total time= 3.6min\n",
      "[CV 4/5] END model__colsample_bytree=0.8, model__gamma=1.0, model__learning_rate=0.05455594781168514, model__max_depth=10, model__min_child_weight=10.0, model__n_estimators=300, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.209) r2: (test=0.835) total time= 3.2min\n",
      "[CV 4/5] END model__colsample_bytree=0.5, model__gamma=0.4444444444444444, model__learning_rate=0.03359818286283781, model__max_depth=7, model__min_child_weight=8.0, model__n_estimators=300, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.184) r2: (test=0.858) total time= 3.2min\n",
      "[CV 3/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.1111111111111111, model__learning_rate=0.3792690190732246, model__max_depth=8, model__min_child_weight=4.0, model__n_estimators=500, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.168) r2: (test=0.909) total time= 3.1min\n",
      "[CV 4/5] END model__colsample_bytree=0.5, model__gamma=0.1111111111111111, model__learning_rate=0.03359818286283781, model__max_depth=4, model__min_child_weight=10.0, model__n_estimators=700, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.167) r2: (test=0.872) total time= 3.8min\n",
      "[CV 3/5] END model__colsample_bytree=0.5, model__gamma=0.4444444444444444, model__learning_rate=0.03359818286283781, model__max_depth=7, model__min_child_weight=8.0, model__n_estimators=300, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.179) r2: (test=0.901) total time= 3.3min\n",
      "[CV 3/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.5555555555555556, model__learning_rate=0.007847599703514606, model__max_depth=9, model__min_child_weight=1.0, model__n_estimators=400, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.194) r2: (test=0.885) total time= 3.9min\n",
      "[CV 4/5] END model__colsample_bytree=0.1, model__gamma=0.2222222222222222, model__learning_rate=0.14384498882876628, model__max_depth=5, model__min_child_weight=10.0, model__n_estimators=100, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.177) r2: (test=0.864) total time= 3.1min\n",
      "[CV 4/5] END model__colsample_bytree=0.6, model__gamma=0.7777777777777777, model__learning_rate=0.0001, model__max_depth=3, model__min_child_weight=2.0, model__n_estimators=500, model__subsample=1.0; neg_mean_absolute_error: (test=-0.544) r2: (test=0.044) total time= 3.7min\n",
      "[CV 4/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.1111111111111111, model__learning_rate=0.3792690190732246, model__max_depth=8, model__min_child_weight=4.0, model__n_estimators=500, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.171) r2: (test=0.867) total time= 3.5min\n",
      "[CV 3/5] END model__colsample_bytree=0.1, model__gamma=0.2222222222222222, model__learning_rate=0.14384498882876628, model__max_depth=5, model__min_child_weight=10.0, model__n_estimators=100, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.173) r2: (test=0.904) total time= 3.4min\n",
      "[CV 1/5] END model__colsample_bytree=0.6, model__gamma=0.7777777777777777, model__learning_rate=0.0001, model__max_depth=3, model__min_child_weight=2.0, model__n_estimators=500, model__subsample=1.0; neg_mean_absolute_error: (test=-0.547) r2: (test=0.032) total time= 3.8min\n",
      "[CV 2/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.2222222222222222, model__learning_rate=1.0, model__max_depth=5, model__min_child_weight=9.0, model__n_estimators=600, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.176) r2: (test=0.864) total time= 3.3min\n",
      "[CV 2/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.1111111111111111, model__learning_rate=0.3792690190732246, model__max_depth=8, model__min_child_weight=4.0, model__n_estimators=500, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.144) r2: (test=0.911) total time= 3.3min\n",
      "[CV 1/5] END model__colsample_bytree=0.8, model__gamma=1.0, model__learning_rate=0.05455594781168514, model__max_depth=10, model__min_child_weight=10.0, model__n_estimators=300, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.191) r2: (test=0.854) total time= 3.2min\n",
      "[CV 5/5] END model__colsample_bytree=0.9, model__gamma=0.0, model__learning_rate=0.012742749857031334, model__max_depth=5, model__min_child_weight=3.0, model__n_estimators=200, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.178) r2: (test=0.881) total time= 2.8min\n",
      "[CV 1/5] END model__colsample_bytree=0.7000000000000001, model__gamma=1.0, model__learning_rate=0.14384498882876628, model__max_depth=9, model__min_child_weight=3.0, model__n_estimators=200, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.198) r2: (test=0.849) total time= 3.1min\n",
      "[CV 5/5] END model__colsample_bytree=0.1, model__gamma=0.2222222222222222, model__learning_rate=0.14384498882876628, model__max_depth=5, model__min_child_weight=10.0, model__n_estimators=100, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.161) r2: (test=0.894) total time= 2.9min\n",
      "[CV 1/5] END model__colsample_bytree=0.1, model__gamma=0.2222222222222222, model__learning_rate=0.14384498882876628, model__max_depth=5, model__min_child_weight=10.0, model__n_estimators=100, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.166) r2: (test=0.887) total time= 3.1min\n",
      "[CV 2/5] END model__colsample_bytree=0.5, model__gamma=0.4444444444444444, model__learning_rate=0.03359818286283781, model__max_depth=7, model__min_child_weight=8.0, model__n_estimators=300, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.157) r2: (test=0.898) total time= 3.3min\n",
      "[CV 3/5] END model__colsample_bytree=0.8, model__gamma=1.0, model__learning_rate=0.05455594781168514, model__max_depth=10, model__min_child_weight=10.0, model__n_estimators=300, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.206) r2: (test=0.877) total time= 3.1min\n",
      "[CV 2/5] END model__colsample_bytree=0.8, model__gamma=0.1111111111111111, model__learning_rate=0.03359818286283781, model__max_depth=None, model__min_child_weight=8.0, model__n_estimators=200, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.146) r2: (test=0.904) total time= 3.0min\n",
      "[CV 1/5] END model__colsample_bytree=0.9, model__gamma=0.0, model__learning_rate=0.012742749857031334, model__max_depth=5, model__min_child_weight=3.0, model__n_estimators=200, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.181) r2: (test=0.873) total time= 2.9min\n",
      "[CV 2/5] END model__colsample_bytree=0.8, model__gamma=1.0, model__learning_rate=0.05455594781168514, model__max_depth=10, model__min_child_weight=10.0, model__n_estimators=300, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.166) r2: (test=0.888) total time= 3.1min\n",
      "[CV 5/5] END model__colsample_bytree=0.5, model__gamma=0.4444444444444444, model__learning_rate=0.03359818286283781, model__max_depth=7, model__min_child_weight=8.0, model__n_estimators=300, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.163) r2: (test=0.894) total time= 2.9min\n",
      "[CV 1/5] END model__colsample_bytree=0.8, model__gamma=0.1111111111111111, model__learning_rate=0.03359818286283781, model__max_depth=None, model__min_child_weight=8.0, model__n_estimators=200, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.157) r2: (test=0.897) total time= 3.0min\n",
      "[CV 2/5] END model__colsample_bytree=0.7000000000000001, model__gamma=1.0, model__learning_rate=0.14384498882876628, model__max_depth=9, model__min_child_weight=3.0, model__n_estimators=200, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.167) r2: (test=0.888) total time= 2.7min\n",
      "[CV 5/5] END model__colsample_bytree=0.8, model__gamma=1.0, model__learning_rate=0.05455594781168514, model__max_depth=10, model__min_child_weight=10.0, model__n_estimators=300, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.185) r2: (test=0.869) total time= 3.0min\n",
      "[CV 4/5] END model__colsample_bytree=0.9, model__gamma=0.0, model__learning_rate=0.012742749857031334, model__max_depth=5, model__min_child_weight=3.0, model__n_estimators=200, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.187) r2: (test=0.853) total time= 3.0min\n",
      "[CV 3/5] END model__colsample_bytree=0.9, model__gamma=0.0, model__learning_rate=0.012742749857031334, model__max_depth=5, model__min_child_weight=3.0, model__n_estimators=200, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.191) r2: (test=0.888) total time= 2.7min\n",
      "[CV 1/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.7777777777777777, model__learning_rate=0.0006951927961775605, model__max_depth=6, model__min_child_weight=9.0, model__n_estimators=200, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.509) r2: (test=0.150) total time= 2.9min\n",
      "[CV 2/5] END model__colsample_bytree=0.9, model__gamma=0.0, model__learning_rate=0.012742749857031334, model__max_depth=5, model__min_child_weight=3.0, model__n_estimators=200, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.173) r2: (test=0.885) total time= 2.9min\n",
      "[CV 3/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.2222222222222222, model__learning_rate=1.0, model__max_depth=5, model__min_child_weight=9.0, model__n_estimators=600, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.206) r2: (test=0.871) total time= 2.7min\n",
      "[CV 4/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.2222222222222222, model__learning_rate=1.0, model__max_depth=5, model__min_child_weight=9.0, model__n_estimators=600, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.205) r2: (test=0.826) total time= 3.5min\n",
      "[CV 5/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.2222222222222222, model__learning_rate=1.0, model__max_depth=5, model__min_child_weight=9.0, model__n_estimators=600, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.213) r2: (test=0.829) total time= 3.8min\n",
      "[CV 2/5] END model__colsample_bytree=0.30000000000000004, model__gamma=1.0, model__learning_rate=0.08858667904100823, model__max_depth=10, model__min_child_weight=2.0, model__n_estimators=100, model__subsample=0.5; neg_mean_absolute_error: (test=-0.183) r2: (test=0.872) total time= 3.2min\n",
      "[CV 3/5] END model__colsample_bytree=0.4, model__gamma=0.2222222222222222, model__learning_rate=0.3792690190732246, model__max_depth=8, model__min_child_weight=3.0, model__n_estimators=900, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.165) r2: (test=0.907) total time= 3.5min\n",
      "[CV 2/5] END model__colsample_bytree=0.4, model__gamma=0.2222222222222222, model__learning_rate=0.3792690190732246, model__max_depth=8, model__min_child_weight=3.0, model__n_estimators=900, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.156) r2: (test=0.884) total time= 3.5min\n",
      "[CV 5/5] END model__colsample_bytree=0.1, model__gamma=0.2222222222222222, model__learning_rate=0.0001623776739188721, model__max_depth=7, model__min_child_weight=4.0, model__n_estimators=400, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.527) r2: (test=0.072) total time= 3.4min\n",
      "[CV 5/5] END model__colsample_bytree=0.4, model__gamma=0.2222222222222222, model__learning_rate=0.3792690190732246, model__max_depth=8, model__min_child_weight=3.0, model__n_estimators=900, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.162) r2: (test=0.894) total time= 3.4min\n",
      "[CV 1/5] END model__colsample_bytree=0.4, model__gamma=0.2222222222222222, model__learning_rate=0.3792690190732246, model__max_depth=8, model__min_child_weight=3.0, model__n_estimators=900, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.155) r2: (test=0.900) total time= 3.6min\n",
      "[CV 3/5] END model__colsample_bytree=0.1, model__gamma=0.2222222222222222, model__learning_rate=0.0001623776739188721, model__max_depth=7, model__min_child_weight=4.0, model__n_estimators=400, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.585) r2: (test=0.069) total time= 3.4min\n",
      "[CV 4/5] END model__colsample_bytree=0.4, model__gamma=0.2222222222222222, model__learning_rate=0.3792690190732246, model__max_depth=8, model__min_child_weight=3.0, model__n_estimators=900, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.170) r2: (test=0.864) total time= 3.5min\n",
      "[CV 4/5] END model__colsample_bytree=0.1, model__gamma=0.2222222222222222, model__learning_rate=0.0001623776739188721, model__max_depth=7, model__min_child_weight=4.0, model__n_estimators=400, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.538) r2: (test=0.069) total time= 3.5min\n",
      "[CV 2/5] END model__colsample_bytree=0.1, model__gamma=0.2222222222222222, model__learning_rate=0.0001623776739188721, model__max_depth=7, model__min_child_weight=4.0, model__n_estimators=400, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.529) r2: (test=0.063) total time= 3.5min\n",
      "[CV 5/5] END model__colsample_bytree=0.30000000000000004, model__gamma=1.0, model__learning_rate=0.08858667904100823, model__max_depth=10, model__min_child_weight=2.0, model__n_estimators=100, model__subsample=0.5; neg_mean_absolute_error: (test=-0.186) r2: (test=0.867) total time= 3.4min\n",
      "[CV 1/5] END model__colsample_bytree=0.1, model__gamma=0.2222222222222222, model__learning_rate=0.0001623776739188721, model__max_depth=7, model__min_child_weight=4.0, model__n_estimators=400, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.540) r2: (test=0.057) total time= 3.6min\n",
      "[CV 1/5] END model__colsample_bytree=0.1, model__gamma=0.5555555555555556, model__learning_rate=0.03359818286283781, model__max_depth=8, model__min_child_weight=5.0, model__n_estimators=800, model__subsample=0.5; neg_mean_absolute_error: (test=-0.186) r2: (test=0.864) total time= 3.3min\n",
      "[CV 4/5] END model__colsample_bytree=0.9, model__gamma=0.3333333333333333, model__learning_rate=0.05455594781168514, model__max_depth=6, model__min_child_weight=6.0, model__n_estimators=500, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.176) r2: (test=0.861) total time= 3.4min\n",
      "[CV 1/5] END model__colsample_bytree=1.0, model__gamma=0.8888888888888888, model__learning_rate=0.00026366508987303583, model__max_depth=3, model__min_child_weight=4.0, model__n_estimators=800, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.506) r2: (test=0.145) total time= 3.5min\n",
      "[CV 4/5] END model__colsample_bytree=0.30000000000000004, model__gamma=1.0, model__learning_rate=0.08858667904100823, model__max_depth=10, model__min_child_weight=2.0, model__n_estimators=100, model__subsample=0.5; neg_mean_absolute_error: (test=-0.212) r2: (test=0.834) total time= 3.5min\n",
      "[CV 4/5] END model__colsample_bytree=1.0, model__gamma=0.8888888888888888, model__learning_rate=0.00026366508987303583, model__max_depth=3, model__min_child_weight=4.0, model__n_estimators=800, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.500) r2: (test=0.176) total time= 3.5min\n",
      "[CV 1/5] END model__colsample_bytree=0.5, model__gamma=0.3333333333333333, model__learning_rate=0.0011288378916846883, model__max_depth=None, model__min_child_weight=1.0, model__n_estimators=100, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.512) r2: (test=0.146) total time= 3.3min\n",
      "[CV 3/5] END model__colsample_bytree=0.30000000000000004, model__gamma=1.0, model__learning_rate=0.08858667904100823, model__max_depth=10, model__min_child_weight=2.0, model__n_estimators=100, model__subsample=0.5; neg_mean_absolute_error: (test=-0.215) r2: (test=0.870) total time= 3.5min\n",
      "[CV 3/5] END model__colsample_bytree=0.1, model__gamma=0.5555555555555556, model__learning_rate=0.03359818286283781, model__max_depth=8, model__min_child_weight=5.0, model__n_estimators=800, model__subsample=0.5; neg_mean_absolute_error: (test=-0.185) r2: (test=0.896) total time= 3.3min\n",
      "[CV 5/5] END model__colsample_bytree=0.5, model__gamma=0.3333333333333333, model__learning_rate=0.0011288378916846883, model__max_depth=None, model__min_child_weight=1.0, model__n_estimators=100, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.500) r2: (test=0.156) total time= 3.3min\n",
      "[CV 3/5] END model__colsample_bytree=0.1, model__gamma=0.3333333333333333, model__learning_rate=0.05455594781168514, model__max_depth=None, model__min_child_weight=5.0, model__n_estimators=900, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.174) r2: (test=0.905) total time= 3.4min\n",
      "[CV 4/5] END model__colsample_bytree=0.1, model__gamma=0.3333333333333333, model__learning_rate=0.05455594781168514, model__max_depth=None, model__min_child_weight=5.0, model__n_estimators=900, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.176) r2: (test=0.863) total time= 3.4min\n",
      "[CV 1/5] END model__colsample_bytree=0.30000000000000004, model__gamma=1.0, model__learning_rate=0.08858667904100823, model__max_depth=10, model__min_child_weight=2.0, model__n_estimators=100, model__subsample=0.5; neg_mean_absolute_error: (test=-0.210) r2: (test=0.834) total time= 3.5min\n",
      "[CV 2/5] END model__colsample_bytree=0.1, model__gamma=0.4444444444444444, model__learning_rate=0.23357214690901212, model__max_depth=None, model__min_child_weight=6.0, model__n_estimators=200, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.169) r2: (test=0.890) total time= 3.3min\n",
      "[CV 5/5] END model__colsample_bytree=0.1, model__gamma=0.3333333333333333, model__learning_rate=0.05455594781168514, model__max_depth=None, model__min_child_weight=5.0, model__n_estimators=900, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.155) r2: (test=0.897) total time= 3.4min\n",
      "[CV 3/5] END model__colsample_bytree=0.1, model__gamma=0.4444444444444444, model__learning_rate=0.23357214690901212, model__max_depth=None, model__min_child_weight=6.0, model__n_estimators=200, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.175) r2: (test=0.900) total time= 3.1min\n",
      "[CV 1/5] END model__colsample_bytree=0.8, model__gamma=0.0, model__learning_rate=0.00026366508987303583, model__max_depth=5, model__min_child_weight=5.0, model__n_estimators=600, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.499) r2: (test=0.179) total time= 3.6min\n",
      "[CV 4/5] END model__colsample_bytree=0.8, model__gamma=0.0, model__learning_rate=0.00026366508987303583, model__max_depth=5, model__min_child_weight=5.0, model__n_estimators=600, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.498) r2: (test=0.191) total time= 3.6min\n",
      "[CV 2/5] END model__colsample_bytree=0.1, model__gamma=0.5555555555555556, model__learning_rate=0.03359818286283781, model__max_depth=8, model__min_child_weight=5.0, model__n_estimators=800, model__subsample=0.5; neg_mean_absolute_error: (test=-0.161) r2: (test=0.894) total time= 3.4min\n",
      "[CV 3/5] END model__colsample_bytree=0.9, model__gamma=0.3333333333333333, model__learning_rate=0.05455594781168514, model__max_depth=6, model__min_child_weight=6.0, model__n_estimators=500, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.175) r2: (test=0.905) total time= 3.5min\n",
      "[CV 2/5] END model__colsample_bytree=1.0, model__gamma=0.8888888888888888, model__learning_rate=0.00026366508987303583, model__max_depth=3, model__min_child_weight=4.0, model__n_estimators=800, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.492) r2: (test=0.176) total time= 3.6min\n",
      "[CV 1/5] END model__colsample_bytree=0.1, model__gamma=0.3333333333333333, model__learning_rate=0.05455594781168514, model__max_depth=None, model__min_child_weight=5.0, model__n_estimators=900, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.171) r2: (test=0.882) total time= 3.5min\n",
      "[CV 5/5] END model__colsample_bytree=0.1, model__gamma=0.5555555555555556, model__learning_rate=0.03359818286283781, model__max_depth=8, model__min_child_weight=5.0, model__n_estimators=800, model__subsample=0.5; neg_mean_absolute_error: (test=-0.167) r2: (test=0.886) total time= 3.4min\n",
      "[CV 5/5] END model__colsample_bytree=0.8, model__gamma=0.0, model__learning_rate=0.00026366508987303583, model__max_depth=5, model__min_child_weight=5.0, model__n_estimators=600, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.487) r2: (test=0.196) total time= 3.6min\n",
      "[CV 2/5] END model__colsample_bytree=0.9, model__gamma=0.3333333333333333, model__learning_rate=0.05455594781168514, model__max_depth=6, model__min_child_weight=6.0, model__n_estimators=500, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.150) r2: (test=0.901) total time= 3.6min\n",
      "[CV 1/5] END model__colsample_bytree=0.9, model__gamma=0.3333333333333333, model__learning_rate=0.05455594781168514, model__max_depth=6, model__min_child_weight=6.0, model__n_estimators=500, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.170) r2: (test=0.884) total time= 3.6min\n",
      "[CV 1/5] END model__colsample_bytree=0.1, model__gamma=0.4444444444444444, model__learning_rate=0.23357214690901212, model__max_depth=None, model__min_child_weight=6.0, model__n_estimators=200, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.181) r2: (test=0.869) total time= 3.3min\n",
      "[CV 5/5] END model__colsample_bytree=1.0, model__gamma=0.8888888888888888, model__learning_rate=0.00026366508987303583, model__max_depth=3, model__min_child_weight=4.0, model__n_estimators=800, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.488) r2: (test=0.174) total time= 3.6min\n",
      "[CV 2/5] END model__colsample_bytree=0.5, model__gamma=0.3333333333333333, model__learning_rate=0.0011288378916846883, model__max_depth=None, model__min_child_weight=1.0, model__n_estimators=100, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.505) r2: (test=0.143) total time= 3.4min\n",
      "[CV 3/5] END model__colsample_bytree=0.5, model__gamma=0.3333333333333333, model__learning_rate=0.0011288378916846883, model__max_depth=None, model__min_child_weight=1.0, model__n_estimators=100, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.555) r2: (test=0.155) total time= 3.4min\n",
      "[CV 3/5] END model__colsample_bytree=0.8, model__gamma=0.0, model__learning_rate=0.00026366508987303583, model__max_depth=5, model__min_child_weight=5.0, model__n_estimators=600, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.540) r2: (test=0.199) total time= 3.7min\n",
      "[CV 3/5] END model__colsample_bytree=1.0, model__gamma=0.8888888888888888, model__learning_rate=0.00026366508987303583, model__max_depth=3, model__min_child_weight=4.0, model__n_estimators=800, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.537) r2: (test=0.187) total time= 3.6min\n",
      "[CV 2/5] END model__colsample_bytree=0.1, model__gamma=0.3333333333333333, model__learning_rate=0.05455594781168514, model__max_depth=None, model__min_child_weight=5.0, model__n_estimators=900, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.156) r2: (test=0.901) total time= 3.5min\n",
      "[CV 4/5] END model__colsample_bytree=0.1, model__gamma=0.5555555555555556, model__learning_rate=0.03359818286283781, model__max_depth=8, model__min_child_weight=5.0, model__n_estimators=800, model__subsample=0.5; neg_mean_absolute_error: (test=-0.193) r2: (test=0.851) total time= 3.5min\n",
      "[CV 4/5] END model__colsample_bytree=0.5, model__gamma=0.3333333333333333, model__learning_rate=0.0011288378916846883, model__max_depth=None, model__min_child_weight=1.0, model__n_estimators=100, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.513) r2: (test=0.146) total time= 3.4min\n",
      "[CV 2/5] END model__colsample_bytree=0.8, model__gamma=0.0, model__learning_rate=0.00026366508987303583, model__max_depth=5, model__min_child_weight=5.0, model__n_estimators=600, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.490) r2: (test=0.192) total time= 3.7min\n",
      "[CV 4/5] END model__colsample_bytree=0.1, model__gamma=0.4444444444444444, model__learning_rate=0.23357214690901212, model__max_depth=None, model__min_child_weight=6.0, model__n_estimators=200, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.175) r2: (test=0.860) total time= 3.2min\n",
      "[CV 5/5] END model__colsample_bytree=0.9, model__gamma=0.3333333333333333, model__learning_rate=0.05455594781168514, model__max_depth=6, model__min_child_weight=6.0, model__n_estimators=500, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.160) r2: (test=0.896) total time= 3.6min\n",
      "[CV 5/5] END model__colsample_bytree=0.1, model__gamma=0.4444444444444444, model__learning_rate=0.23357214690901212, model__max_depth=None, model__min_child_weight=6.0, model__n_estimators=200, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.159) r2: (test=0.898) total time= 3.2min\n",
      "[CV 2/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.5555555555555556, model__learning_rate=0.08858667904100823, model__max_depth=8, model__min_child_weight=1.0, model__n_estimators=800, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.152) r2: (test=0.901) total time= 3.1min\n",
      "[CV 3/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.5555555555555556, model__learning_rate=0.08858667904100823, model__max_depth=8, model__min_child_weight=1.0, model__n_estimators=800, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.180) r2: (test=0.900) total time= 3.0min\n",
      "[CV 1/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.5555555555555556, model__learning_rate=0.08858667904100823, model__max_depth=8, model__min_child_weight=1.0, model__n_estimators=800, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.171) r2: (test=0.885) total time= 3.3min\n",
      "[CV 4/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.5555555555555556, model__learning_rate=0.08858667904100823, model__max_depth=8, model__min_child_weight=1.0, model__n_estimators=800, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.178) r2: (test=0.866) total time= 3.4min\n",
      "[CV 5/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.5555555555555556, model__learning_rate=0.08858667904100823, model__max_depth=8, model__min_child_weight=1.0, model__n_estimators=800, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.168) r2: (test=0.891) total time= 3.4min\n",
      "[CV 2/5] END model__colsample_bytree=0.5, model__gamma=0.8888888888888888, model__learning_rate=0.007847599703514606, model__max_depth=6, model__min_child_weight=10.0, model__n_estimators=1000, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.174) r2: (test=0.882) total time= 4.4min\n",
      "[CV 1/5] END model__colsample_bytree=0.5, model__gamma=0.8888888888888888, model__learning_rate=0.007847599703514606, model__max_depth=6, model__min_child_weight=10.0, model__n_estimators=1000, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.199) r2: (test=0.849) total time= 4.7min\n",
      "[CV 3/5] END model__colsample_bytree=0.5, model__gamma=0.8888888888888888, model__learning_rate=0.007847599703514606, model__max_depth=6, model__min_child_weight=10.0, model__n_estimators=1000, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.203) r2: (test=0.877) total time= 4.3min\n",
      "[CV 4/5] END model__colsample_bytree=0.5, model__gamma=0.8888888888888888, model__learning_rate=0.007847599703514606, model__max_depth=6, model__min_child_weight=10.0, model__n_estimators=1000, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.209) r2: (test=0.834) total time= 4.8min\n",
      "[CV 5/5] END model__colsample_bytree=0.5, model__gamma=0.8888888888888888, model__learning_rate=0.007847599703514606, model__max_depth=6, model__min_child_weight=10.0, model__n_estimators=1000, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.181) r2: (test=0.872) total time= 4.7min\n",
      "[CV 1/5] END model__colsample_bytree=0.6, model__gamma=0.1111111111111111, model__learning_rate=0.00026366508987303583, model__max_depth=6, model__min_child_weight=9.0, model__n_estimators=700, model__subsample=1.0; neg_mean_absolute_error: (test=-0.484) r2: (test=0.231) total time= 4.6min\n",
      "[CV 2/5] END model__colsample_bytree=0.6, model__gamma=0.1111111111111111, model__learning_rate=0.00026366508987303583, model__max_depth=6, model__min_child_weight=9.0, model__n_estimators=700, model__subsample=1.0; neg_mean_absolute_error: (test=-0.480) r2: (test=0.229) total time= 4.5min\n",
      "[CV 4/5] END model__colsample_bytree=1.0, model__gamma=0.6666666666666666, model__learning_rate=0.007847599703514606, model__max_depth=3, model__min_child_weight=1.0, model__n_estimators=500, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.209) r2: (test=0.829) total time= 3.4min\n",
      "[CV 3/5] END model__colsample_bytree=1.0, model__gamma=0.7777777777777777, model__learning_rate=0.0011288378916846883, model__max_depth=7, model__min_child_weight=1.0, model__n_estimators=100, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.553) r2: (test=0.161) total time= 3.5min\n",
      "[CV 5/5] END model__colsample_bytree=1.0, model__gamma=0.7777777777777777, model__learning_rate=0.0011288378916846883, model__max_depth=7, model__min_child_weight=1.0, model__n_estimators=100, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.496) r2: (test=0.166) total time= 3.5min\n",
      "[CV 2/5] END model__colsample_bytree=0.1, model__gamma=1.0, model__learning_rate=0.0206913808111479, model__max_depth=7, model__min_child_weight=3.0, model__n_estimators=600, model__subsample=1.0; neg_mean_absolute_error: (test=-0.187) r2: (test=0.871) total time= 3.5min\n",
      "[CV 4/5] END model__colsample_bytree=1.0, model__gamma=0.7777777777777777, model__learning_rate=0.0011288378916846883, model__max_depth=7, model__min_child_weight=1.0, model__n_estimators=100, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.509) r2: (test=0.153) total time= 3.6min\n",
      "[CV 5/5] END model__colsample_bytree=0.6, model__gamma=0.2222222222222222, model__learning_rate=0.3792690190732246, model__max_depth=9, model__min_child_weight=4.0, model__n_estimators=600, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.168) r2: (test=0.887) total time= 3.4min\n",
      "[CV 3/5] END model__colsample_bytree=1.0, model__gamma=0.6666666666666666, model__learning_rate=0.14384498882876628, model__max_depth=None, model__min_child_weight=2.0, model__n_estimators=1000, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.184) r2: (test=0.895) total time= 3.6min\n",
      "[CV 3/5] END model__colsample_bytree=0.6, model__gamma=0.2222222222222222, model__learning_rate=0.3792690190732246, model__max_depth=9, model__min_child_weight=4.0, model__n_estimators=600, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.165) r2: (test=0.914) total time= 3.4min\n",
      "[CV 2/5] END model__colsample_bytree=1.0, model__gamma=0.6666666666666666, model__learning_rate=0.14384498882876628, model__max_depth=None, model__min_child_weight=2.0, model__n_estimators=1000, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.152) r2: (test=0.904) total time= 3.6min\n",
      "[CV 5/5] END model__colsample_bytree=1.0, model__gamma=0.6666666666666666, model__learning_rate=0.007847599703514606, model__max_depth=3, model__min_child_weight=1.0, model__n_estimators=500, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.184) r2: (test=0.869) total time= 3.5min\n",
      "[CV 2/5] END model__colsample_bytree=1.0, model__gamma=0.7777777777777777, model__learning_rate=0.0011288378916846883, model__max_depth=7, model__min_child_weight=1.0, model__n_estimators=100, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.499) r2: (test=0.161) total time= 3.6min\n",
      "[CV 1/5] END model__colsample_bytree=0.1, model__gamma=1.0, model__learning_rate=0.0206913808111479, model__max_depth=7, model__min_child_weight=3.0, model__n_estimators=600, model__subsample=1.0; neg_mean_absolute_error: (test=-0.201) r2: (test=0.846) total time= 3.5min\n",
      "[CV 1/5] END model__colsample_bytree=1.0, model__gamma=0.6666666666666666, model__learning_rate=0.14384498882876628, model__max_depth=None, model__min_child_weight=2.0, model__n_estimators=1000, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.179) r2: (test=0.878) total time= 3.6min\n",
      "[CV 3/5] END model__colsample_bytree=0.1, model__gamma=1.0, model__learning_rate=0.0206913808111479, model__max_depth=7, model__min_child_weight=3.0, model__n_estimators=600, model__subsample=1.0; neg_mean_absolute_error: (test=-0.213) r2: (test=0.869) total time= 3.5min\n",
      "[CV 2/5] END model__colsample_bytree=0.6, model__gamma=0.2222222222222222, model__learning_rate=0.3792690190732246, model__max_depth=9, model__min_child_weight=4.0, model__n_estimators=600, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.147) r2: (test=0.902) total time= 3.5min\n",
      "[CV 1/5] END model__colsample_bytree=0.6, model__gamma=0.2222222222222222, model__learning_rate=0.3792690190732246, model__max_depth=9, model__min_child_weight=4.0, model__n_estimators=600, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.149) r2: (test=0.900) total time= 3.5min\n",
      "[CV 2/5] END model__colsample_bytree=0.8, model__gamma=0.5555555555555556, model__learning_rate=0.0006951927961775605, model__max_depth=3, model__min_child_weight=5.0, model__n_estimators=500, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.464) r2: (test=0.261) total time= 3.4min\n",
      "[CV 3/5] END model__colsample_bytree=0.6, model__gamma=0.1111111111111111, model__learning_rate=0.00026366508987303583, model__max_depth=6, model__min_child_weight=9.0, model__n_estimators=700, model__subsample=1.0; neg_mean_absolute_error: (test=-0.527) r2: (test=0.236) total time= 4.5min\n",
      "[CV 3/5] END model__colsample_bytree=0.8, model__gamma=0.6666666666666666, model__learning_rate=0.002976351441631319, model__max_depth=8, model__min_child_weight=1.0, model__n_estimators=500, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.258) r2: (test=0.802) total time= 3.9min\n",
      "[CV 5/5] END model__colsample_bytree=1.0, model__gamma=0.6666666666666666, model__learning_rate=0.14384498882876628, model__max_depth=None, model__min_child_weight=2.0, model__n_estimators=1000, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.175) r2: (test=0.886) total time= 3.7min\n",
      "[CV 4/5] END model__colsample_bytree=0.6, model__gamma=0.1111111111111111, model__learning_rate=0.00026366508987303583, model__max_depth=6, model__min_child_weight=9.0, model__n_estimators=700, model__subsample=1.0; neg_mean_absolute_error: (test=-0.487) r2: (test=0.223) total time= 4.1min\n",
      "[CV 1/5] END model__colsample_bytree=0.8, model__gamma=0.6666666666666666, model__learning_rate=0.002976351441631319, model__max_depth=8, model__min_child_weight=1.0, model__n_estimators=500, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.228) r2: (test=0.801) total time= 3.9min\n",
      "[CV 5/5] END model__colsample_bytree=0.1, model__gamma=1.0, model__learning_rate=0.0206913808111479, model__max_depth=7, model__min_child_weight=3.0, model__n_estimators=600, model__subsample=1.0; neg_mean_absolute_error: (test=-0.186) r2: (test=0.867) total time= 3.5min\n",
      "[CV 4/5] END model__colsample_bytree=1.0, model__gamma=0.6666666666666666, model__learning_rate=0.14384498882876628, model__max_depth=None, model__min_child_weight=2.0, model__n_estimators=1000, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.179) r2: (test=0.863) total time= 3.7min\n",
      "[CV 5/5] END model__colsample_bytree=0.6, model__gamma=0.1111111111111111, model__learning_rate=0.00026366508987303583, model__max_depth=6, model__min_child_weight=9.0, model__n_estimators=700, model__subsample=1.0; neg_mean_absolute_error: (test=-0.475) r2: (test=0.233) total time= 4.0min\n",
      "[CV 1/5] END model__colsample_bytree=1.0, model__gamma=0.7777777777777777, model__learning_rate=0.0011288378916846883, model__max_depth=7, model__min_child_weight=1.0, model__n_estimators=100, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.507) r2: (test=0.157) total time= 3.7min\n",
      "[CV 5/5] END model__colsample_bytree=0.8, model__gamma=0.6666666666666666, model__learning_rate=0.002976351441631319, model__max_depth=8, model__min_child_weight=1.0, model__n_estimators=500, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.224) r2: (test=0.812) total time= 3.9min\n",
      "[CV 5/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.1111111111111111, model__learning_rate=0.0011288378916846883, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=500, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.352) r2: (test=0.557) total time= 3.7min\n",
      "[CV 4/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.1111111111111111, model__learning_rate=0.0011288378916846883, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=500, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.369) r2: (test=0.529) total time= 3.7min\n",
      "[CV 2/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.1111111111111111, model__learning_rate=0.0011288378916846883, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=500, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.364) r2: (test=0.548) total time= 3.8min\n",
      "[CV 2/5] END model__colsample_bytree=1.0, model__gamma=0.6666666666666666, model__learning_rate=0.007847599703514606, model__max_depth=3, model__min_child_weight=1.0, model__n_estimators=500, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.179) r2: (test=0.880) total time= 3.6min\n",
      "[CV 3/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.1111111111111111, model__learning_rate=0.0011288378916846883, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=500, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.402) r2: (test=0.542) total time= 3.8min\n",
      "[CV 2/5] END model__colsample_bytree=0.8, model__gamma=0.6666666666666666, model__learning_rate=0.002976351441631319, model__max_depth=8, model__min_child_weight=1.0, model__n_estimators=500, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.227) r2: (test=0.814) total time= 3.9min\n",
      "[CV 2/5] END model__colsample_bytree=0.5, model__gamma=0.8888888888888888, model__learning_rate=0.00026366508987303583, model__max_depth=7, model__min_child_weight=2.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.481) r2: (test=0.216) total time= 3.5min\n",
      "[CV 1/5] END model__colsample_bytree=1.0, model__gamma=0.6666666666666666, model__learning_rate=0.007847599703514606, model__max_depth=3, model__min_child_weight=1.0, model__n_estimators=500, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.201) r2: (test=0.844) total time= 3.7min\n",
      "[CV 1/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.1111111111111111, model__learning_rate=0.0011288378916846883, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=500, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.362) r2: (test=0.547) total time= 3.9min\n",
      "[CV 4/5] END model__colsample_bytree=0.1, model__gamma=1.0, model__learning_rate=0.0206913808111479, model__max_depth=7, model__min_child_weight=3.0, model__n_estimators=600, model__subsample=1.0; neg_mean_absolute_error: (test=-0.215) r2: (test=0.826) total time= 3.6min\n",
      "[CV 3/5] END model__colsample_bytree=1.0, model__gamma=0.6666666666666666, model__learning_rate=0.007847599703514606, model__max_depth=3, model__min_child_weight=1.0, model__n_estimators=500, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.208) r2: (test=0.874) total time= 3.6min\n",
      "[CV 4/5] END model__colsample_bytree=0.6, model__gamma=0.2222222222222222, model__learning_rate=0.3792690190732246, model__max_depth=9, model__min_child_weight=4.0, model__n_estimators=600, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.167) r2: (test=0.876) total time= 3.6min\n",
      "[CV 5/5] END model__colsample_bytree=0.5, model__gamma=0.8888888888888888, model__learning_rate=0.00026366508987303583, model__max_depth=7, model__min_child_weight=2.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.476) r2: (test=0.226) total time= 3.5min\n",
      "[CV 1/5] END model__colsample_bytree=1.0, model__gamma=0.1111111111111111, model__learning_rate=0.0001623776739188721, model__max_depth=6, model__min_child_weight=9.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.516) r2: (test=0.129) total time= 3.4min\n",
      "[CV 4/5] END model__colsample_bytree=0.8, model__gamma=0.6666666666666666, model__learning_rate=0.002976351441631319, model__max_depth=8, model__min_child_weight=1.0, model__n_estimators=500, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.244) r2: (test=0.773) total time= 3.9min\n",
      "[CV 4/5] END model__colsample_bytree=0.8, model__gamma=0.5555555555555556, model__learning_rate=0.0006951927961775605, model__max_depth=3, model__min_child_weight=5.0, model__n_estimators=500, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.469) r2: (test=0.262) total time= 3.5min\n",
      "[CV 1/5] END model__colsample_bytree=0.8, model__gamma=0.5555555555555556, model__learning_rate=0.0006951927961775605, model__max_depth=3, model__min_child_weight=5.0, model__n_estimators=500, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.473) r2: (test=0.236) total time= 3.5min\n",
      "[CV 3/5] END model__colsample_bytree=0.5, model__gamma=0.8888888888888888, model__learning_rate=0.00026366508987303583, model__max_depth=7, model__min_child_weight=2.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.532) r2: (test=0.216) total time= 3.6min\n",
      "[CV 3/5] END model__colsample_bytree=0.8, model__gamma=0.5555555555555556, model__learning_rate=0.0006951927961775605, model__max_depth=3, model__min_child_weight=5.0, model__n_estimators=500, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.504) r2: (test=0.275) total time= 3.5min\n",
      "[CV 5/5] END model__colsample_bytree=0.8, model__gamma=0.5555555555555556, model__learning_rate=0.0006951927961775605, model__max_depth=3, model__min_child_weight=5.0, model__n_estimators=500, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.458) r2: (test=0.258) total time= 3.5min\n",
      "[CV 2/5] END model__colsample_bytree=1.0, model__gamma=0.1111111111111111, model__learning_rate=0.0001623776739188721, model__max_depth=6, model__min_child_weight=9.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.508) r2: (test=0.133) total time= 3.7min\n",
      "[CV 5/5] END model__colsample_bytree=1.0, model__gamma=0.1111111111111111, model__learning_rate=0.0001623776739188721, model__max_depth=6, model__min_child_weight=9.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.506) r2: (test=0.138) total time= 3.8min\n",
      "[CV 1/5] END model__colsample_bytree=0.5, model__gamma=0.8888888888888888, model__learning_rate=0.00026366508987303583, model__max_depth=7, model__min_child_weight=2.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.488) r2: (test=0.210) total time= 4.1min\n",
      "[CV 4/5] END model__colsample_bytree=0.5, model__gamma=0.8888888888888888, model__learning_rate=0.00026366508987303583, model__max_depth=7, model__min_child_weight=2.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.490) r2: (test=0.210) total time= 4.1min\n",
      "[CV 4/5] END model__colsample_bytree=1.0, model__gamma=0.1111111111111111, model__learning_rate=0.0001623776739188721, model__max_depth=6, model__min_child_weight=9.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.517) r2: (test=0.133) total time= 4.1min\n",
      "[CV 3/5] END model__colsample_bytree=1.0, model__gamma=0.1111111111111111, model__learning_rate=0.0001623776739188721, model__max_depth=6, model__min_child_weight=9.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.560) r2: (test=0.137) total time= 4.1min\n",
      "[CV 2/5] END model__colsample_bytree=1.0, model__gamma=0.0, model__learning_rate=0.012742749857031334, model__max_depth=6, model__min_child_weight=4.0, model__n_estimators=1000, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.153) r2: (test=0.895) total time= 6.1min\n",
      "[CV 1/5] END model__colsample_bytree=1.0, model__gamma=0.0, model__learning_rate=0.012742749857031334, model__max_depth=6, model__min_child_weight=4.0, model__n_estimators=1000, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.157) r2: (test=0.900) total time= 6.3min\n",
      "[CV 3/5] END model__colsample_bytree=1.0, model__gamma=0.0, model__learning_rate=0.012742749857031334, model__max_depth=6, model__min_child_weight=4.0, model__n_estimators=1000, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.172) r2: (test=0.894) total time= 5.7min\n",
      "[CV 4/5] END model__colsample_bytree=1.0, model__gamma=0.0, model__learning_rate=0.012742749857031334, model__max_depth=6, model__min_child_weight=4.0, model__n_estimators=1000, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.174) r2: (test=0.865) total time= 5.7min\n",
      "[CV 1/5] END model__colsample_bytree=0.6, model__gamma=0.7777777777777777, model__learning_rate=0.05455594781168514, model__max_depth=7, model__min_child_weight=10.0, model__n_estimators=1000, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.191) r2: (test=0.857) total time= 4.5min\n",
      "[CV 2/5] END model__colsample_bytree=0.6, model__gamma=0.7777777777777777, model__learning_rate=0.05455594781168514, model__max_depth=7, model__min_child_weight=10.0, model__n_estimators=1000, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.158) r2: (test=0.894) total time= 4.3min\n",
      "[CV 2/5] END model__colsample_bytree=0.4, model__gamma=0.7777777777777777, model__learning_rate=0.3792690190732246, model__max_depth=3, model__min_child_weight=6.0, model__n_estimators=600, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.174) r2: (test=0.878) total time= 3.9min\n",
      "[CV 5/5] END model__colsample_bytree=0.6, model__gamma=0.7777777777777777, model__learning_rate=0.05455594781168514, model__max_depth=7, model__min_child_weight=10.0, model__n_estimators=1000, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.175) r2: (test=0.879) total time= 4.0min\n",
      "[CV 3/5] END model__colsample_bytree=0.6, model__gamma=0.7777777777777777, model__learning_rate=0.05455594781168514, model__max_depth=7, model__min_child_weight=10.0, model__n_estimators=1000, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.188) r2: (test=0.893) total time= 4.1min\n",
      "[CV 1/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.1111111111111111, model__learning_rate=1.0, model__max_depth=5, model__min_child_weight=6.0, model__n_estimators=800, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.177) r2: (test=0.876) total time= 3.9min\n",
      "[CV 1/5] END model__colsample_bytree=0.4, model__gamma=0.7777777777777777, model__learning_rate=0.3792690190732246, model__max_depth=3, model__min_child_weight=6.0, model__n_estimators=600, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.184) r2: (test=0.860) total time= 4.0min\n",
      "[CV 5/5] END model__colsample_bytree=0.4, model__gamma=0.7777777777777777, model__learning_rate=0.3792690190732246, model__max_depth=3, model__min_child_weight=6.0, model__n_estimators=600, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.177) r2: (test=0.875) total time= 3.9min\n",
      "[CV 2/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.6666666666666666, model__learning_rate=0.05455594781168514, model__max_depth=None, model__min_child_weight=3.0, model__n_estimators=200, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.168) r2: (test=0.892) total time= 3.7min\n",
      "[CV 5/5] END model__colsample_bytree=0.1, model__gamma=0.6666666666666666, model__learning_rate=0.012742749857031334, model__max_depth=5, model__min_child_weight=9.0, model__n_estimators=600, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.181) r2: (test=0.873) total time= 3.8min\n",
      "[CV 4/5] END model__colsample_bytree=0.4, model__gamma=0.7777777777777777, model__learning_rate=0.3792690190732246, model__max_depth=3, model__min_child_weight=6.0, model__n_estimators=600, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.198) r2: (test=0.840) total time= 3.9min\n",
      "[CV 2/5] END model__colsample_bytree=0.1, model__gamma=0.6666666666666666, model__learning_rate=0.012742749857031334, model__max_depth=5, model__min_child_weight=9.0, model__n_estimators=600, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.181) r2: (test=0.878) total time= 3.8min\n",
      "[CV 2/5] END model__colsample_bytree=0.2, model__gamma=0.1111111111111111, model__learning_rate=0.3792690190732246, model__max_depth=8, model__min_child_weight=3.0, model__n_estimators=300, model__subsample=0.5; neg_mean_absolute_error: (test=-0.151) r2: (test=0.911) total time= 3.8min\n",
      "[CV 4/5] END model__colsample_bytree=0.6, model__gamma=0.7777777777777777, model__learning_rate=0.05455594781168514, model__max_depth=7, model__min_child_weight=10.0, model__n_estimators=1000, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.197) r2: (test=0.847) total time= 4.2min\n",
      "[CV 4/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.1111111111111111, model__learning_rate=1.0, model__max_depth=5, model__min_child_weight=6.0, model__n_estimators=800, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.193) r2: (test=0.843) total time= 3.9min\n",
      "[CV 5/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.1111111111111111, model__learning_rate=1.0, model__max_depth=5, model__min_child_weight=6.0, model__n_estimators=800, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.184) r2: (test=0.848) total time= 3.9min\n",
      "[CV 3/5] END model__colsample_bytree=0.4, model__gamma=0.7777777777777777, model__learning_rate=0.3792690190732246, model__max_depth=3, model__min_child_weight=6.0, model__n_estimators=600, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.186) r2: (test=0.894) total time= 4.0min\n",
      "[CV 5/5] END model__colsample_bytree=1.0, model__gamma=0.0, model__learning_rate=0.012742749857031334, model__max_depth=6, model__min_child_weight=4.0, model__n_estimators=1000, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.168) r2: (test=0.879) total time= 4.8min\n",
      "[CV 3/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.1111111111111111, model__learning_rate=1.0, model__max_depth=5, model__min_child_weight=6.0, model__n_estimators=800, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.185) r2: (test=0.894) total time= 3.9min\n",
      "[CV 5/5] END model__colsample_bytree=0.2, model__gamma=0.1111111111111111, model__learning_rate=0.3792690190732246, model__max_depth=8, model__min_child_weight=3.0, model__n_estimators=300, model__subsample=0.5; neg_mean_absolute_error: (test=-0.171) r2: (test=0.886) total time= 3.8min\n",
      "[CV 3/5] END model__colsample_bytree=0.1, model__gamma=0.6666666666666666, model__learning_rate=0.012742749857031334, model__max_depth=5, model__min_child_weight=9.0, model__n_estimators=600, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.202) r2: (test=0.878) total time= 3.9min\n",
      "[CV 4/5] END model__colsample_bytree=0.1, model__gamma=0.6666666666666666, model__learning_rate=0.012742749857031334, model__max_depth=5, model__min_child_weight=9.0, model__n_estimators=600, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.212) r2: (test=0.829) total time= 3.9min\n",
      "[CV 1/5] END model__colsample_bytree=0.2, model__gamma=0.1111111111111111, model__learning_rate=0.3792690190732246, model__max_depth=8, model__min_child_weight=3.0, model__n_estimators=300, model__subsample=0.5; neg_mean_absolute_error: (test=-0.166) r2: (test=0.889) total time= 3.9min\n",
      "[CV 3/5] END model__colsample_bytree=0.2, model__gamma=0.1111111111111111, model__learning_rate=0.3792690190732246, model__max_depth=8, model__min_child_weight=3.0, model__n_estimators=300, model__subsample=0.5; neg_mean_absolute_error: (test=-0.180) r2: (test=0.900) total time= 3.9min\n",
      "[CV 4/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.6666666666666666, model__learning_rate=0.05455594781168514, model__max_depth=None, model__min_child_weight=3.0, model__n_estimators=200, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.196) r2: (test=0.849) total time= 3.8min\n",
      "[CV 2/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.1111111111111111, model__learning_rate=1.0, model__max_depth=5, model__min_child_weight=6.0, model__n_estimators=800, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.187) r2: (test=0.860) total time= 4.0min\n",
      "[CV 1/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.7777777777777777, model__learning_rate=1.0, model__max_depth=6, model__min_child_weight=10.0, model__n_estimators=500, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.215) r2: (test=0.805) total time= 3.9min\n",
      "[CV 4/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.7777777777777777, model__learning_rate=1.0, model__max_depth=6, model__min_child_weight=10.0, model__n_estimators=500, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.186) r2: (test=0.848) total time= 3.8min\n",
      "[CV 5/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.7777777777777777, model__learning_rate=1.0, model__max_depth=6, model__min_child_weight=10.0, model__n_estimators=500, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.245) r2: (test=0.804) total time= 3.8min\n",
      "[CV 3/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.7777777777777777, model__learning_rate=1.0, model__max_depth=6, model__min_child_weight=10.0, model__n_estimators=500, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.197) r2: (test=0.872) total time= 3.9min\n",
      "[CV 4/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.0, model__learning_rate=0.08858667904100823, model__max_depth=5, model__min_child_weight=1.0, model__n_estimators=600, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.184) r2: (test=0.850) total time= 3.8min\n",
      "[CV 1/5] END model__colsample_bytree=0.1, model__gamma=0.6666666666666666, model__learning_rate=0.012742749857031334, model__max_depth=5, model__min_child_weight=9.0, model__n_estimators=600, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.198) r2: (test=0.846) total time= 4.0min\n",
      "[CV 4/5] END model__colsample_bytree=0.2, model__gamma=0.1111111111111111, model__learning_rate=0.3792690190732246, model__max_depth=8, model__min_child_weight=3.0, model__n_estimators=300, model__subsample=0.5; neg_mean_absolute_error: (test=-0.178) r2: (test=0.864) total time= 4.0min\n",
      "[CV 1/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.6666666666666666, model__learning_rate=0.05455594781168514, model__max_depth=None, model__min_child_weight=3.0, model__n_estimators=200, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.189) r2: (test=0.866) total time= 3.9min\n",
      "[CV 2/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.7777777777777777, model__learning_rate=1.0, model__max_depth=6, model__min_child_weight=10.0, model__n_estimators=500, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.194) r2: (test=0.826) total time= 3.9min\n",
      "[CV 3/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.6666666666666666, model__learning_rate=0.05455594781168514, model__max_depth=None, model__min_child_weight=3.0, model__n_estimators=200, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.190) r2: (test=0.892) total time= 3.9min\n",
      "[CV 3/5] END model__colsample_bytree=0.9, model__gamma=0.0, model__learning_rate=0.14384498882876628, model__max_depth=5, model__min_child_weight=9.0, model__n_estimators=800, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.189) r2: (test=0.857) total time= 3.8min\n",
      "[CV 2/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.0, model__learning_rate=0.08858667904100823, model__max_depth=5, model__min_child_weight=1.0, model__n_estimators=600, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.161) r2: (test=0.889) total time= 3.9min\n",
      "[CV 5/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.6666666666666666, model__learning_rate=0.05455594781168514, model__max_depth=None, model__min_child_weight=3.0, model__n_estimators=200, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.172) r2: (test=0.884) total time= 3.9min\n",
      "[CV 1/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.0, model__learning_rate=0.08858667904100823, model__max_depth=5, model__min_child_weight=1.0, model__n_estimators=600, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.163) r2: (test=0.895) total time= 3.9min\n",
      "[CV 1/5] END model__colsample_bytree=0.2, model__gamma=0.1111111111111111, model__learning_rate=0.05455594781168514, model__max_depth=9, model__min_child_weight=6.0, model__n_estimators=400, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.160) r2: (test=0.896) total time= 3.4min\n",
      "[CV 5/5] END model__colsample_bytree=0.9, model__gamma=0.0, model__learning_rate=0.14384498882876628, model__max_depth=5, model__min_child_weight=9.0, model__n_estimators=800, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.182) r2: (test=0.860) total time= 3.8min\n",
      "[CV 2/5] END model__colsample_bytree=0.9, model__gamma=0.0, model__learning_rate=0.14384498882876628, model__max_depth=5, model__min_child_weight=9.0, model__n_estimators=800, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.167) r2: (test=0.885) total time= 3.9min\n",
      "[CV 5/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.0, model__learning_rate=0.08858667904100823, model__max_depth=5, model__min_child_weight=1.0, model__n_estimators=600, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.180) r2: (test=0.862) total time= 3.9min\n",
      "[CV 3/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.0, model__learning_rate=0.08858667904100823, model__max_depth=5, model__min_child_weight=1.0, model__n_estimators=600, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.187) r2: (test=0.858) total time= 3.9min\n",
      "[CV 4/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.0, model__learning_rate=0.615848211066026, model__max_depth=10, model__min_child_weight=1.0, model__n_estimators=700, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.227) r2: (test=0.779) total time= 4.1min\n",
      "[CV 4/5] END model__colsample_bytree=0.9, model__gamma=0.0, model__learning_rate=0.14384498882876628, model__max_depth=5, model__min_child_weight=9.0, model__n_estimators=800, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.184) r2: (test=0.850) total time= 3.9min\n",
      "[CV 1/5] END model__colsample_bytree=0.9, model__gamma=0.0, model__learning_rate=0.14384498882876628, model__max_depth=5, model__min_child_weight=9.0, model__n_estimators=800, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.167) r2: (test=0.893) total time= 4.0min\n",
      "[CV 3/5] END model__colsample_bytree=0.2, model__gamma=0.1111111111111111, model__learning_rate=0.05455594781168514, model__max_depth=9, model__min_child_weight=6.0, model__n_estimators=400, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.162) r2: (test=0.914) total time= 3.1min\n",
      "[CV 1/5] END model__colsample_bytree=0.6, model__gamma=0.0, model__learning_rate=0.0006951927961775605, model__max_depth=8, model__min_child_weight=1.0, model__n_estimators=500, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.417) r2: (test=0.415) total time= 3.9min\n",
      "[CV 2/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.0, model__learning_rate=0.615848211066026, model__max_depth=10, model__min_child_weight=1.0, model__n_estimators=700, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.196) r2: (test=0.831) total time= 4.2min\n",
      "[CV 2/5] END model__colsample_bytree=0.2, model__gamma=0.1111111111111111, model__learning_rate=0.05455594781168514, model__max_depth=9, model__min_child_weight=6.0, model__n_estimators=400, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.145) r2: (test=0.907) total time= 3.4min\n",
      "[CV 2/5] END model__colsample_bytree=0.6, model__gamma=0.0, model__learning_rate=0.0006951927961775605, model__max_depth=8, model__min_child_weight=1.0, model__n_estimators=500, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.415) r2: (test=0.413) total time= 4.2min\n",
      "[CV 3/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.0, model__learning_rate=0.615848211066026, model__max_depth=10, model__min_child_weight=1.0, model__n_estimators=700, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.217) r2: (test=0.813) total time= 4.6min\n",
      "[CV 4/5] END model__colsample_bytree=0.2, model__gamma=0.1111111111111111, model__learning_rate=0.05455594781168514, model__max_depth=9, model__min_child_weight=6.0, model__n_estimators=400, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.167) r2: (test=0.870) total time= 3.8min\n",
      "[CV 3/5] END model__colsample_bytree=0.6, model__gamma=0.0, model__learning_rate=0.0006951927961775605, model__max_depth=8, model__min_child_weight=1.0, model__n_estimators=500, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.460) r2: (test=0.407) total time= 4.7min\n",
      "[CV 1/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.0, model__learning_rate=0.615848211066026, model__max_depth=10, model__min_child_weight=1.0, model__n_estimators=700, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.271) r2: (test=0.339) total time= 5.3min\n",
      "[CV 4/5] END model__colsample_bytree=0.6, model__gamma=0.0, model__learning_rate=0.0006951927961775605, model__max_depth=8, model__min_child_weight=1.0, model__n_estimators=500, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.424) r2: (test=0.398) total time= 5.9min\n",
      "[CV 5/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.0, model__learning_rate=0.615848211066026, model__max_depth=10, model__min_child_weight=1.0, model__n_estimators=700, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.197) r2: (test=0.823) total time= 6.5min\n",
      "[CV 5/5] END model__colsample_bytree=0.6, model__gamma=0.0, model__learning_rate=0.0006951927961775605, model__max_depth=8, model__min_child_weight=1.0, model__n_estimators=500, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.407) r2: (test=0.424) total time= 6.1min\n",
      "[CV 5/5] END model__colsample_bytree=0.2, model__gamma=0.1111111111111111, model__learning_rate=0.05455594781168514, model__max_depth=9, model__min_child_weight=6.0, model__n_estimators=400, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.159) r2: (test=0.898) total time= 4.4min\n",
      "[CV 5/5] END model__colsample_bytree=0.1, model__gamma=0.8888888888888888, model__learning_rate=0.007847599703514606, model__max_depth=5, model__min_child_weight=8.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.204) r2: (test=0.844) total time= 3.7min\n",
      "[CV 1/5] END model__colsample_bytree=0.1, model__gamma=0.8888888888888888, model__learning_rate=0.007847599703514606, model__max_depth=5, model__min_child_weight=8.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.221) r2: (test=0.811) total time= 3.8min\n",
      "[CV 1/5] END model__colsample_bytree=0.9, model__gamma=0.3333333333333333, model__learning_rate=0.23357214690901212, model__max_depth=3, model__min_child_weight=3.0, model__n_estimators=500, model__subsample=0.5; neg_mean_absolute_error: (test=-0.157) r2: (test=0.895) total time= 3.7min\n",
      "[CV 2/5] END model__colsample_bytree=0.9, model__gamma=0.3333333333333333, model__learning_rate=0.23357214690901212, model__max_depth=3, model__min_child_weight=3.0, model__n_estimators=500, model__subsample=0.5; neg_mean_absolute_error: (test=-0.151) r2: (test=0.896) total time= 3.7min\n",
      "[CV 3/5] END model__colsample_bytree=0.1, model__gamma=0.8888888888888888, model__learning_rate=0.007847599703514606, model__max_depth=5, model__min_child_weight=8.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.226) r2: (test=0.847) total time= 3.8min\n",
      "[CV 3/5] END model__colsample_bytree=0.9, model__gamma=0.3333333333333333, model__learning_rate=0.23357214690901212, model__max_depth=3, model__min_child_weight=3.0, model__n_estimators=500, model__subsample=0.5; neg_mean_absolute_error: (test=-0.165) r2: (test=0.910) total time= 3.7min\n",
      "[CV 2/5] END model__colsample_bytree=1.0, model__gamma=0.2222222222222222, model__learning_rate=0.3792690190732246, model__max_depth=5, model__min_child_weight=4.0, model__n_estimators=900, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.146) r2: (test=0.908) total time= 3.5min\n",
      "[CV 1/5] END model__colsample_bytree=0.9, model__gamma=0.3333333333333333, model__learning_rate=0.0001, model__max_depth=9, model__min_child_weight=9.0, model__n_estimators=600, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.533) r2: (test=0.080) total time= 4.3min\n",
      "[CV 4/5] END model__colsample_bytree=0.1, model__gamma=0.8888888888888888, model__learning_rate=0.007847599703514606, model__max_depth=5, model__min_child_weight=8.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.228) r2: (test=0.807) total time= 3.8min\n",
      "[CV 3/5] END model__colsample_bytree=0.8, model__gamma=0.4444444444444444, model__learning_rate=1.0, model__max_depth=5, model__min_child_weight=4.0, model__n_estimators=500, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.177) r2: (test=0.903) total time= 3.6min\n",
      "[CV 2/5] END model__colsample_bytree=0.1, model__gamma=0.8888888888888888, model__learning_rate=0.007847599703514606, model__max_depth=5, model__min_child_weight=8.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.205) r2: (test=0.850) total time= 3.8min\n",
      "[CV 3/5] END model__colsample_bytree=0.8, model__gamma=0.8888888888888888, model__learning_rate=0.012742749857031334, model__max_depth=10, model__min_child_weight=5.0, model__n_estimators=200, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.213) r2: (test=0.864) total time= 3.7min\n",
      "[CV 1/5] END model__colsample_bytree=0.2, model__gamma=0.6666666666666666, model__learning_rate=0.14384498882876628, model__max_depth=4, model__min_child_weight=1.0, model__n_estimators=300, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.185) r2: (test=0.869) total time= 3.5min\n",
      "[CV 2/5] END model__colsample_bytree=0.9, model__gamma=0.2222222222222222, model__learning_rate=0.0006951927961775605, model__max_depth=5, model__min_child_weight=2.0, model__n_estimators=400, model__subsample=0.5; neg_mean_absolute_error: (test=-0.452) r2: (test=0.302) total time= 3.6min\n",
      "[CV 3/5] END model__colsample_bytree=0.2, model__gamma=0.6666666666666666, model__learning_rate=0.14384498882876628, model__max_depth=4, model__min_child_weight=1.0, model__n_estimators=300, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.178) r2: (test=0.900) total time= 3.5min\n",
      "[CV 4/5] END model__colsample_bytree=0.9, model__gamma=0.3333333333333333, model__learning_rate=0.23357214690901212, model__max_depth=3, model__min_child_weight=3.0, model__n_estimators=500, model__subsample=0.5; neg_mean_absolute_error: (test=-0.175) r2: (test=0.865) total time= 3.8min\n",
      "[CV 2/5] END model__colsample_bytree=0.8, model__gamma=0.8888888888888888, model__learning_rate=0.012742749857031334, model__max_depth=10, model__min_child_weight=5.0, model__n_estimators=200, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.183) r2: (test=0.870) total time= 3.7min\n",
      "[CV 2/5] END model__colsample_bytree=0.8, model__gamma=0.4444444444444444, model__learning_rate=1.0, model__max_depth=5, model__min_child_weight=4.0, model__n_estimators=500, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.181) r2: (test=0.864) total time= 3.6min\n",
      "[CV 5/5] END model__colsample_bytree=0.8, model__gamma=0.8888888888888888, model__learning_rate=0.012742749857031334, model__max_depth=10, model__min_child_weight=5.0, model__n_estimators=200, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.186) r2: (test=0.867) total time= 3.7min\n",
      "[CV 4/5] END model__colsample_bytree=0.8, model__gamma=0.8888888888888888, model__learning_rate=0.012742749857031334, model__max_depth=10, model__min_child_weight=5.0, model__n_estimators=200, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.212) r2: (test=0.824) total time= 3.7min\n",
      "[CV 1/5] END model__colsample_bytree=0.5, model__gamma=0.8888888888888888, model__learning_rate=0.0001623776739188721, model__max_depth=None, model__min_child_weight=8.0, model__n_estimators=800, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.509) r2: (test=0.151) total time= 3.7min\n",
      "[CV 4/5] END model__colsample_bytree=0.8, model__gamma=0.4444444444444444, model__learning_rate=1.0, model__max_depth=5, model__min_child_weight=4.0, model__n_estimators=500, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.192) r2: (test=0.845) total time= 3.6min\n",
      "[CV 5/5] END model__colsample_bytree=0.9, model__gamma=0.3333333333333333, model__learning_rate=0.23357214690901212, model__max_depth=3, model__min_child_weight=3.0, model__n_estimators=500, model__subsample=0.5; neg_mean_absolute_error: (test=-0.178) r2: (test=0.877) total time= 3.8min\n",
      "[CV 5/5] END model__colsample_bytree=0.2, model__gamma=0.6666666666666666, model__learning_rate=0.14384498882876628, model__max_depth=4, model__min_child_weight=1.0, model__n_estimators=300, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.168) r2: (test=0.886) total time= 3.5min\n",
      "[CV 4/5] END model__colsample_bytree=0.2, model__gamma=0.6666666666666666, model__learning_rate=0.14384498882876628, model__max_depth=4, model__min_child_weight=1.0, model__n_estimators=300, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.192) r2: (test=0.848) total time= 3.6min\n",
      "[CV 3/5] END model__colsample_bytree=0.5, model__gamma=0.8888888888888888, model__learning_rate=0.0001623776739188721, model__max_depth=None, model__min_child_weight=8.0, model__n_estimators=800, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.554) r2: (test=0.158) total time= 3.7min\n",
      "[CV 5/5] END model__colsample_bytree=0.9, model__gamma=0.2222222222222222, model__learning_rate=0.0006951927961775605, model__max_depth=5, model__min_child_weight=2.0, model__n_estimators=400, model__subsample=0.5; neg_mean_absolute_error: (test=-0.449) r2: (test=0.304) total time= 3.7min\n",
      "[CV 1/5] END model__colsample_bytree=0.9, model__gamma=0.2222222222222222, model__learning_rate=0.0006951927961775605, model__max_depth=5, model__min_child_weight=2.0, model__n_estimators=400, model__subsample=0.5; neg_mean_absolute_error: (test=-0.459) r2: (test=0.289) total time= 3.7min\n",
      "[CV 1/5] END model__colsample_bytree=0.8, model__gamma=0.8888888888888888, model__learning_rate=0.012742749857031334, model__max_depth=10, model__min_child_weight=5.0, model__n_estimators=200, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.202) r2: (test=0.846) total time= 3.8min\n",
      "[CV 3/5] END model__colsample_bytree=0.9, model__gamma=0.2222222222222222, model__learning_rate=0.0006951927961775605, model__max_depth=5, model__min_child_weight=2.0, model__n_estimators=400, model__subsample=0.5; neg_mean_absolute_error: (test=-0.499) r2: (test=0.304) total time= 3.7min\n",
      "[CV 2/5] END model__colsample_bytree=0.5, model__gamma=0.8888888888888888, model__learning_rate=0.0001623776739188721, model__max_depth=None, model__min_child_weight=8.0, model__n_estimators=800, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.502) r2: (test=0.153) total time= 3.8min\n",
      "[CV 1/5] END model__colsample_bytree=0.8, model__gamma=0.4444444444444444, model__learning_rate=1.0, model__max_depth=5, model__min_child_weight=4.0, model__n_estimators=500, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.183) r2: (test=0.852) total time= 3.7min\n",
      "[CV 1/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.1111111111111111, model__learning_rate=0.23357214690901212, model__max_depth=5, model__min_child_weight=7.0, model__n_estimators=100, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.158) r2: (test=0.893) total time= 3.5min\n",
      "[CV 5/5] END model__colsample_bytree=1.0, model__gamma=0.2222222222222222, model__learning_rate=0.3792690190732246, model__max_depth=5, model__min_child_weight=4.0, model__n_estimators=900, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.164) r2: (test=0.892) total time= 3.6min\n",
      "[CV 4/5] END model__colsample_bytree=0.9, model__gamma=0.3333333333333333, model__learning_rate=0.0001, model__max_depth=9, model__min_child_weight=9.0, model__n_estimators=600, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.533) r2: (test=0.082) total time= 4.0min\n",
      "[CV 4/5] END model__colsample_bytree=1.0, model__gamma=1.0, model__learning_rate=0.0006951927961775605, model__max_depth=5, model__min_child_weight=4.0, model__n_estimators=300, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.482) r2: (test=0.235) total time= 3.5min\n",
      "[CV 2/5] END model__colsample_bytree=0.2, model__gamma=0.6666666666666666, model__learning_rate=0.14384498882876628, model__max_depth=4, model__min_child_weight=1.0, model__n_estimators=300, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.166) r2: (test=0.892) total time= 3.6min\n",
      "[CV 1/5] END model__colsample_bytree=1.0, model__gamma=0.2222222222222222, model__learning_rate=0.3792690190732246, model__max_depth=5, model__min_child_weight=4.0, model__n_estimators=900, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.157) r2: (test=0.900) total time= 3.7min\n",
      "[CV 3/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.1111111111111111, model__learning_rate=0.23357214690901212, model__max_depth=5, model__min_child_weight=7.0, model__n_estimators=100, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.162) r2: (test=0.911) total time= 3.4min\n",
      "[CV 3/5] END model__colsample_bytree=1.0, model__gamma=0.2222222222222222, model__learning_rate=0.3792690190732246, model__max_depth=5, model__min_child_weight=4.0, model__n_estimators=900, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.164) r2: (test=0.908) total time= 3.7min\n",
      "[CV 2/5] END model__colsample_bytree=1.0, model__gamma=1.0, model__learning_rate=0.0006951927961775605, model__max_depth=5, model__min_child_weight=4.0, model__n_estimators=300, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.474) r2: (test=0.241) total time= 3.6min\n",
      "[CV 2/5] END model__colsample_bytree=0.9, model__gamma=0.3333333333333333, model__learning_rate=0.0001, model__max_depth=9, model__min_child_weight=9.0, model__n_estimators=600, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.524) r2: (test=0.081) total time= 4.4min\n",
      "[CV 4/5] END model__colsample_bytree=0.5, model__gamma=0.8888888888888888, model__learning_rate=0.0001623776739188721, model__max_depth=None, model__min_child_weight=8.0, model__n_estimators=800, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.510) r2: (test=0.153) total time= 3.8min\n",
      "[CV 4/5] END model__colsample_bytree=1.0, model__gamma=0.2222222222222222, model__learning_rate=0.3792690190732246, model__max_depth=5, model__min_child_weight=4.0, model__n_estimators=900, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.174) r2: (test=0.867) total time= 3.6min\n",
      "[CV 4/5] END model__colsample_bytree=0.9, model__gamma=0.2222222222222222, model__learning_rate=0.0006951927961775605, model__max_depth=5, model__min_child_weight=2.0, model__n_estimators=400, model__subsample=0.5; neg_mean_absolute_error: (test=-0.460) r2: (test=0.294) total time= 3.8min\n",
      "[CV 2/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.1111111111111111, model__learning_rate=0.23357214690901212, model__max_depth=5, model__min_child_weight=7.0, model__n_estimators=100, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.152) r2: (test=0.899) total time= 3.5min\n",
      "[CV 4/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.1111111111111111, model__learning_rate=0.23357214690901212, model__max_depth=5, model__min_child_weight=7.0, model__n_estimators=100, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.170) r2: (test=0.869) total time= 3.4min\n",
      "[CV 5/5] END model__colsample_bytree=0.8, model__gamma=0.4444444444444444, model__learning_rate=1.0, model__max_depth=5, model__min_child_weight=4.0, model__n_estimators=500, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.213) r2: (test=0.831) total time= 3.7min\n",
      "[CV 1/5] END model__colsample_bytree=1.0, model__gamma=1.0, model__learning_rate=0.0006951927961775605, model__max_depth=5, model__min_child_weight=4.0, model__n_estimators=300, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.481) r2: (test=0.225) total time= 3.6min\n",
      "[CV 5/5] END model__colsample_bytree=0.5, model__gamma=0.8888888888888888, model__learning_rate=0.0001623776739188721, model__max_depth=None, model__min_child_weight=8.0, model__n_estimators=800, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.499) r2: (test=0.161) total time= 3.8min\n",
      "[CV 3/5] END model__colsample_bytree=0.9, model__gamma=0.3333333333333333, model__learning_rate=0.0001, model__max_depth=9, model__min_child_weight=9.0, model__n_estimators=600, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.579) r2: (test=0.086) total time= 4.3min\n",
      "[CV 5/5] END model__colsample_bytree=0.9, model__gamma=0.3333333333333333, model__learning_rate=0.0001, model__max_depth=9, model__min_child_weight=9.0, model__n_estimators=600, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.522) r2: (test=0.087) total time= 4.1min\n",
      "[CV 2/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.1111111111111111, model__learning_rate=0.05455594781168514, model__max_depth=9, model__min_child_weight=6.0, model__n_estimators=700, model__subsample=1.0; neg_mean_absolute_error: (test=-0.150) r2: (test=0.902) total time= 3.1min\n",
      "[CV 5/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.1111111111111111, model__learning_rate=0.23357214690901212, model__max_depth=5, model__min_child_weight=7.0, model__n_estimators=100, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.154) r2: (test=0.903) total time= 3.5min\n",
      "[CV 3/5] END model__colsample_bytree=1.0, model__gamma=1.0, model__learning_rate=0.0006951927961775605, model__max_depth=5, model__min_child_weight=4.0, model__n_estimators=300, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.523) r2: (test=0.242) total time= 3.7min\n",
      "[CV 5/5] END model__colsample_bytree=1.0, model__gamma=1.0, model__learning_rate=0.0006951927961775605, model__max_depth=5, model__min_child_weight=4.0, model__n_estimators=300, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.471) r2: (test=0.242) total time= 3.8min\n",
      "[CV 1/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.1111111111111111, model__learning_rate=0.05455594781168514, model__max_depth=9, model__min_child_weight=6.0, model__n_estimators=700, model__subsample=1.0; neg_mean_absolute_error: (test=-0.166) r2: (test=0.891) total time= 3.4min\n",
      "[CV 3/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.1111111111111111, model__learning_rate=0.05455594781168514, model__max_depth=9, model__min_child_weight=6.0, model__n_estimators=700, model__subsample=1.0; neg_mean_absolute_error: (test=-0.173) r2: (test=0.905) total time= 4.5min\n",
      "[CV 4/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.1111111111111111, model__learning_rate=0.05455594781168514, model__max_depth=9, model__min_child_weight=6.0, model__n_estimators=700, model__subsample=1.0; neg_mean_absolute_error: (test=-0.168) r2: (test=0.872) total time= 5.4min\n",
      "[CV 5/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.1111111111111111, model__learning_rate=0.05455594781168514, model__max_depth=9, model__min_child_weight=6.0, model__n_estimators=700, model__subsample=1.0; neg_mean_absolute_error: (test=-0.164) r2: (test=0.895) total time= 5.5min\n",
      "[CV 1/5] END model__colsample_bytree=1.0, model__gamma=1.0, model__learning_rate=0.00026366508987303583, model__max_depth=10, model__min_child_weight=8.0, model__n_estimators=200, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.536) r2: (test=0.069) total time= 4.6min\n",
      "[CV 2/5] END model__colsample_bytree=1.0, model__gamma=1.0, model__learning_rate=0.00026366508987303583, model__max_depth=10, model__min_child_weight=8.0, model__n_estimators=200, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.525) r2: (test=0.073) total time= 4.5min\n",
      "[CV 4/5] END model__colsample_bytree=0.30000000000000004, model__gamma=1.0, model__learning_rate=0.0206913808111479, model__max_depth=6, model__min_child_weight=4.0, model__n_estimators=100, model__subsample=0.5; neg_mean_absolute_error: (test=-0.249) r2: (test=0.774) total time= 3.7min\n",
      "[CV 3/5] END model__colsample_bytree=1.0, model__gamma=1.0, model__learning_rate=0.00026366508987303583, model__max_depth=10, model__min_child_weight=8.0, model__n_estimators=200, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.582) r2: (test=0.076) total time= 4.3min\n",
      "[CV 5/5] END model__colsample_bytree=0.30000000000000004, model__gamma=1.0, model__learning_rate=0.0206913808111479, model__max_depth=6, model__min_child_weight=4.0, model__n_estimators=100, model__subsample=0.5; neg_mean_absolute_error: (test=-0.223) r2: (test=0.816) total time= 3.7min\n",
      "[CV 2/5] END model__colsample_bytree=0.5, model__gamma=1.0, model__learning_rate=0.3792690190732246, model__max_depth=10, model__min_child_weight=5.0, model__n_estimators=300, model__subsample=0.5; neg_mean_absolute_error: (test=-0.172) r2: (test=0.889) total time= 3.7min\n",
      "[CV 3/5] END model__colsample_bytree=0.30000000000000004, model__gamma=1.0, model__learning_rate=0.0206913808111479, model__max_depth=6, model__min_child_weight=4.0, model__n_estimators=100, model__subsample=0.5; neg_mean_absolute_error: (test=-0.265) r2: (test=0.801) total time= 3.7min\n",
      "[CV 3/5] END model__colsample_bytree=0.4, model__gamma=0.0, model__learning_rate=0.3792690190732246, model__max_depth=4, model__min_child_weight=1.0, model__n_estimators=200, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.189) r2: (test=0.857) total time= 3.7min\n",
      "[CV 5/5] END model__colsample_bytree=0.5, model__gamma=1.0, model__learning_rate=0.3792690190732246, model__max_depth=10, model__min_child_weight=5.0, model__n_estimators=300, model__subsample=0.5; neg_mean_absolute_error: (test=-0.154) r2: (test=0.906) total time= 3.7min\n",
      "[CV 5/5] END model__colsample_bytree=0.9, model__gamma=0.5555555555555556, model__learning_rate=0.23357214690901212, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=600, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.165) r2: (test=0.893) total time= 3.6min\n",
      "[CV 5/5] END model__colsample_bytree=0.4, model__gamma=0.0, model__learning_rate=0.3792690190732246, model__max_depth=4, model__min_child_weight=1.0, model__n_estimators=200, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.194) r2: (test=0.845) total time= 3.7min\n",
      "[CV 4/5] END model__colsample_bytree=0.5, model__gamma=1.0, model__learning_rate=0.3792690190732246, model__max_depth=10, model__min_child_weight=5.0, model__n_estimators=300, model__subsample=0.5; neg_mean_absolute_error: (test=-0.186) r2: (test=0.859) total time= 3.7min\n",
      "[CV 1/5] END model__colsample_bytree=0.4, model__gamma=0.0, model__learning_rate=0.3792690190732246, model__max_depth=4, model__min_child_weight=1.0, model__n_estimators=200, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.172) r2: (test=0.883) total time= 3.7min\n",
      "[CV 4/5] END model__colsample_bytree=0.4, model__gamma=0.0, model__learning_rate=0.3792690190732246, model__max_depth=4, model__min_child_weight=1.0, model__n_estimators=200, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.182) r2: (test=0.852) total time= 3.7min\n",
      "[CV 4/5] END model__colsample_bytree=1.0, model__gamma=1.0, model__learning_rate=0.00026366508987303583, model__max_depth=10, model__min_child_weight=8.0, model__n_estimators=200, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.536) r2: (test=0.073) total time= 4.0min\n",
      "[CV 2/5] END model__colsample_bytree=0.30000000000000004, model__gamma=1.0, model__learning_rate=0.0206913808111479, model__max_depth=6, model__min_child_weight=4.0, model__n_estimators=100, model__subsample=0.5; neg_mean_absolute_error: (test=-0.237) r2: (test=0.800) total time= 3.8min\n",
      "[CV 1/5] END model__colsample_bytree=0.5, model__gamma=1.0, model__learning_rate=0.3792690190732246, model__max_depth=10, model__min_child_weight=5.0, model__n_estimators=300, model__subsample=0.5; neg_mean_absolute_error: (test=-0.202) r2: (test=0.839) total time= 3.7min\n",
      "[CV 3/5] END model__colsample_bytree=0.5, model__gamma=1.0, model__learning_rate=0.3792690190732246, model__max_depth=10, model__min_child_weight=5.0, model__n_estimators=300, model__subsample=0.5; neg_mean_absolute_error: (test=-0.204) r2: (test=0.873) total time= 3.7min\n",
      "[CV 1/5] END model__colsample_bytree=0.30000000000000004, model__gamma=1.0, model__learning_rate=0.0206913808111479, model__max_depth=6, model__min_child_weight=4.0, model__n_estimators=100, model__subsample=0.5; neg_mean_absolute_error: (test=-0.248) r2: (test=0.771) total time= 3.8min\n",
      "[CV 3/5] END model__colsample_bytree=0.9, model__gamma=0.5555555555555556, model__learning_rate=0.23357214690901212, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=600, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.182) r2: (test=0.897) total time= 3.6min\n",
      "[CV 2/5] END model__colsample_bytree=0.4, model__gamma=0.0, model__learning_rate=0.3792690190732246, model__max_depth=4, model__min_child_weight=1.0, model__n_estimators=200, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.175) r2: (test=0.879) total time= 3.7min\n",
      "[CV 5/5] END model__colsample_bytree=0.1, model__gamma=0.8888888888888888, model__learning_rate=0.007847599703514606, model__max_depth=8, model__min_child_weight=9.0, model__n_estimators=500, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.191) r2: (test=0.860) total time= 3.4min\n",
      "[CV 2/5] END model__colsample_bytree=0.9, model__gamma=0.5555555555555556, model__learning_rate=0.23357214690901212, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=600, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.148) r2: (test=0.907) total time= 3.6min\n",
      "[CV 2/5] END model__colsample_bytree=1.0, model__gamma=0.5555555555555556, model__learning_rate=0.004832930238571752, model__max_depth=None, model__min_child_weight=2.0, model__n_estimators=1000, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.160) r2: (test=0.893) total time= 3.7min\n",
      "[CV 4/5] END model__colsample_bytree=1.0, model__gamma=0.0, model__learning_rate=0.05455594781168514, model__max_depth=None, model__min_child_weight=7.0, model__n_estimators=200, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.175) r2: (test=0.865) total time= 3.5min\n",
      "[CV 2/5] END model__colsample_bytree=0.1, model__gamma=0.8888888888888888, model__learning_rate=0.007847599703514606, model__max_depth=8, model__min_child_weight=9.0, model__n_estimators=500, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.189) r2: (test=0.869) total time= 3.5min\n",
      "[CV 4/5] END model__colsample_bytree=0.9, model__gamma=0.5555555555555556, model__learning_rate=0.23357214690901212, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=600, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.178) r2: (test=0.862) total time= 3.6min\n",
      "[CV 5/5] END model__colsample_bytree=1.0, model__gamma=1.0, model__learning_rate=0.00026366508987303583, model__max_depth=10, model__min_child_weight=8.0, model__n_estimators=200, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.525) r2: (test=0.079) total time= 3.9min\n",
      "[CV 3/5] END model__colsample_bytree=1.0, model__gamma=0.0, model__learning_rate=0.05455594781168514, model__max_depth=None, model__min_child_weight=7.0, model__n_estimators=200, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.172) r2: (test=0.897) total time= 3.5min\n",
      "[CV 3/5] END model__colsample_bytree=1.0, model__gamma=0.5555555555555556, model__learning_rate=0.004832930238571752, model__max_depth=None, model__min_child_weight=2.0, model__n_estimators=1000, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.187) r2: (test=0.894) total time= 3.7min\n",
      "[CV 1/5] END model__colsample_bytree=0.1, model__gamma=0.8888888888888888, model__learning_rate=0.007847599703514606, model__max_depth=8, model__min_child_weight=9.0, model__n_estimators=500, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.207) r2: (test=0.833) total time= 3.5min\n",
      "[CV 1/5] END model__colsample_bytree=0.9, model__gamma=0.5555555555555556, model__learning_rate=0.23357214690901212, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=600, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.179) r2: (test=0.877) total time= 3.7min\n",
      "[CV 4/5] END model__colsample_bytree=1.0, model__gamma=0.5555555555555556, model__learning_rate=0.004832930238571752, model__max_depth=None, model__min_child_weight=2.0, model__n_estimators=1000, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.189) r2: (test=0.853) total time= 3.7min\n",
      "[CV 5/5] END model__colsample_bytree=1.0, model__gamma=0.5555555555555556, model__learning_rate=0.004832930238571752, model__max_depth=None, model__min_child_weight=2.0, model__n_estimators=1000, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.169) r2: (test=0.887) total time= 3.7min\n",
      "[CV 3/5] END model__colsample_bytree=0.1, model__gamma=0.8888888888888888, model__learning_rate=0.007847599703514606, model__max_depth=8, model__min_child_weight=9.0, model__n_estimators=500, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.218) r2: (test=0.860) total time= 3.5min\n",
      "[CV 2/5] END model__colsample_bytree=1.0, model__gamma=0.0, model__learning_rate=0.05455594781168514, model__max_depth=None, model__min_child_weight=7.0, model__n_estimators=200, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.151) r2: (test=0.898) total time= 3.6min\n",
      "[CV 4/5] END model__colsample_bytree=0.1, model__gamma=0.8888888888888888, model__learning_rate=0.007847599703514606, model__max_depth=8, model__min_child_weight=9.0, model__n_estimators=500, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.220) r2: (test=0.818) total time= 3.5min\n",
      "[CV 1/5] END model__colsample_bytree=0.4, model__gamma=0.0, model__learning_rate=0.00026366508987303583, model__max_depth=10, model__min_child_weight=2.0, model__n_estimators=600, model__subsample=1.0; neg_mean_absolute_error: (test=-0.488) r2: (test=0.224) total time= 3.9min\n",
      "[CV 1/5] END model__colsample_bytree=1.0, model__gamma=0.0, model__learning_rate=0.05455594781168514, model__max_depth=None, model__min_child_weight=7.0, model__n_estimators=200, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.158) r2: (test=0.899) total time= 3.6min\n",
      "[CV 4/5] END model__colsample_bytree=0.4, model__gamma=0.0, model__learning_rate=0.00026366508987303583, model__max_depth=10, model__min_child_weight=2.0, model__n_estimators=600, model__subsample=1.0; neg_mean_absolute_error: (test=-0.490) r2: (test=0.216) total time= 3.9min\n",
      "[CV 2/5] END model__colsample_bytree=0.4, model__gamma=0.0, model__learning_rate=0.00026366508987303583, model__max_depth=10, model__min_child_weight=2.0, model__n_estimators=600, model__subsample=1.0; neg_mean_absolute_error: (test=-0.482) r2: (test=0.219) total time= 3.9min\n",
      "[CV 1/5] END model__colsample_bytree=0.4, model__gamma=0.7777777777777777, model__learning_rate=0.23357214690901212, model__max_depth=7, model__min_child_weight=4.0, model__n_estimators=100, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.188) r2: (test=0.867) total time= 3.4min\n",
      "[CV 1/5] END model__colsample_bytree=1.0, model__gamma=0.5555555555555556, model__learning_rate=0.004832930238571752, model__max_depth=None, model__min_child_weight=2.0, model__n_estimators=1000, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.181) r2: (test=0.872) total time= 3.8min\n",
      "[CV 1/5] END model__colsample_bytree=0.9, model__gamma=0.7777777777777777, model__learning_rate=0.00026366508987303583, model__max_depth=7, model__min_child_weight=8.0, model__n_estimators=1000, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.449) r2: (test=0.324) total time= 3.8min\n",
      "[CV 5/5] END model__colsample_bytree=1.0, model__gamma=0.0, model__learning_rate=0.05455594781168514, model__max_depth=None, model__min_child_weight=7.0, model__n_estimators=200, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.167) r2: (test=0.881) total time= 3.6min\n",
      "[CV 3/5] END model__colsample_bytree=0.4, model__gamma=0.0, model__learning_rate=0.00026366508987303583, model__max_depth=10, model__min_child_weight=2.0, model__n_estimators=600, model__subsample=1.0; neg_mean_absolute_error: (test=-0.532) r2: (test=0.222) total time= 4.0min\n",
      "[CV 4/5] END model__colsample_bytree=0.9, model__gamma=0.7777777777777777, model__learning_rate=0.00026366508987303583, model__max_depth=7, model__min_child_weight=8.0, model__n_estimators=1000, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.456) r2: (test=0.307) total time= 4.2min\n",
      "[CV 3/5] END model__colsample_bytree=0.9, model__gamma=0.7777777777777777, model__learning_rate=0.00026366508987303583, model__max_depth=7, model__min_child_weight=8.0, model__n_estimators=1000, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.494) r2: (test=0.322) total time= 4.7min\n",
      "[CV 5/5] END model__colsample_bytree=0.9, model__gamma=0.7777777777777777, model__learning_rate=0.00026366508987303583, model__max_depth=7, model__min_child_weight=8.0, model__n_estimators=1000, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.441) r2: (test=0.332) total time= 4.7min\n",
      "[CV 5/5] END model__colsample_bytree=0.4, model__gamma=0.0, model__learning_rate=0.00026366508987303583, model__max_depth=10, model__min_child_weight=2.0, model__n_estimators=600, model__subsample=1.0; neg_mean_absolute_error: (test=-0.477) r2: (test=0.229) total time= 5.1min\n",
      "[CV 1/5] END model__colsample_bytree=1.0, model__gamma=0.5555555555555556, model__learning_rate=0.0001, model__max_depth=7, model__min_child_weight=1.0, model__n_estimators=900, model__subsample=0.5; neg_mean_absolute_error: (test=-0.521) r2: (test=0.112) total time= 5.1min\n",
      "[CV 3/5] END model__colsample_bytree=1.0, model__gamma=0.5555555555555556, model__learning_rate=0.0001, model__max_depth=7, model__min_child_weight=1.0, model__n_estimators=900, model__subsample=0.5; neg_mean_absolute_error: (test=-0.567) r2: (test=0.119) total time= 5.3min\n",
      "[CV 4/5] END model__colsample_bytree=1.0, model__gamma=0.0, model__learning_rate=0.03359818286283781, model__max_depth=8, model__min_child_weight=3.0, model__n_estimators=800, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.184) r2: (test=0.851) total time= 5.5min\n",
      "[CV 4/5] END model__colsample_bytree=1.0, model__gamma=0.5555555555555556, model__learning_rate=0.0001, model__max_depth=7, model__min_child_weight=1.0, model__n_estimators=900, model__subsample=0.5; neg_mean_absolute_error: (test=-0.522) r2: (test=0.117) total time= 5.8min\n",
      "[CV 2/5] END model__colsample_bytree=0.9, model__gamma=0.7777777777777777, model__learning_rate=0.00026366508987303583, model__max_depth=7, model__min_child_weight=8.0, model__n_estimators=1000, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.443) r2: (test=0.334) total time= 5.9min\n",
      "[CV 2/5] END model__colsample_bytree=1.0, model__gamma=0.5555555555555556, model__learning_rate=0.0001, model__max_depth=7, model__min_child_weight=1.0, model__n_estimators=900, model__subsample=0.5; neg_mean_absolute_error: (test=-0.512) r2: (test=0.117) total time= 6.0min\n",
      "[CV 3/5] END model__colsample_bytree=1.0, model__gamma=0.0, model__learning_rate=0.03359818286283781, model__max_depth=8, model__min_child_weight=3.0, model__n_estimators=800, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.189) r2: (test=0.857) total time= 6.0min\n",
      "[CV 2/5] END model__colsample_bytree=1.0, model__gamma=0.0, model__learning_rate=0.03359818286283781, model__max_depth=8, model__min_child_weight=3.0, model__n_estimators=800, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.164) r2: (test=0.887) total time= 6.0min\n",
      "[CV 5/5] END model__colsample_bytree=1.0, model__gamma=0.5555555555555556, model__learning_rate=0.0001, model__max_depth=7, model__min_child_weight=1.0, model__n_estimators=900, model__subsample=0.5; neg_mean_absolute_error: (test=-0.510) r2: (test=0.125) total time= 6.1min\n",
      "[CV 1/5] END model__colsample_bytree=1.0, model__gamma=0.0, model__learning_rate=0.03359818286283781, model__max_depth=8, model__min_child_weight=3.0, model__n_estimators=800, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.162) r2: (test=0.897) total time= 6.2min\n",
      "[CV 5/5] END model__colsample_bytree=1.0, model__gamma=0.0, model__learning_rate=0.03359818286283781, model__max_depth=8, model__min_child_weight=3.0, model__n_estimators=800, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.179) r2: (test=0.862) total time= 6.4min\n",
      "[CV 2/5] END model__colsample_bytree=0.4, model__gamma=0.7777777777777777, model__learning_rate=0.23357214690901212, model__max_depth=7, model__min_child_weight=4.0, model__n_estimators=100, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.174) r2: (test=0.877) total time= 4.6min\n",
      "[CV 3/5] END model__colsample_bytree=0.4, model__gamma=0.7777777777777777, model__learning_rate=0.23357214690901212, model__max_depth=7, model__min_child_weight=4.0, model__n_estimators=100, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.198) r2: (test=0.881) total time= 3.7min\n",
      "[CV 2/5] END model__colsample_bytree=0.1, model__gamma=0.8888888888888888, model__learning_rate=0.00026366508987303583, model__max_depth=7, model__min_child_weight=6.0, model__n_estimators=400, model__subsample=0.5; neg_mean_absolute_error: (test=-0.520) r2: (test=0.093) total time= 3.4min\n",
      "[CV 4/5] END model__colsample_bytree=0.4, model__gamma=0.7777777777777777, model__learning_rate=0.23357214690901212, model__max_depth=7, model__min_child_weight=4.0, model__n_estimators=100, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.192) r2: (test=0.844) total time= 3.5min\n",
      "[CV 2/5] END model__colsample_bytree=0.9, model__gamma=0.6666666666666666, model__learning_rate=0.23357214690901212, model__max_depth=5, model__min_child_weight=1.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.143) r2: (test=0.911) total time= 3.4min\n",
      "[CV 5/5] END model__colsample_bytree=0.1, model__gamma=0.8888888888888888, model__learning_rate=0.00026366508987303583, model__max_depth=7, model__min_child_weight=6.0, model__n_estimators=400, model__subsample=0.5; neg_mean_absolute_error: (test=-0.517) r2: (test=0.104) total time= 3.4min\n",
      "[CV 1/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.4444444444444444, model__learning_rate=0.0001, model__max_depth=7, model__min_child_weight=1.0, model__n_estimators=200, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.552) r2: (test=0.019) total time= 3.4min\n",
      "[CV 5/5] END model__colsample_bytree=0.4, model__gamma=0.7777777777777777, model__learning_rate=0.23357214690901212, model__max_depth=7, model__min_child_weight=4.0, model__n_estimators=100, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.171) r2: (test=0.884) total time= 3.5min\n",
      "[CV 2/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.4444444444444444, model__learning_rate=0.0001, model__max_depth=7, model__min_child_weight=1.0, model__n_estimators=200, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.541) r2: (test=0.018) total time= 3.4min\n",
      "[CV 1/5] END model__colsample_bytree=0.8, model__gamma=0.3333333333333333, model__learning_rate=0.00042813323987193956, model__max_depth=10, model__min_child_weight=5.0, model__n_estimators=300, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.504) r2: (test=0.167) total time= 3.4min\n",
      "[CV 3/5] END model__colsample_bytree=0.9, model__gamma=0.6666666666666666, model__learning_rate=0.23357214690901212, model__max_depth=5, model__min_child_weight=1.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.177) r2: (test=0.899) total time= 3.4min\n",
      "[CV 3/5] END model__colsample_bytree=0.1, model__gamma=0.8888888888888888, model__learning_rate=0.00026366508987303583, model__max_depth=7, model__min_child_weight=6.0, model__n_estimators=400, model__subsample=0.5; neg_mean_absolute_error: (test=-0.575) r2: (test=0.097) total time= 3.5min\n",
      "[CV 1/5] END model__colsample_bytree=0.1, model__gamma=0.8888888888888888, model__learning_rate=0.00026366508987303583, model__max_depth=7, model__min_child_weight=6.0, model__n_estimators=400, model__subsample=0.5; neg_mean_absolute_error: (test=-0.531) r2: (test=0.085) total time= 3.5min\n",
      "[CV 4/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.4444444444444444, model__learning_rate=0.0001, model__max_depth=7, model__min_child_weight=1.0, model__n_estimators=200, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.550) r2: (test=0.027) total time= 3.4min\n",
      "[CV 4/5] END model__colsample_bytree=0.9, model__gamma=0.6666666666666666, model__learning_rate=0.23357214690901212, model__max_depth=5, model__min_child_weight=1.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.183) r2: (test=0.866) total time= 3.5min\n",
      "[CV 3/5] END model__colsample_bytree=0.2, model__gamma=0.4444444444444444, model__learning_rate=0.0018329807108324356, model__max_depth=7, model__min_child_weight=1.0, model__n_estimators=100, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.532) r2: (test=0.224) total time= 3.4min\n",
      "[CV 4/5] END model__colsample_bytree=0.2, model__gamma=0.4444444444444444, model__learning_rate=0.0018329807108324356, model__max_depth=7, model__min_child_weight=1.0, model__n_estimators=100, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.491) r2: (test=0.213) total time= 3.4min\n",
      "[CV 5/5] END model__colsample_bytree=0.9, model__gamma=0.6666666666666666, model__learning_rate=0.23357214690901212, model__max_depth=5, model__min_child_weight=1.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.173) r2: (test=0.888) total time= 3.5min\n",
      "[CV 1/5] END model__colsample_bytree=1.0, model__gamma=0.5555555555555556, model__learning_rate=0.05455594781168514, model__max_depth=8, model__min_child_weight=1.0, model__n_estimators=600, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.174) r2: (test=0.884) total time= 3.4min\n",
      "[CV 1/5] END model__colsample_bytree=0.2, model__gamma=0.4444444444444444, model__learning_rate=0.0018329807108324356, model__max_depth=7, model__min_child_weight=1.0, model__n_estimators=100, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.490) r2: (test=0.213) total time= 3.5min\n",
      "[CV 4/5] END model__colsample_bytree=0.1, model__gamma=0.8888888888888888, model__learning_rate=0.00026366508987303583, model__max_depth=7, model__min_child_weight=6.0, model__n_estimators=400, model__subsample=0.5; neg_mean_absolute_error: (test=-0.529) r2: (test=0.097) total time= 3.5min\n",
      "[CV 5/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.4444444444444444, model__learning_rate=0.0001, model__max_depth=7, model__min_child_weight=1.0, model__n_estimators=200, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.540) r2: (test=0.028) total time= 3.5min\n",
      "[CV 1/5] END model__colsample_bytree=0.9, model__gamma=0.6666666666666666, model__learning_rate=0.23357214690901212, model__max_depth=5, model__min_child_weight=1.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.181) r2: (test=0.870) total time= 3.5min\n",
      "[CV 3/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.4444444444444444, model__learning_rate=0.0001, model__max_depth=7, model__min_child_weight=1.0, model__n_estimators=200, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.598) r2: (test=0.028) total time= 3.5min\n",
      "[CV 3/5] END model__colsample_bytree=0.5, model__gamma=0.1111111111111111, model__learning_rate=0.3792690190732246, model__max_depth=None, model__min_child_weight=8.0, model__n_estimators=100, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.164) r2: (test=0.911) total time= 3.4min\n",
      "[CV 5/5] END model__colsample_bytree=0.2, model__gamma=0.4444444444444444, model__learning_rate=0.0018329807108324356, model__max_depth=7, model__min_child_weight=1.0, model__n_estimators=100, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.477) r2: (test=0.230) total time= 3.5min\n",
      "[CV 2/5] END model__colsample_bytree=0.5, model__gamma=0.1111111111111111, model__learning_rate=0.3792690190732246, model__max_depth=None, model__min_child_weight=8.0, model__n_estimators=100, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.151) r2: (test=0.896) total time= 3.4min\n",
      "[CV 5/5] END model__colsample_bytree=0.8, model__gamma=0.3333333333333333, model__learning_rate=0.00042813323987193956, model__max_depth=10, model__min_child_weight=5.0, model__n_estimators=300, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.494) r2: (test=0.175) total time= 3.5min\n",
      "[CV 2/5] END model__colsample_bytree=0.2, model__gamma=0.4444444444444444, model__learning_rate=0.0018329807108324356, model__max_depth=7, model__min_child_weight=1.0, model__n_estimators=100, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.483) r2: (test=0.216) total time= 3.5min\n",
      "[CV 2/5] END model__colsample_bytree=0.8, model__gamma=0.3333333333333333, model__learning_rate=0.00042813323987193956, model__max_depth=10, model__min_child_weight=5.0, model__n_estimators=300, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.497) r2: (test=0.169) total time= 3.5min\n",
      "[CV 5/5] END model__colsample_bytree=0.5, model__gamma=0.1111111111111111, model__learning_rate=0.3792690190732246, model__max_depth=None, model__min_child_weight=8.0, model__n_estimators=100, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.159) r2: (test=0.901) total time= 3.5min\n",
      "[CV 2/5] END model__colsample_bytree=1.0, model__gamma=0.5555555555555556, model__learning_rate=0.05455594781168514, model__max_depth=8, model__min_child_weight=1.0, model__n_estimators=600, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.152) r2: (test=0.899) total time= 3.5min\n",
      "[CV 2/5] END model__colsample_bytree=0.1, model__gamma=0.0, model__learning_rate=0.00026366508987303583, model__max_depth=8, model__min_child_weight=2.0, model__n_estimators=500, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.504) r2: (test=0.148) total time= 3.5min\n",
      "[CV 3/5] END model__colsample_bytree=0.8, model__gamma=0.3333333333333333, model__learning_rate=0.00042813323987193956, model__max_depth=10, model__min_child_weight=5.0, model__n_estimators=300, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.550) r2: (test=0.168) total time= 3.6min\n",
      "[CV 1/5] END model__colsample_bytree=0.9, model__gamma=0.1111111111111111, model__learning_rate=0.002976351441631319, model__max_depth=3, model__min_child_weight=2.0, model__n_estimators=100, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.485) r2: (test=0.208) total time= 3.5min\n",
      "[CV 1/5] END model__colsample_bytree=0.1, model__gamma=0.0, model__learning_rate=0.00026366508987303583, model__max_depth=8, model__min_child_weight=2.0, model__n_estimators=500, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.514) r2: (test=0.140) total time= 3.5min\n",
      "[CV 4/5] END model__colsample_bytree=0.9, model__gamma=0.1111111111111111, model__learning_rate=0.002976351441631319, model__max_depth=3, model__min_child_weight=2.0, model__n_estimators=100, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.481) r2: (test=0.233) total time= 3.5min\n",
      "[CV 4/5] END model__colsample_bytree=1.0, model__gamma=0.5555555555555556, model__learning_rate=0.05455594781168514, model__max_depth=8, model__min_child_weight=1.0, model__n_estimators=600, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.181) r2: (test=0.859) total time= 3.6min\n",
      "[CV 5/5] END model__colsample_bytree=1.0, model__gamma=0.5555555555555556, model__learning_rate=0.05455594781168514, model__max_depth=8, model__min_child_weight=1.0, model__n_estimators=600, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.163) r2: (test=0.895) total time= 3.6min\n",
      "[CV 4/5] END model__colsample_bytree=0.5, model__gamma=0.1111111111111111, model__learning_rate=0.3792690190732246, model__max_depth=None, model__min_child_weight=8.0, model__n_estimators=100, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.173) r2: (test=0.868) total time= 3.6min\n",
      "[CV 3/5] END model__colsample_bytree=1.0, model__gamma=0.5555555555555556, model__learning_rate=0.05455594781168514, model__max_depth=8, model__min_child_weight=1.0, model__n_estimators=600, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.181) r2: (test=0.900) total time= 3.6min\n",
      "[CV 4/5] END model__colsample_bytree=0.8, model__gamma=0.3333333333333333, model__learning_rate=0.00042813323987193956, model__max_depth=10, model__min_child_weight=5.0, model__n_estimators=300, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.506) r2: (test=0.165) total time= 3.7min\n",
      "[CV 1/5] END model__colsample_bytree=0.5, model__gamma=0.1111111111111111, model__learning_rate=0.3792690190732246, model__max_depth=None, model__min_child_weight=8.0, model__n_estimators=100, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.157) r2: (test=0.895) total time= 3.6min\n",
      "[CV 4/5] END model__colsample_bytree=0.1, model__gamma=0.0, model__learning_rate=0.00026366508987303583, model__max_depth=8, model__min_child_weight=2.0, model__n_estimators=500, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.513) r2: (test=0.150) total time= 3.6min\n",
      "[CV 2/5] END model__colsample_bytree=0.9, model__gamma=0.1111111111111111, model__learning_rate=0.002976351441631319, model__max_depth=3, model__min_child_weight=2.0, model__n_estimators=100, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.474) r2: (test=0.234) total time= 3.6min\n",
      "[CV 3/5] END model__colsample_bytree=0.1, model__gamma=0.0, model__learning_rate=0.00026366508987303583, model__max_depth=8, model__min_child_weight=2.0, model__n_estimators=500, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.558) r2: (test=0.152) total time= 3.7min\n",
      "[CV 5/5] END model__colsample_bytree=0.9, model__gamma=0.1111111111111111, model__learning_rate=0.002976351441631319, model__max_depth=3, model__min_child_weight=2.0, model__n_estimators=100, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.469) r2: (test=0.233) total time= 3.6min\n",
      "[CV 5/5] END model__colsample_bytree=0.1, model__gamma=0.0, model__learning_rate=0.00026366508987303583, model__max_depth=8, model__min_child_weight=2.0, model__n_estimators=500, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.500) r2: (test=0.159) total time= 3.7min\n",
      "[CV 3/5] END model__colsample_bytree=0.9, model__gamma=0.1111111111111111, model__learning_rate=0.002976351441631319, model__max_depth=3, model__min_child_weight=2.0, model__n_estimators=100, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.516) r2: (test=0.246) total time= 3.7min\n",
      "[CV 1/5] END model__colsample_bytree=0.6, model__gamma=0.3333333333333333, model__learning_rate=0.03359818286283781, model__max_depth=3, model__min_child_weight=8.0, model__n_estimators=100, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.209) r2: (test=0.835) total time= 3.3min\n",
      "[CV 2/5] END model__colsample_bytree=0.6, model__gamma=0.3333333333333333, model__learning_rate=0.03359818286283781, model__max_depth=3, model__min_child_weight=8.0, model__n_estimators=100, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.196) r2: (test=0.858) total time= 4.7min\n",
      "[CV 3/5] END model__colsample_bytree=0.6, model__gamma=0.3333333333333333, model__learning_rate=0.03359818286283781, model__max_depth=3, model__min_child_weight=8.0, model__n_estimators=100, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.213) r2: (test=0.863) total time= 4.6min\n",
      "[CV 4/5] END model__colsample_bytree=0.6, model__gamma=0.3333333333333333, model__learning_rate=0.03359818286283781, model__max_depth=3, model__min_child_weight=8.0, model__n_estimators=100, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.220) r2: (test=0.816) total time= 4.3min\n",
      "[CV 5/5] END model__colsample_bytree=0.6, model__gamma=0.3333333333333333, model__learning_rate=0.03359818286283781, model__max_depth=3, model__min_child_weight=8.0, model__n_estimators=100, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.199) r2: (test=0.850) total time= 5.1min\n",
      "[CV 1/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.3333333333333333, model__learning_rate=0.0001623776739188721, model__max_depth=7, model__min_child_weight=3.0, model__n_estimators=500, model__subsample=1.0; neg_mean_absolute_error: (test=-0.524) r2: (test=0.108) total time= 5.3min\n",
      "[CV 5/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.3333333333333333, model__learning_rate=0.0001623776739188721, model__max_depth=7, model__min_child_weight=3.0, model__n_estimators=500, model__subsample=1.0; neg_mean_absolute_error: (test=-0.514) r2: (test=0.115) total time= 4.9min\n",
      "[CV 5/5] END model__colsample_bytree=0.1, model__gamma=0.1111111111111111, model__learning_rate=0.0011288378916846883, model__max_depth=None, model__min_child_weight=9.0, model__n_estimators=500, model__subsample=0.5; neg_mean_absolute_error: (test=-0.412) r2: (test=0.405) total time= 4.4min\n",
      "[CV 4/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.3333333333333333, model__learning_rate=0.0001623776739188721, model__max_depth=7, model__min_child_weight=3.0, model__n_estimators=500, model__subsample=1.0; neg_mean_absolute_error: (test=-0.525) r2: (test=0.109) total time= 5.0min\n",
      "[CV 3/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.3333333333333333, model__learning_rate=0.0001623776739188721, model__max_depth=7, model__min_child_weight=3.0, model__n_estimators=500, model__subsample=1.0; neg_mean_absolute_error: (test=-0.569) r2: (test=0.115) total time= 5.1min\n",
      "[CV 2/5] END model__colsample_bytree=0.1, model__gamma=0.1111111111111111, model__learning_rate=0.0011288378916846883, model__max_depth=None, model__min_child_weight=9.0, model__n_estimators=500, model__subsample=0.5; neg_mean_absolute_error: (test=-0.421) r2: (test=0.396) total time= 4.7min\n",
      "[CV 5/5] END model__colsample_bytree=0.6, model__gamma=0.2222222222222222, model__learning_rate=0.0001623776739188721, model__max_depth=3, model__min_child_weight=3.0, model__n_estimators=300, model__subsample=1.0; neg_mean_absolute_error: (test=-0.535) r2: (test=0.041) total time= 4.3min\n",
      "[CV 2/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.3333333333333333, model__learning_rate=0.0001623776739188721, model__max_depth=7, model__min_child_weight=3.0, model__n_estimators=500, model__subsample=1.0; neg_mean_absolute_error: (test=-0.516) r2: (test=0.104) total time= 5.3min\n",
      "[CV 1/5] END model__colsample_bytree=0.8, model__gamma=0.6666666666666666, model__learning_rate=0.14384498882876628, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=400, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.181) r2: (test=0.876) total time= 4.0min\n",
      "[CV 1/5] END model__colsample_bytree=0.6, model__gamma=0.2222222222222222, model__learning_rate=0.0001623776739188721, model__max_depth=3, model__min_child_weight=3.0, model__n_estimators=300, model__subsample=1.0; neg_mean_absolute_error: (test=-0.547) r2: (test=0.031) total time= 4.4min\n",
      "[CV 1/5] END model__colsample_bytree=0.9, model__gamma=0.2222222222222222, model__learning_rate=0.615848211066026, model__max_depth=8, model__min_child_weight=5.0, model__n_estimators=300, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.159) r2: (test=0.902) total time= 4.1min\n",
      "[CV 2/5] END model__colsample_bytree=0.9, model__gamma=0.2222222222222222, model__learning_rate=0.615848211066026, model__max_depth=8, model__min_child_weight=5.0, model__n_estimators=300, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.160) r2: (test=0.888) total time= 4.1min\n",
      "[CV 2/5] END model__colsample_bytree=0.6, model__gamma=0.2222222222222222, model__learning_rate=0.0001623776739188721, model__max_depth=3, model__min_child_weight=3.0, model__n_estimators=300, model__subsample=1.0; neg_mean_absolute_error: (test=-0.536) r2: (test=0.035) total time= 4.4min\n",
      "[CV 3/5] END model__colsample_bytree=0.6, model__gamma=0.2222222222222222, model__learning_rate=0.0001623776739188721, model__max_depth=3, model__min_child_weight=3.0, model__n_estimators=300, model__subsample=1.0; neg_mean_absolute_error: (test=-0.590) r2: (test=0.047) total time= 4.4min\n",
      "[CV 1/5] END model__colsample_bytree=0.1, model__gamma=0.1111111111111111, model__learning_rate=0.0011288378916846883, model__max_depth=None, model__min_child_weight=9.0, model__n_estimators=500, model__subsample=0.5; neg_mean_absolute_error: (test=-0.428) r2: (test=0.370) total time= 4.8min\n",
      "[CV 3/5] END model__colsample_bytree=0.1, model__gamma=0.1111111111111111, model__learning_rate=0.0011288378916846883, model__max_depth=None, model__min_child_weight=9.0, model__n_estimators=500, model__subsample=0.5; neg_mean_absolute_error: (test=-0.466) r2: (test=0.388) total time= 4.6min\n",
      "[CV 2/5] END model__colsample_bytree=0.2, model__gamma=0.3333333333333333, model__learning_rate=1.0, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.196) r2: (test=0.867) total time= 4.2min\n",
      "[CV 4/5] END model__colsample_bytree=0.2, model__gamma=0.3333333333333333, model__learning_rate=1.0, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.203) r2: (test=0.831) total time= 4.2min\n",
      "[CV 2/5] END model__colsample_bytree=0.6, model__gamma=0.4444444444444444, model__learning_rate=0.0001623776739188721, model__max_depth=3, model__min_child_weight=3.0, model__n_estimators=400, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.532) r2: (test=0.049) total time= 4.2min\n",
      "[CV 3/5] END model__colsample_bytree=0.9, model__gamma=0.2222222222222222, model__learning_rate=0.615848211066026, model__max_depth=8, model__min_child_weight=5.0, model__n_estimators=300, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.160) r2: (test=0.919) total time= 4.1min\n",
      "[CV 1/5] END model__colsample_bytree=0.2, model__gamma=0.3333333333333333, model__learning_rate=1.0, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.182) r2: (test=0.880) total time= 4.3min\n",
      "[CV 5/5] END model__colsample_bytree=0.9, model__gamma=0.2222222222222222, model__learning_rate=0.615848211066026, model__max_depth=8, model__min_child_weight=5.0, model__n_estimators=300, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.166) r2: (test=0.894) total time= 4.1min\n",
      "[CV 3/5] END model__colsample_bytree=0.6, model__gamma=0.4444444444444444, model__learning_rate=0.0001623776739188721, model__max_depth=3, model__min_child_weight=3.0, model__n_estimators=400, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.584) r2: (test=0.062) total time= 4.2min\n",
      "[CV 4/5] END model__colsample_bytree=0.1, model__gamma=0.1111111111111111, model__learning_rate=0.0011288378916846883, model__max_depth=None, model__min_child_weight=9.0, model__n_estimators=500, model__subsample=0.5; neg_mean_absolute_error: (test=-0.426) r2: (test=0.387) total time= 4.6min\n",
      "[CV 4/5] END model__colsample_bytree=0.9, model__gamma=0.2222222222222222, model__learning_rate=0.615848211066026, model__max_depth=8, model__min_child_weight=5.0, model__n_estimators=300, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.175) r2: (test=0.857) total time= 4.1min\n",
      "[CV 3/5] END model__colsample_bytree=0.2, model__gamma=0.3333333333333333, model__learning_rate=1.0, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.200) r2: (test=0.880) total time= 4.2min\n",
      "[CV 5/5] END model__colsample_bytree=0.6, model__gamma=0.4444444444444444, model__learning_rate=0.0001623776739188721, model__max_depth=3, model__min_child_weight=3.0, model__n_estimators=400, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.530) r2: (test=0.056) total time= 4.1min\n",
      "[CV 4/5] END model__colsample_bytree=0.6, model__gamma=0.2222222222222222, model__learning_rate=0.0001623776739188721, model__max_depth=3, model__min_child_weight=3.0, model__n_estimators=300, model__subsample=1.0; neg_mean_absolute_error: (test=-0.545) r2: (test=0.043) total time= 4.4min\n",
      "[CV 4/5] END model__colsample_bytree=0.6, model__gamma=0.2222222222222222, model__learning_rate=0.14384498882876628, model__max_depth=5, model__min_child_weight=7.0, model__n_estimators=500, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.173) r2: (test=0.865) total time= 3.8min\n",
      "[CV 3/5] END model__colsample_bytree=0.6, model__gamma=0.2222222222222222, model__learning_rate=0.14384498882876628, model__max_depth=5, model__min_child_weight=7.0, model__n_estimators=500, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.164) r2: (test=0.911) total time= 3.8min\n",
      "[CV 1/5] END model__colsample_bytree=0.6, model__gamma=0.4444444444444444, model__learning_rate=0.0001623776739188721, model__max_depth=3, model__min_child_weight=3.0, model__n_estimators=400, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.543) r2: (test=0.043) total time= 4.2min\n",
      "[CV 2/5] END model__colsample_bytree=0.8, model__gamma=0.1111111111111111, model__learning_rate=0.14384498882876628, model__max_depth=10, model__min_child_weight=2.0, model__n_estimators=700, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.145) r2: (test=0.900) total time= 4.0min\n",
      "[CV 2/5] END model__colsample_bytree=0.8, model__gamma=0.2222222222222222, model__learning_rate=0.007847599703514606, model__max_depth=8, model__min_child_weight=8.0, model__n_estimators=700, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.151) r2: (test=0.901) total time= 3.9min\n",
      "[CV 2/5] END model__colsample_bytree=0.8, model__gamma=0.6666666666666666, model__learning_rate=0.14384498882876628, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=400, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.158) r2: (test=0.898) total time= 4.1min\n",
      "[CV 5/5] END model__colsample_bytree=0.2, model__gamma=0.3333333333333333, model__learning_rate=1.0, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.218) r2: (test=0.817) total time= 4.2min\n",
      "[CV 4/5] END model__colsample_bytree=0.6, model__gamma=0.4444444444444444, model__learning_rate=0.0001623776739188721, model__max_depth=3, model__min_child_weight=3.0, model__n_estimators=400, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.540) r2: (test=0.058) total time= 4.2min\n",
      "[CV 4/5] END model__colsample_bytree=0.8, model__gamma=0.1111111111111111, model__learning_rate=0.14384498882876628, model__max_depth=10, model__min_child_weight=2.0, model__n_estimators=700, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.161) r2: (test=0.879) total time= 4.0min\n",
      "[CV 3/5] END model__colsample_bytree=0.8, model__gamma=0.1111111111111111, model__learning_rate=0.14384498882876628, model__max_depth=10, model__min_child_weight=2.0, model__n_estimators=700, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.165) r2: (test=0.904) total time= 4.0min\n",
      "[CV 5/5] END model__colsample_bytree=0.8, model__gamma=0.6666666666666666, model__learning_rate=0.14384498882876628, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=400, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.167) r2: (test=0.890) total time= 4.0min\n",
      "[CV 3/5] END model__colsample_bytree=0.8, model__gamma=0.6666666666666666, model__learning_rate=0.14384498882876628, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=400, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.187) r2: (test=0.893) total time= 4.1min\n",
      "[CV 5/5] END model__colsample_bytree=0.8, model__gamma=0.1111111111111111, model__learning_rate=0.14384498882876628, model__max_depth=10, model__min_child_weight=2.0, model__n_estimators=700, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.167) r2: (test=0.885) total time= 3.9min\n",
      "[CV 4/5] END model__colsample_bytree=0.8, model__gamma=0.6666666666666666, model__learning_rate=0.14384498882876628, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=400, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.189) r2: (test=0.848) total time= 4.1min\n",
      "[CV 3/5] END model__colsample_bytree=0.8, model__gamma=0.2222222222222222, model__learning_rate=0.007847599703514606, model__max_depth=8, model__min_child_weight=8.0, model__n_estimators=700, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.174) r2: (test=0.905) total time= 3.9min\n",
      "[CV 5/5] END model__colsample_bytree=0.6, model__gamma=0.2222222222222222, model__learning_rate=0.14384498882876628, model__max_depth=5, model__min_child_weight=7.0, model__n_estimators=500, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.156) r2: (test=0.902) total time= 3.8min\n",
      "[CV 1/5] END model__colsample_bytree=0.6, model__gamma=0.2222222222222222, model__learning_rate=0.14384498882876628, model__max_depth=5, model__min_child_weight=7.0, model__n_estimators=500, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.169) r2: (test=0.888) total time= 3.8min\n",
      "[CV 4/5] END model__colsample_bytree=0.8, model__gamma=0.2222222222222222, model__learning_rate=0.007847599703514606, model__max_depth=8, model__min_child_weight=8.0, model__n_estimators=700, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.174) r2: (test=0.867) total time= 3.9min\n",
      "[CV 2/5] END model__colsample_bytree=1.0, model__gamma=0.2222222222222222, model__learning_rate=0.23357214690901212, model__max_depth=7, model__min_child_weight=10.0, model__n_estimators=500, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.149) r2: (test=0.897) total time= 3.8min\n",
      "[CV 2/5] END model__colsample_bytree=0.6, model__gamma=0.2222222222222222, model__learning_rate=0.14384498882876628, model__max_depth=5, model__min_child_weight=7.0, model__n_estimators=500, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.145) r2: (test=0.904) total time= 3.8min\n",
      "[CV 1/5] END model__colsample_bytree=0.8, model__gamma=0.2222222222222222, model__learning_rate=0.007847599703514606, model__max_depth=8, model__min_child_weight=8.0, model__n_estimators=700, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.166) r2: (test=0.889) total time= 3.9min\n",
      "[CV 4/5] END model__colsample_bytree=1.0, model__gamma=0.2222222222222222, model__learning_rate=0.23357214690901212, model__max_depth=7, model__min_child_weight=10.0, model__n_estimators=500, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.167) r2: (test=0.873) total time= 3.8min\n",
      "[CV 3/5] END model__colsample_bytree=1.0, model__gamma=0.2222222222222222, model__learning_rate=0.23357214690901212, model__max_depth=7, model__min_child_weight=10.0, model__n_estimators=500, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.167) r2: (test=0.910) total time= 3.8min\n",
      "[CV 5/5] END model__colsample_bytree=1.0, model__gamma=0.2222222222222222, model__learning_rate=0.23357214690901212, model__max_depth=7, model__min_child_weight=10.0, model__n_estimators=500, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.168) r2: (test=0.887) total time= 3.8min\n",
      "[CV 5/5] END model__colsample_bytree=0.8, model__gamma=0.2222222222222222, model__learning_rate=0.007847599703514606, model__max_depth=8, model__min_child_weight=8.0, model__n_estimators=700, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.158) r2: (test=0.899) total time= 3.9min\n",
      "[CV 1/5] END model__colsample_bytree=1.0, model__gamma=0.2222222222222222, model__learning_rate=0.23357214690901212, model__max_depth=7, model__min_child_weight=10.0, model__n_estimators=500, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.159) r2: (test=0.891) total time= 3.8min\n",
      "[CV 1/5] END model__colsample_bytree=0.8, model__gamma=0.1111111111111111, model__learning_rate=0.14384498882876628, model__max_depth=10, model__min_child_weight=2.0, model__n_estimators=700, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.158) r2: (test=0.904) total time= 4.0min\n",
      "[CV 2/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.5555555555555556, model__learning_rate=0.004832930238571752, model__max_depth=6, model__min_child_weight=5.0, model__n_estimators=1000, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.162) r2: (test=0.892) total time= 3.8min\n",
      "[CV 1/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.5555555555555556, model__learning_rate=0.004832930238571752, model__max_depth=6, model__min_child_weight=5.0, model__n_estimators=1000, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.184) r2: (test=0.870) total time= 3.8min\n",
      "[CV 4/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.5555555555555556, model__learning_rate=0.004832930238571752, model__max_depth=6, model__min_child_weight=5.0, model__n_estimators=1000, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.190) r2: (test=0.851) total time= 3.5min\n",
      "[CV 3/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.5555555555555556, model__learning_rate=0.004832930238571752, model__max_depth=6, model__min_child_weight=5.0, model__n_estimators=1000, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.190) r2: (test=0.891) total time= 3.7min\n",
      "[CV 5/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.5555555555555556, model__learning_rate=0.004832930238571752, model__max_depth=6, model__min_child_weight=5.0, model__n_estimators=1000, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.170) r2: (test=0.886) total time= 3.5min\n",
      "Fitting took 1922.511s.\n",
      "Best parameters found:\n",
      "model__subsample: 0.7222222222222222\n",
      "model__n_estimators: 700\n",
      "model__min_child_weight: 10.0\n",
      "model__max_depth: 4\n",
      "model__learning_rate: 0.03359818286283781\n",
      "model__gamma: 0.1111111111111111\n",
      "model__colsample_bytree: 0.5\n"
     ]
    }
   ],
   "source": [
    "seed = 4815162342 // 2\n",
    "np.random.seed(seed)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_data, test_size=0.4, random_state=seed)\n",
    "\n",
    "f_select_model = RandomForestRegressor(n_estimators=1000, n_jobs=64, random_state=1234)\n",
    "\n",
    "pipe_random = Pipeline(steps=[\n",
    "    ('preprocess', VarianceThreshold(1e-3)),\n",
    "    ('feature_selection', SelectFromModel(f_select_model, max_features=30)),\n",
    "    ('model', XGBRegressor(n_estimators=500, learning_rate=0.01))\n",
    "])\n",
    "\n",
    "param_dict = {\n",
    "    'model__learning_rate': np.logspace(-4, 0, 20),\n",
    "    'model__subsample': np.linspace(0.5, 1.0, 10),\n",
    "    'model__colsample_bytree': np.linspace(0.1, 1.0, 10),\n",
    "    'model__max_depth': [3, 4, 5, 6, 7, 8, 9, 10, None],\n",
    "    'model__min_child_weight': np.linspace(1, 10, 10),\n",
    "    'model__gamma': np.linspace(0, 1, 10),\n",
    "    'model__n_estimators': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(pipe_random, cv=5, param_distributions=param_dict,\n",
    "                            n_iter=100, n_jobs=64, verbose=3, refit='neg_mean_absolute_error',\n",
    "                            scoring=['neg_mean_absolute_error', 'r2'])\n",
    "\n",
    "t0 = time()\n",
    "print(\"Fitting started...\")\n",
    "search = search.fit(X_train, Y_train)\n",
    "print(f\"Fitting took {time() - t0:0.3f}s.\")\n",
    "\n",
    "best_model = search.best_estimator_\n",
    "\n",
    "print(\"Best parameters found:\")\n",
    "for param, value in search.best_params_.items():\n",
    "    print(f\"{param}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.92936, train MAE: 0.12899\n",
      "Test R^2: 0.90314, test MAE: 0.15338\n"
     ]
    }
   ],
   "source": [
    "Y_pred_train = best_model.predict(X_train)\n",
    "Y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "train_r2 = r2_score(Y_train, Y_pred_train)\n",
    "train_mae = mean_absolute_error(Y_train, Y_pred_train)\n",
    "test_r2 = r2_score(Y_test, Y_pred_test)\n",
    "test_mae = mean_absolute_error(Y_test, Y_pred_test)\n",
    "\n",
    "print(f\"Train R^2: {train_r2:.5f}, train MAE: {train_mae:.5f}\")\n",
    "print(f\"Test R^2: {test_r2:.5f}, test MAE: {test_mae:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for reaction 1_i_1_D: 1.1572\n"
     ]
    }
   ],
   "source": [
    "def predict_ddg(catalyst_id, imine_id, thiol_id, product_id):\n",
    "    if all(id in embeddings for id in [catalyst_id, imine_id, thiol_id, product_id]):\n",
    "        combined_embedding = np.concatenate([\n",
    "            embeddings[catalyst_id],\n",
    "            embeddings[imine_id],\n",
    "            embeddings[thiol_id],\n",
    "            embeddings[product_id]\n",
    "        ])\n",
    "        return best_model.predict([combined_embedding])[0]\n",
    "    else:\n",
    "        return \"One or more components not found in embeddings\"\n",
    "\n",
    "# Example usage\n",
    "example_row = Y_df.iloc[3]\n",
    "print(f\"Prediction for reaction {example_row['reaction_handle']}: \"\n",
    "      f\"{predict_ddg(example_row['catalyst_id'], example_row['imine_id'], example_row['thiol_id'], example_row['product_id']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting results...\n",
      "EQUICAT Prediction\n",
      "Train R^2: 0.92936, train MAE: 0.12899\n",
      "Test R^2: 0.90314, test MAE: 0.15338\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_and_print(estimator, X_train, Y_train, X_test, Y_test, title, verbose=1, file_dpi=800):\n",
    "    predicted_train = estimator.predict(X_train)\n",
    "    r2_train = r2_score(Y_train, predicted_train)\n",
    "    mae_train = mean_absolute_error(Y_train, predicted_train)\n",
    "\n",
    "    predicted_test = estimator.predict(X_test)\n",
    "    r2_test = r2_score(Y_test, predicted_test)\n",
    "    mae_test = mean_absolute_error(Y_test, predicted_test)\n",
    "\n",
    "    if verbose:\n",
    "        print(title)\n",
    "        print(f\"Train R^2: {r2_train:0.5f}, train MAE: {mae_train:0.5f}\")\n",
    "        print(f\"Test R^2: {r2_test:0.5f}, test MAE: {mae_test:0.5f}\")\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    train_plot = ax.scatter(\n",
    "        Y_train,\n",
    "        predicted_train,\n",
    "        color=\"gray\",\n",
    "        label=f\"Train (r2={r2_train:0.3f}, MAE={mae_train:0.3f})\"\n",
    "    )\n",
    "\n",
    "    test_plot = ax.scatter(\n",
    "        Y_test,\n",
    "        predicted_test,\n",
    "        color=\"blue\",\n",
    "        label=f\"Test (r2={r2_test:0.3f}, MAE={mae_test:0.3f})\"\n",
    "    )\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Observed \")\n",
    "    ax.set_ylabel(\"Predicted \")\n",
    "    ax.set_ylim(-3, 3)\n",
    "    ax.set_xlim(-3, 3)\n",
    "        \n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(title + \".png\", dpi=file_dpi)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "# Plot and print results\n",
    "print(\"Plotting results...\")\n",
    "plot_and_print(best_model, X_train, Y_train, X_test, Y_test, \"EQUICAT Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
