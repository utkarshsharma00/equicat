{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel, VarianceThreshold\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from time import time\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded embeddings for 835 entities\n",
      "Sample keys from embeddings: ['54_vi', '177_i', '83_vi', '15_i', '8_i', '73_vi', '134_i', '230_vi', '131_vi', '263_vi', '109_vi', '282_i', '319_i', '1_i', '70_vi', '332_i', '388_vi', '135_vi', '270_i', '394_vi', '276_i', '62_vi', '129_i', '212_vi', '124_vi', '289_i', '331_i', '216_i', '223_vi', '353_i', '341_vi', '80_i', '363_i', '52_vi', '366_i', '365_i', '60_vi', '320_i', '121_i', '324_vi', '285_vi', '151_i', '380_vi', '326_i', '353_vi', '124_i', '338_vi', '254_i', '147_vi', '98_i', '272_i', '286_i', '397_i', '322_vi', '87_vi', '107_i', '312_i', '150_vi', '347_vi', '261_vi', '315_i', '92_i', '120_vi', '186_vi', '103_i', '148_i', '155_i', '362_i', '347_i', '48_i', '122_i', '361_vi', '50_vi', '30_vi', '192_i', '203_i', '16_vi', '244_i', '120_i', '119_vi', '72_i', '44_i', '130_i', '385_vi', '271_i', '12_vi', '402_vi', '303_i', '185_i', '303_vi', '268_vi', '279_i', '392_i', '340_vi', '394_i', '396_i', '198_vi', '33_vi', '358_vi', '114_i', '250_i', '25_i', '200_vi', '301_vi', '56_i', '89_i', '328_vi', '67_i', '182_i', '186_i', '233_i', '324_i', '224_i', '110_vi', '163_vi', '221_vi', '153_vi', '378_vi', '188_vi', '282_vi', '157_i', '284_vi', '231_i', '277_vi', '404_vi', '202_i', '206_vi', '335_i', '247_vi', '82_i', '94_vi', '348_i', '172_vi', '136_vi', '160_i', '393_i', '154_i', '243_i', '93_i', '253_vi', '311_i', '407_i', '175_i', '265_vi', '167_vi', '220_i', '263_i', '265_i', '64_vi', '345_vi', '286_vi', '28_vi', '299_i', '154_vi', '67_vi', '110_i', '143_vi', '207_vi', '312_vi', '22_i', '308_i', '1_vi', '77_vi', '198_i', '235_i', '384_vi', '116_vi', '81_vi', '279_vi', '151_vi', '362_vi', '373_vi', '17_vi', '127_vi', '213_vi', '234_i', '71_vi', '39_vi', '99_vi', '217_vi', '229_i', '173_vi', '84_vi', '96_i', '27_i', '368_vi', '101_vi', '187_vi', '266_vi', '307_i', '156_i', '25_vi', '395_i', '46_i', '284_i', '201_i', '115_vi', '276_vi', '100_vi', '221_i', '65_i', '83_i', '105_vi', '218_vi', '93_vi', '111_vi', '376_vi', '219_vi', '152_vi', '364_i', '409_vi', '333_i', '144_vi', '266_i', '287_i', '348_vi', '163_i', '118_vi', '354_vi', '89_vi', '278_i', '166_i', '354_i', '147_i', '368_i', '59_vi', '106_i', '112_vi', '226_vi', '187_i', '3_i', '174_vi', '24_i', '329_vi', '153_i', '10_vi', '375_vi', '172_i', '295_vi', '36_vi', '175_vi', '351_i', '222_vi', '374_vi', '356_vi', '194_i', '91_i', '138_vi', '269_i', '146_i', '290_i', '269_vi', '173_i', '101_i', '274_i', '267_vi', '352_i', '405_vi', '298_vi', '236_i', '17_i', '409_i', '53_i', '114_vi', '383_vi', '29_i', '307_vi', '182_vi', '57_vi', '216_vi', '397_vi', '391_i', '372_vi', '132_vi', '310_vi', '195_vi', '298_i', '135_i', '193_vi', '16_i', '76_vi', '70_i', '122_vi', '141_vi', '272_vi', '317_i', '123_vi', '157_vi', '160_vi', '199_i', '377_i', '91_vi', '238_i', '78_vi', '140_i', '30_i', '277_i', '271_vi', '134_vi', '40_vi', '223_i', '319_vi', '40_i', '306_vi', '314_i', '273_vi', '229_vi', '145_vi', '389_i', '212_i', '107_vi', '211_i', '18_i', '21_vi', '260_vi', '235_vi', '43_vi', '346_vi', '156_vi', '391_vi', '352_vi', '79_vi', '55_i', '382_i', '280_i', '20_i', '364_vi', '299_vi', '100_i', '169_vi', '204_vi', '399_i', '267_i', '13_i', '228_vi', '337_vi', '257_vi', '297_vi', '49_vi', '142_vi', '389_vi', '254_vi', '246_i', '6_i', '209_vi', '152_i', '53_vi', '204_i', '119_i', '20_vi', '11_vi', '373_i', '281_i', '290_vi', '97_i', '233_vi', '133_vi', '330_i', '41_i', '259_vi', '206_i', '256_i', '181_vi', '357_vi', '191_i', '311_vi', '381_i', '45_vi', '215_vi', '44_vi', '359_vi', '251_i', '164_vi', '128_vi', '68_i', '77_i', '326_vi', '189_vi', '7_i', '359_i', '116_i', '239_vi', '184_i', '387_vi', '248_vi', '393_vi', '310_i', '403_i', '228_i', '401_vi', '158_i', '159_i', '210_i', '33_i', '405_i', '225_vi', '155_vi', '273_i', '377_vi', '304_i', '184_vi', '19_vi', '220_vi', '369_i', '170_i', '55_vi', '85_i', '399_vi', '357_i', '318_i', '238_vi', '39_i', '37_vi', '177_vi', '384_i', '57_i', '278_vi', '351_vi', '123_i', '99_i', '18_vi', '5_i', '372_i', '38_vi', '262_i', '45_i', '29_vi', '19_i', '371_vi', '381_vi', '71_i', '75_i', '295_i', '374_i', '239_i', '203_vi', '117_vi', '210_vi', '244_vi', '291_vi', '196_vi', '105_i', '97_vi', '169_i', '59_i', '390_vi', '383_i', '302_i', '115_i', '2_vi', '246_vi', '330_vi', '293_i', '275_i', '245_i', '82_vi', '213_i', '345_i', '22_vi', '51_i', '240_vi', '80_vi', '360_i', '146_vi', '38_i', '320_vi', '360_vi', '23_i', '85_vi', '31_vi', '250_vi', '242_vi', '363_vi', '112_i', '199_vi', '140_vi', '103_vi', '274_vi', '321_i', '90_vi', '264_i', '74_i', '108_vi', '398_vi', '167_i', '188_i', '142_i', '247_i', '138_i', '95_vi', '164_i', '280_vi', '215_i', '137_vi', '63_vi', '327_vi', '291_i', '334_vi', '338_i', '42_i', '287_vi', '109_i', '289_vi', '118_i', '375_i', '165_vi', '145_i', '297_i', '380_i', '404_i', '132_i', '376_i', '130_vi', '309_i', '208_i', '283_i', '74_vi', '190_i', '50_i', '46_vi', '42_vi', '205_vi', '366_vi', '275_vi', '296_vi', '96_vi', '108_i', '56_vi', '365_vi', '88_vi', '386_i', '159_vi', '26_i', '111_i', '9_i', '316_i', '339_vi', '102_vi', '137_i', '90_i', '370_i', '262_vi', '207_i', '49_i', '325_i', '321_vi', '193_i', '125_i', '48_vi', '23_vi', '168_vi', '323_vi', '313_vi', '382_vi', '197_vi', '32_vi', '211_vi', '87_i', '264_vi', '343_vi', '171_vi', '148_vi', '323_i', '195_i', '356_i', '9_vi', '243_vi', '174_i', '227_i', '73_i', '117_i', '34_vi', '234_vi', '125_vi', '293_vi', '400_i', '302_vi', '313_i', '13_vi', '200_i', '197_i', '222_i', '406_i', '346_i', '231_vi', '98_vi', '14_vi', '81_i', '349_vi', '407_vi', '104_vi', '63_i', '255_i', '270_vi', '106_vi', '342_vi', '6_vi', '4_i', '219_i', '327_i', '7_vi', '218_i', '92_vi', '257_i', '12_i', '104_i', '317_vi', '102_i', '332_vi', '256_vi', '236_vi', '322_i', '176_vi', '2_i', '170_vi', '358_i', '176_i', '294_i', '402_i', '32_i', '300_vi', '361_i', '65_vi', '144_i', '14_i', '217_i', '344_i', '268_i', '408_i', '61_i', '281_vi', '349_i', '392_vi', '209_i', '136_i', '24_vi', '253_i', '191_vi', '41_vi', '94_i', '21_i', '27_vi', '95_i', '35_i', '288_vi', '367_vi', '141_i', '192_vi', '214_vi', '292_vi', '11_i', '258_i', '385_i', '306_i', '408_vi', '47_i', '214_i', '158_vi', '294_vi', '339_i', '406_vi', '301_i', '252_i', '315_vi', '4_vi', '367_i', '355_i', '255_vi', '386_vi', '342_i', '285_i', '292_i', '314_vi', '205_i', '300_i', '43_i', '259_i', '66_vi', '396_vi', '51_vi', '31_i', '66_i', '196_i', '10_i', '139_i', '249_vi', '336_vi', '150_i', '227_vi', '387_i', '325_vi', '3_vi', '232_i', '88_i', '337_i', '344_vi', '252_vi', '318_vi', '355_vi', '251_vi', '309_vi', '128_i', '388_i', '47_vi', '185_vi', '179_i', '127_i', '350_vi', '304_vi', '334_i', '52_i', '370_vi', '331_vi', '86_vi', '400_vi', '226_i', '369_vi', '202_vi', '296_i', '75_vi', '194_vi', '143_i', '162_i', '162_vi', '379_i', '72_vi', '171_i', '129_vi', '371_i', '208_vi', '58_i', '329_i', '131_i', '288_i', '308_vi', '410_i', '343_i', '336_i', '8_vi', '258_vi', '68_vi', '410_vi', '390_i', '36_i', '201_vi', '341_i', '350_i', '232_vi', '61_vi', '121_vi', '333_vi', '28_i', '37_i', '62_i', '5_vi', '249_i', '225_i', '79_i', '248_i', '328_i', '69_vi', '403_vi', '165_i', '113_vi', '76_i', '113_i', '133_i', '261_i', '395_vi', '64_i', '58_vi', '245_vi', '242_i', '340_i', '260_i', '69_i', '240_i', '190_vi', '398_i', '35_vi', '139_vi', '283_vi', '378_i', '230_i', '189_i', '401_i', '78_i', '166_vi', '224_vi', '379_vi', '54_i', '84_i', '316_vi', '34_i', '60_i', '26_vi', '168_i', '86_i', '335_vi', '15_vi', 'C', 'D', 'B', 'A', 'E', '1', '4', '3', '5', '2', '1_C', '1_A', '5_B', '5_E', '4_A', '5_A', '2_A', '2_C', '1_E', '1_B', '5_C', '3_A', '3_D', '4_D', '2_B', '4_E', '3_C', '4_B', '4_C', '2_E', '3_E', '1_D', '3_B', '2_D', '5_D']\n",
      "Loaded Y data with 1075 rows\n",
      "Sample rows from Y_df:\n",
      "  reaction_handle catalyst_id imine_id thiol_id product_id  \\\n",
      "0         1_i_1_A         1_i        1        A        1_A   \n",
      "1         1_i_1_B         1_i        1        B        1_B   \n",
      "2         1_i_1_C         1_i        1        C        1_C   \n",
      "3         1_i_1_D         1_i        1        D        1_D   \n",
      "4         1_i_1_E         1_i        1        E        1_E   \n",
      "\n",
      "   selectivity_ee_percent  selectivity_ddGact_kcal  \n",
      "0                      76                 1.180364  \n",
      "1                      40                 0.501960  \n",
      "2                      50                 0.650844  \n",
      "3                      78                 1.238605  \n",
      "4                      80                 1.301689  \n",
      "Number of missing IDs: 1\n",
      "Sample of missing IDs: ['181_i']\n",
      "All embeddings have consistent size: (192,)\n",
      "\n",
      "Summary:\n",
      "Total embeddings loaded: 835\n",
      "Total rows in Y_df: 1075\n",
      "Total missing IDs: 1\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Function to load embeddings from JSON file and strip family prefix\n",
    "def load_embeddings(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        raw_embeddings = json.load(f)\n",
    "    \n",
    "    # Strip family prefix and convert to numpy arrays\n",
    "    embeddings = {}\n",
    "    family_pattern = re.compile(r'^family\\d+_')\n",
    "    for key, value in raw_embeddings.items():\n",
    "        stripped_key = family_pattern.sub('', key)  # Remove any 'familyX_' prefix\n",
    "        embeddings[stripped_key] = np.array(value)\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "# Load embeddings\n",
    "try:\n",
    "    embeddings = load_embeddings('/Users/utkarsh/MMLI/equicat/develop_op/final_molecule_embeddings.json')\n",
    "    print(f\"Loaded embeddings for {len(embeddings)} entities\")\n",
    "    print(\"Sample keys from embeddings:\", list(embeddings.keys()))\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'embeddings.json' file not found. Please ensure it's in the correct directory.\")\n",
    "    embeddings = {}\n",
    "except Exception as e:\n",
    "    print(f\"Error loading embeddings: {str(e)}\")\n",
    "    embeddings = {}\n",
    "\n",
    "# Load Y data\n",
    "try:\n",
    "    Y_df = pd.read_csv('/Users/utkarsh/MMLI/equicat/science/Y_DATA.csv', dtype={\n",
    "        'catalyst_id': str,\n",
    "        'imine_id': str,\n",
    "        'thiol_id': str,\n",
    "        'product_id': str\n",
    "    })\n",
    "    print(f\"Loaded Y data with {len(Y_df)} rows\")\n",
    "    print(\"Sample rows from Y_df:\")\n",
    "    print(Y_df.head())\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: 'Y_DATA.csv' file not found. Please ensure it's in the correct directory.\")\n",
    "    Y_df = pd.DataFrame()\n",
    "\n",
    "# Check for missing IDs\n",
    "missing_ids = set()\n",
    "for _, row in Y_df.iterrows():\n",
    "    for id_type in ['catalyst_id', 'imine_id', 'thiol_id', 'product_id']:\n",
    "        if row[id_type] not in embeddings:\n",
    "            missing_ids.add(row[id_type])\n",
    "\n",
    "print(f\"Number of missing IDs: {len(missing_ids)}\")\n",
    "print(\"Sample of missing IDs:\", list(missing_ids)[:10] if missing_ids else \"None\")\n",
    "\n",
    "# Additional checks\n",
    "if embeddings:\n",
    "    # Check for consistency in embedding dimensions\n",
    "    embedding_sizes = set(emb.shape for emb in embeddings.values())\n",
    "    if len(embedding_sizes) > 1:\n",
    "        print(\"Warning: Inconsistent embedding sizes detected.\")\n",
    "        print(\"Unique embedding sizes:\", embedding_sizes)\n",
    "    else:\n",
    "        print(f\"All embeddings have consistent size: {next(iter(embedding_sizes))}\")\n",
    "\n",
    "    # Check for any potential data issues\n",
    "    nan_keys = [key for key, emb in embeddings.items() if np.isnan(emb).any()]\n",
    "    inf_keys = [key for key, emb in embeddings.items() if np.isinf(emb).any()]\n",
    "    \n",
    "    if nan_keys:\n",
    "        print(f\"Warning: NaN values found in embeddings for keys: {nan_keys[:10]}\")\n",
    "    if inf_keys:\n",
    "        print(f\"Warning: Inf values found in embeddings for keys: {inf_keys[:10]}\")\n",
    "\n",
    "# Print summary\n",
    "print(\"\\nSummary:\")\n",
    "print(f\"Total embeddings loaded: {len(embeddings)}\")\n",
    "print(f\"Total rows in Y_df: {len(Y_df)}\")\n",
    "print(f\"Total missing IDs: {len(missing_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing embedding for reaction: 181_i_1_A - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_1_B - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_1_C - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_1_D - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_1_E - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_2_A - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_2_B - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_2_C - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_2_D - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_2_E - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_3_A - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_3_B - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_3_C - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_3_D - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_3_E - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_4_A - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_4_B - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_4_C - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_4_D - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_4_E - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_5_A - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_5_B - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_5_C - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_5_D - Missing IDs: ['181_i']\n",
      "Missing embedding for reaction: 181_i_5_E - Missing IDs: ['181_i']\n",
      "Created dataset with 1050 samples and 768 features\n",
      "Sample rows from X_df:\n",
      "        0         1         2         3         4         5         6    \\\n",
      "0  0.059702  0.097801 -0.133508  0.433837 -0.241312  0.284329  0.061268   \n",
      "1  0.059702  0.097801 -0.133508  0.433837 -0.241312  0.284329  0.061268   \n",
      "2  0.059702  0.097801 -0.133508  0.433837 -0.241312  0.284329  0.061268   \n",
      "3  0.059702  0.097801 -0.133508  0.433837 -0.241312  0.284329  0.061268   \n",
      "4  0.059702  0.097801 -0.133508  0.433837 -0.241312  0.284329  0.061268   \n",
      "\n",
      "        7       8         9         10        11       12        13   \\\n",
      "0 -0.360275  0.2159 -0.278718 -0.207204 -0.027256 -0.10759  0.201754   \n",
      "1 -0.360275  0.2159 -0.278718 -0.207204 -0.027256 -0.10759  0.201754   \n",
      "2 -0.360275  0.2159 -0.278718 -0.207204 -0.027256 -0.10759  0.201754   \n",
      "3 -0.360275  0.2159 -0.278718 -0.207204 -0.027256 -0.10759  0.201754   \n",
      "4 -0.360275  0.2159 -0.278718 -0.207204 -0.027256 -0.10759  0.201754   \n",
      "\n",
      "        14        15        16        17        18        19        20   \\\n",
      "0  0.371465  0.367026  0.054596 -0.047462 -0.129077 -0.014236 -0.056233   \n",
      "1  0.371465  0.367026  0.054596 -0.047462 -0.129077 -0.014236 -0.056233   \n",
      "2  0.371465  0.367026  0.054596 -0.047462 -0.129077 -0.014236 -0.056233   \n",
      "3  0.371465  0.367026  0.054596 -0.047462 -0.129077 -0.014236 -0.056233   \n",
      "4  0.371465  0.367026  0.054596 -0.047462 -0.129077 -0.014236 -0.056233   \n",
      "\n",
      "        21       22        23        24        25        26        27   \\\n",
      "0  0.046305  0.26017 -0.255884  0.117071  0.031715  0.062077 -0.202235   \n",
      "1  0.046305  0.26017 -0.255884  0.117071  0.031715  0.062077 -0.202235   \n",
      "2  0.046305  0.26017 -0.255884  0.117071  0.031715  0.062077 -0.202235   \n",
      "3  0.046305  0.26017 -0.255884  0.117071  0.031715  0.062077 -0.202235   \n",
      "4  0.046305  0.26017 -0.255884  0.117071  0.031715  0.062077 -0.202235   \n",
      "\n",
      "        28        29        30        31     32        33        34   \\\n",
      "0 -0.373367  0.225403 -0.125812 -0.128084  0.233  0.129592 -0.041916   \n",
      "1 -0.373367  0.225403 -0.125812 -0.128084  0.233  0.129592 -0.041916   \n",
      "2 -0.373367  0.225403 -0.125812 -0.128084  0.233  0.129592 -0.041916   \n",
      "3 -0.373367  0.225403 -0.125812 -0.128084  0.233  0.129592 -0.041916   \n",
      "4 -0.373367  0.225403 -0.125812 -0.128084  0.233  0.129592 -0.041916   \n",
      "\n",
      "        35        36      37        38        39        40        41   \\\n",
      "0  0.073348  0.240877  0.1688 -0.038025 -0.172315 -0.124472 -0.019201   \n",
      "1  0.073348  0.240877  0.1688 -0.038025 -0.172315 -0.124472 -0.019201   \n",
      "2  0.073348  0.240877  0.1688 -0.038025 -0.172315 -0.124472 -0.019201   \n",
      "3  0.073348  0.240877  0.1688 -0.038025 -0.172315 -0.124472 -0.019201   \n",
      "4  0.073348  0.240877  0.1688 -0.038025 -0.172315 -0.124472 -0.019201   \n",
      "\n",
      "        42        43        44        45        46        47        48   \\\n",
      "0 -0.151991 -0.097632  0.064929 -0.410066  0.363352  0.031726  0.349113   \n",
      "1 -0.151991 -0.097632  0.064929 -0.410066  0.363352  0.031726  0.349113   \n",
      "2 -0.151991 -0.097632  0.064929 -0.410066  0.363352  0.031726  0.349113   \n",
      "3 -0.151991 -0.097632  0.064929 -0.410066  0.363352  0.031726  0.349113   \n",
      "4 -0.151991 -0.097632  0.064929 -0.410066  0.363352  0.031726  0.349113   \n",
      "\n",
      "        49        50        51        52        53        54        55   \\\n",
      "0  0.074807 -0.055627 -0.055334 -0.114275 -0.011503  0.118988 -0.060063   \n",
      "1  0.074807 -0.055627 -0.055334 -0.114275 -0.011503  0.118988 -0.060063   \n",
      "2  0.074807 -0.055627 -0.055334 -0.114275 -0.011503  0.118988 -0.060063   \n",
      "3  0.074807 -0.055627 -0.055334 -0.114275 -0.011503  0.118988 -0.060063   \n",
      "4  0.074807 -0.055627 -0.055334 -0.114275 -0.011503  0.118988 -0.060063   \n",
      "\n",
      "        56       57        58        59        60       61        62   \\\n",
      "0 -0.224802 -0.00177 -0.068026 -0.149758 -0.177054  0.08943  0.232912   \n",
      "1 -0.224802 -0.00177 -0.068026 -0.149758 -0.177054  0.08943  0.232912   \n",
      "2 -0.224802 -0.00177 -0.068026 -0.149758 -0.177054  0.08943  0.232912   \n",
      "3 -0.224802 -0.00177 -0.068026 -0.149758 -0.177054  0.08943  0.232912   \n",
      "4 -0.224802 -0.00177 -0.068026 -0.149758 -0.177054  0.08943  0.232912   \n",
      "\n",
      "        63        64        65        66        67        68        69   \\\n",
      "0 -0.226818 -0.006815  0.175058  0.291354 -0.140475  0.053637 -0.021314   \n",
      "1 -0.226818 -0.006815  0.175058  0.291354 -0.140475  0.053637 -0.021314   \n",
      "2 -0.226818 -0.006815  0.175058  0.291354 -0.140475  0.053637 -0.021314   \n",
      "3 -0.226818 -0.006815  0.175058  0.291354 -0.140475  0.053637 -0.021314   \n",
      "4 -0.226818 -0.006815  0.175058  0.291354 -0.140475  0.053637 -0.021314   \n",
      "\n",
      "        70        71        72       73        74        75       76   \\\n",
      "0  0.312755  0.017258 -0.148343 -0.09097  0.185547 -0.164348 -0.35741   \n",
      "1  0.312755  0.017258 -0.148343 -0.09097  0.185547 -0.164348 -0.35741   \n",
      "2  0.312755  0.017258 -0.148343 -0.09097  0.185547 -0.164348 -0.35741   \n",
      "3  0.312755  0.017258 -0.148343 -0.09097  0.185547 -0.164348 -0.35741   \n",
      "4  0.312755  0.017258 -0.148343 -0.09097  0.185547 -0.164348 -0.35741   \n",
      "\n",
      "        77        78        79        80       81        82        83   \\\n",
      "0  0.324303  0.107182 -0.290727 -0.237524  0.01333 -0.283692  0.105871   \n",
      "1  0.324303  0.107182 -0.290727 -0.237524  0.01333 -0.283692  0.105871   \n",
      "2  0.324303  0.107182 -0.290727 -0.237524  0.01333 -0.283692  0.105871   \n",
      "3  0.324303  0.107182 -0.290727 -0.237524  0.01333 -0.283692  0.105871   \n",
      "4  0.324303  0.107182 -0.290727 -0.237524  0.01333 -0.283692  0.105871   \n",
      "\n",
      "        84       85        86        87        88        89       90   \\\n",
      "0 -0.110244 -0.08585  0.190105  0.110427 -0.361728  0.379517  0.18882   \n",
      "1 -0.110244 -0.08585  0.190105  0.110427 -0.361728  0.379517  0.18882   \n",
      "2 -0.110244 -0.08585  0.190105  0.110427 -0.361728  0.379517  0.18882   \n",
      "3 -0.110244 -0.08585  0.190105  0.110427 -0.361728  0.379517  0.18882   \n",
      "4 -0.110244 -0.08585  0.190105  0.110427 -0.361728  0.379517  0.18882   \n",
      "\n",
      "        91        92        93        94        95        96        97   \\\n",
      "0 -0.045283  0.046627 -0.018546  0.145051  0.013187  0.048796 -0.019762   \n",
      "1 -0.045283  0.046627 -0.018546  0.145051  0.013187  0.048796 -0.019762   \n",
      "2 -0.045283  0.046627 -0.018546  0.145051  0.013187  0.048796 -0.019762   \n",
      "3 -0.045283  0.046627 -0.018546  0.145051  0.013187  0.048796 -0.019762   \n",
      "4 -0.045283  0.046627 -0.018546  0.145051  0.013187  0.048796 -0.019762   \n",
      "\n",
      "        98       99        100       101       102       103       104  \\\n",
      "0  0.082458 -0.07106  0.083862  0.115814  0.163545 -0.026949  0.427256   \n",
      "1  0.082458 -0.07106  0.083862  0.115814  0.163545 -0.026949  0.427256   \n",
      "2  0.082458 -0.07106  0.083862  0.115814  0.163545 -0.026949  0.427256   \n",
      "3  0.082458 -0.07106  0.083862  0.115814  0.163545 -0.026949  0.427256   \n",
      "4  0.082458 -0.07106  0.083862  0.115814  0.163545 -0.026949  0.427256   \n",
      "\n",
      "        105       106       107       108       109       110       111  \\\n",
      "0 -0.229767  0.052396  0.267402 -0.105557 -0.189469  0.101044 -0.243278   \n",
      "1 -0.229767  0.052396  0.267402 -0.105557 -0.189469  0.101044 -0.243278   \n",
      "2 -0.229767  0.052396  0.267402 -0.105557 -0.189469  0.101044 -0.243278   \n",
      "3 -0.229767  0.052396  0.267402 -0.105557 -0.189469  0.101044 -0.243278   \n",
      "4 -0.229767  0.052396  0.267402 -0.105557 -0.189469  0.101044 -0.243278   \n",
      "\n",
      "        112       113       114       115       116       117       118  \\\n",
      "0  0.017574 -0.127785 -0.152757 -0.090199  0.067592 -0.033598 -0.073833   \n",
      "1  0.017574 -0.127785 -0.152757 -0.090199  0.067592 -0.033598 -0.073833   \n",
      "2  0.017574 -0.127785 -0.152757 -0.090199  0.067592 -0.033598 -0.073833   \n",
      "3  0.017574 -0.127785 -0.152757 -0.090199  0.067592 -0.033598 -0.073833   \n",
      "4  0.017574 -0.127785 -0.152757 -0.090199  0.067592 -0.033598 -0.073833   \n",
      "\n",
      "        119       120       121       122       123       124       125  \\\n",
      "0 -0.044983 -0.103245  0.081391  0.225008  0.173095  0.032172  0.186914   \n",
      "1 -0.044983 -0.103245  0.081391  0.225008  0.173095  0.032172  0.186914   \n",
      "2 -0.044983 -0.103245  0.081391  0.225008  0.173095  0.032172  0.186914   \n",
      "3 -0.044983 -0.103245  0.081391  0.225008  0.173095  0.032172  0.186914   \n",
      "4 -0.044983 -0.103245  0.081391  0.225008  0.173095  0.032172  0.186914   \n",
      "\n",
      "        126      127       128      129      130       131       132      133  \\\n",
      "0 -0.013753  0.28171  0.195421  0.00051 -0.20219  0.522948  0.213933  0.01303   \n",
      "1 -0.013753  0.28171  0.195421  0.00051 -0.20219  0.522948  0.213933  0.01303   \n",
      "2 -0.013753  0.28171  0.195421  0.00051 -0.20219  0.522948  0.213933  0.01303   \n",
      "3 -0.013753  0.28171  0.195421  0.00051 -0.20219  0.522948  0.213933  0.01303   \n",
      "4 -0.013753  0.28171  0.195421  0.00051 -0.20219  0.522948  0.213933  0.01303   \n",
      "\n",
      "        134       135       136       137       138       139       140  \\\n",
      "0  0.149428 -0.021461 -0.041844  0.084554  0.159248  0.246548  0.227308   \n",
      "1  0.149428 -0.021461 -0.041844  0.084554  0.159248  0.246548  0.227308   \n",
      "2  0.149428 -0.021461 -0.041844  0.084554  0.159248  0.246548  0.227308   \n",
      "3  0.149428 -0.021461 -0.041844  0.084554  0.159248  0.246548  0.227308   \n",
      "4  0.149428 -0.021461 -0.041844  0.084554  0.159248  0.246548  0.227308   \n",
      "\n",
      "        141       142       143      144       145      146       147  \\\n",
      "0 -0.073524  0.037301 -0.050774 -0.09617  0.137807  0.03773  0.128621   \n",
      "1 -0.073524  0.037301 -0.050774 -0.09617  0.137807  0.03773  0.128621   \n",
      "2 -0.073524  0.037301 -0.050774 -0.09617  0.137807  0.03773  0.128621   \n",
      "3 -0.073524  0.037301 -0.050774 -0.09617  0.137807  0.03773  0.128621   \n",
      "4 -0.073524  0.037301 -0.050774 -0.09617  0.137807  0.03773  0.128621   \n",
      "\n",
      "        148       149       150       151       152       153       154  \\\n",
      "0  0.013069  0.278068  0.021593 -0.159386  0.099384 -0.005634  0.214963   \n",
      "1  0.013069  0.278068  0.021593 -0.159386  0.099384 -0.005634  0.214963   \n",
      "2  0.013069  0.278068  0.021593 -0.159386  0.099384 -0.005634  0.214963   \n",
      "3  0.013069  0.278068  0.021593 -0.159386  0.099384 -0.005634  0.214963   \n",
      "4  0.013069  0.278068  0.021593 -0.159386  0.099384 -0.005634  0.214963   \n",
      "\n",
      "        155       156       157       158       159       160       161  \\\n",
      "0  0.076524  0.101378  0.167185 -0.067168 -0.143393 -0.167686  0.080895   \n",
      "1  0.076524  0.101378  0.167185 -0.067168 -0.143393 -0.167686  0.080895   \n",
      "2  0.076524  0.101378  0.167185 -0.067168 -0.143393 -0.167686  0.080895   \n",
      "3  0.076524  0.101378  0.167185 -0.067168 -0.143393 -0.167686  0.080895   \n",
      "4  0.076524  0.101378  0.167185 -0.067168 -0.143393 -0.167686  0.080895   \n",
      "\n",
      "        162       163      164       165       166       167       168  \\\n",
      "0  0.325542  0.034741  0.05892  0.162684  0.130835  0.327625  0.046696   \n",
      "1  0.325542  0.034741  0.05892  0.162684  0.130835  0.327625  0.046696   \n",
      "2  0.325542  0.034741  0.05892  0.162684  0.130835  0.327625  0.046696   \n",
      "3  0.325542  0.034741  0.05892  0.162684  0.130835  0.327625  0.046696   \n",
      "4  0.325542  0.034741  0.05892  0.162684  0.130835  0.327625  0.046696   \n",
      "\n",
      "        169       170       171       172      173       174       175  \\\n",
      "0  0.253608  0.729479  0.175139 -0.166338 -0.25341 -0.206609 -0.280869   \n",
      "1  0.253608  0.729479  0.175139 -0.166338 -0.25341 -0.206609 -0.280869   \n",
      "2  0.253608  0.729479  0.175139 -0.166338 -0.25341 -0.206609 -0.280869   \n",
      "3  0.253608  0.729479  0.175139 -0.166338 -0.25341 -0.206609 -0.280869   \n",
      "4  0.253608  0.729479  0.175139 -0.166338 -0.25341 -0.206609 -0.280869   \n",
      "\n",
      "        176       177       178       179       180       181       182  \\\n",
      "0  0.084485 -0.209598 -0.196896  0.163695 -0.336955  0.178987 -0.110857   \n",
      "1  0.084485 -0.209598 -0.196896  0.163695 -0.336955  0.178987 -0.110857   \n",
      "2  0.084485 -0.209598 -0.196896  0.163695 -0.336955  0.178987 -0.110857   \n",
      "3  0.084485 -0.209598 -0.196896  0.163695 -0.336955  0.178987 -0.110857   \n",
      "4  0.084485 -0.209598 -0.196896  0.163695 -0.336955  0.178987 -0.110857   \n",
      "\n",
      "        183       184       185       186      187       188       189  \\\n",
      "0 -0.305137 -0.070185  0.096085 -0.444327  0.31024  0.109652  0.231367   \n",
      "1 -0.305137 -0.070185  0.096085 -0.444327  0.31024  0.109652  0.231367   \n",
      "2 -0.305137 -0.070185  0.096085 -0.444327  0.31024  0.109652  0.231367   \n",
      "3 -0.305137 -0.070185  0.096085 -0.444327  0.31024  0.109652  0.231367   \n",
      "4 -0.305137 -0.070185  0.096085 -0.444327  0.31024  0.109652  0.231367   \n",
      "\n",
      "        190       191       192       193       194       195       196  \\\n",
      "0 -0.271001 -0.234838 -0.128222  0.360285  0.218228 -0.035759  0.167678   \n",
      "1 -0.271001 -0.234838 -0.128222  0.360285  0.218228 -0.035759  0.167678   \n",
      "2 -0.271001 -0.234838 -0.128222  0.360285  0.218228 -0.035759  0.167678   \n",
      "3 -0.271001 -0.234838 -0.128222  0.360285  0.218228 -0.035759  0.167678   \n",
      "4 -0.271001 -0.234838 -0.128222  0.360285  0.218228 -0.035759  0.167678   \n",
      "\n",
      "        197       198       199       200       201      202       203  \\\n",
      "0 -0.039883  0.065422  0.135604 -0.057472 -0.472612 -0.01056 -0.220713   \n",
      "1 -0.039883  0.065422  0.135604 -0.057472 -0.472612 -0.01056 -0.220713   \n",
      "2 -0.039883  0.065422  0.135604 -0.057472 -0.472612 -0.01056 -0.220713   \n",
      "3 -0.039883  0.065422  0.135604 -0.057472 -0.472612 -0.01056 -0.220713   \n",
      "4 -0.039883  0.065422  0.135604 -0.057472 -0.472612 -0.01056 -0.220713   \n",
      "\n",
      "        204       205      206       207       208       209       210  \\\n",
      "0  0.303621 -0.023525 -0.10078  0.208469  0.145895 -0.176284  0.311861   \n",
      "1  0.303621 -0.023525 -0.10078  0.208469  0.145895 -0.176284  0.311861   \n",
      "2  0.303621 -0.023525 -0.10078  0.208469  0.145895 -0.176284  0.311861   \n",
      "3  0.303621 -0.023525 -0.10078  0.208469  0.145895 -0.176284  0.311861   \n",
      "4  0.303621 -0.023525 -0.10078  0.208469  0.145895 -0.176284  0.311861   \n",
      "\n",
      "        211       212       213       214       215       216      217  \\\n",
      "0  0.054537 -0.064728 -0.152545  0.613019  0.038621 -0.442664  0.39888   \n",
      "1  0.054537 -0.064728 -0.152545  0.613019  0.038621 -0.442664  0.39888   \n",
      "2  0.054537 -0.064728 -0.152545  0.613019  0.038621 -0.442664  0.39888   \n",
      "3  0.054537 -0.064728 -0.152545  0.613019  0.038621 -0.442664  0.39888   \n",
      "4  0.054537 -0.064728 -0.152545  0.613019  0.038621 -0.442664  0.39888   \n",
      "\n",
      "       218       219       220       221       222       223       224  \\\n",
      "0 -0.36079 -0.536162 -0.222888  0.132616  0.092065 -0.502154 -0.070784   \n",
      "1 -0.36079 -0.536162 -0.222888  0.132616  0.092065 -0.502154 -0.070784   \n",
      "2 -0.36079 -0.536162 -0.222888  0.132616  0.092065 -0.502154 -0.070784   \n",
      "3 -0.36079 -0.536162 -0.222888  0.132616  0.092065 -0.502154 -0.070784   \n",
      "4 -0.36079 -0.536162 -0.222888  0.132616  0.092065 -0.502154 -0.070784   \n",
      "\n",
      "        225       226       227       228       229       230       231  \\\n",
      "0 -0.192442 -0.271141  0.076571  0.126125  0.101447 -0.069848 -0.090967   \n",
      "1 -0.192442 -0.271141  0.076571  0.126125  0.101447 -0.069848 -0.090967   \n",
      "2 -0.192442 -0.271141  0.076571  0.126125  0.101447 -0.069848 -0.090967   \n",
      "3 -0.192442 -0.271141  0.076571  0.126125  0.101447 -0.069848 -0.090967   \n",
      "4 -0.192442 -0.271141  0.076571  0.126125  0.101447 -0.069848 -0.090967   \n",
      "\n",
      "        232       233       234       235       236       237       238  \\\n",
      "0 -0.123262 -0.038942  0.135719 -0.174894 -0.225187 -0.190187  0.010882   \n",
      "1 -0.123262 -0.038942  0.135719 -0.174894 -0.225187 -0.190187  0.010882   \n",
      "2 -0.123262 -0.038942  0.135719 -0.174894 -0.225187 -0.190187  0.010882   \n",
      "3 -0.123262 -0.038942  0.135719 -0.174894 -0.225187 -0.190187  0.010882   \n",
      "4 -0.123262 -0.038942  0.135719 -0.174894 -0.225187 -0.190187  0.010882   \n",
      "\n",
      "        239       240       241       242       243      244       245  \\\n",
      "0  0.403052 -0.017271 -0.093454 -0.056886  0.128922 -0.20247  0.112095   \n",
      "1  0.403052 -0.017271 -0.093454 -0.056886  0.128922 -0.20247  0.112095   \n",
      "2  0.403052 -0.017271 -0.093454 -0.056886  0.128922 -0.20247  0.112095   \n",
      "3  0.403052 -0.017271 -0.093454 -0.056886  0.128922 -0.20247  0.112095   \n",
      "4  0.403052 -0.017271 -0.093454 -0.056886  0.128922 -0.20247  0.112095   \n",
      "\n",
      "       246       247       248       249     250       251       252  \\\n",
      "0 -0.09949 -0.364957 -0.182224 -0.025327  0.4166  0.334075  0.155321   \n",
      "1 -0.09949 -0.364957 -0.182224 -0.025327  0.4166  0.334075  0.155321   \n",
      "2 -0.09949 -0.364957 -0.182224 -0.025327  0.4166  0.334075  0.155321   \n",
      "3 -0.09949 -0.364957 -0.182224 -0.025327  0.4166  0.334075  0.155321   \n",
      "4 -0.09949 -0.364957 -0.182224 -0.025327  0.4166  0.334075  0.155321   \n",
      "\n",
      "        253       254       255       256       257       258       259  \\\n",
      "0  0.028687 -0.314933 -0.019461 -0.318352  0.072335  0.013883 -0.197759   \n",
      "1  0.028687 -0.314933 -0.019461 -0.318352  0.072335  0.013883 -0.197759   \n",
      "2  0.028687 -0.314933 -0.019461 -0.318352  0.072335  0.013883 -0.197759   \n",
      "3  0.028687 -0.314933 -0.019461 -0.318352  0.072335  0.013883 -0.197759   \n",
      "4  0.028687 -0.314933 -0.019461 -0.318352  0.072335  0.013883 -0.197759   \n",
      "\n",
      "        260       261      262       263       264       265       266  \\\n",
      "0  0.290062 -0.014262  0.21637  0.070702  0.234687  0.068988 -0.522282   \n",
      "1  0.290062 -0.014262  0.21637  0.070702  0.234687  0.068988 -0.522282   \n",
      "2  0.290062 -0.014262  0.21637  0.070702  0.234687  0.068988 -0.522282   \n",
      "3  0.290062 -0.014262  0.21637  0.070702  0.234687  0.068988 -0.522282   \n",
      "4  0.290062 -0.014262  0.21637  0.070702  0.234687  0.068988 -0.522282   \n",
      "\n",
      "        267       268       269       270       271      272       273  \\\n",
      "0 -0.187031  0.350003  0.242503  0.065115 -0.071536 -0.24999  0.285111   \n",
      "1 -0.187031  0.350003  0.242503  0.065115 -0.071536 -0.24999  0.285111   \n",
      "2 -0.187031  0.350003  0.242503  0.065115 -0.071536 -0.24999  0.285111   \n",
      "3 -0.187031  0.350003  0.242503  0.065115 -0.071536 -0.24999  0.285111   \n",
      "4 -0.187031  0.350003  0.242503  0.065115 -0.071536 -0.24999  0.285111   \n",
      "\n",
      "        274       275       276       277       278     279      280      281  \\\n",
      "0  0.407933 -0.215751 -0.299714 -0.184689 -0.528956 -0.2798  0.35521  0.07986   \n",
      "1  0.407933 -0.215751 -0.299714 -0.184689 -0.528956 -0.2798  0.35521  0.07986   \n",
      "2  0.407933 -0.215751 -0.299714 -0.184689 -0.528956 -0.2798  0.35521  0.07986   \n",
      "3  0.407933 -0.215751 -0.299714 -0.184689 -0.528956 -0.2798  0.35521  0.07986   \n",
      "4  0.407933 -0.215751 -0.299714 -0.184689 -0.528956 -0.2798  0.35521  0.07986   \n",
      "\n",
      "        282       283       284       285       286       287       288  \\\n",
      "0 -0.249624 -0.390522 -0.245494  0.076036  0.144014 -0.272659  0.065805   \n",
      "1 -0.249624 -0.390522 -0.245494  0.076036  0.144014 -0.272659  0.065805   \n",
      "2 -0.249624 -0.390522 -0.245494  0.076036  0.144014 -0.272659  0.065805   \n",
      "3 -0.249624 -0.390522 -0.245494  0.076036  0.144014 -0.272659  0.065805   \n",
      "4 -0.249624 -0.390522 -0.245494  0.076036  0.144014 -0.272659  0.065805   \n",
      "\n",
      "        289       290      291       292       293       294       295  \\\n",
      "0  0.125176 -0.075168  0.03894 -0.838664  0.079776  0.139106 -0.150014   \n",
      "1  0.125176 -0.075168  0.03894 -0.838664  0.079776  0.139106 -0.150014   \n",
      "2  0.125176 -0.075168  0.03894 -0.838664  0.079776  0.139106 -0.150014   \n",
      "3  0.125176 -0.075168  0.03894 -0.838664  0.079776  0.139106 -0.150014   \n",
      "4  0.125176 -0.075168  0.03894 -0.838664  0.079776  0.139106 -0.150014   \n",
      "\n",
      "        296       297      298       299       300       301       302  \\\n",
      "0  0.016471  0.068909 -0.04889  0.745264  0.100816 -0.024083  0.254466   \n",
      "1  0.016471  0.068909 -0.04889  0.745264  0.100816 -0.024083  0.254466   \n",
      "2  0.016471  0.068909 -0.04889  0.745264  0.100816 -0.024083  0.254466   \n",
      "3  0.016471  0.068909 -0.04889  0.745264  0.100816 -0.024083  0.254466   \n",
      "4  0.016471  0.068909 -0.04889  0.745264  0.100816 -0.024083  0.254466   \n",
      "\n",
      "        303       304       305       306       307       308       309  \\\n",
      "0 -0.329108 -0.391167  0.046859  0.328923  0.369584 -0.115401  0.337694   \n",
      "1 -0.329108 -0.391167  0.046859  0.328923  0.369584 -0.115401  0.337694   \n",
      "2 -0.329108 -0.391167  0.046859  0.328923  0.369584 -0.115401  0.337694   \n",
      "3 -0.329108 -0.391167  0.046859  0.328923  0.369584 -0.115401  0.337694   \n",
      "4 -0.329108 -0.391167  0.046859  0.328923  0.369584 -0.115401  0.337694   \n",
      "\n",
      "        310       311       312       313       314       315       316  \\\n",
      "0  0.132871 -0.061383 -0.014353  0.534793 -0.293491  0.140201 -0.113866   \n",
      "1  0.132871 -0.061383 -0.014353  0.534793 -0.293491  0.140201 -0.113866   \n",
      "2  0.132871 -0.061383 -0.014353  0.534793 -0.293491  0.140201 -0.113866   \n",
      "3  0.132871 -0.061383 -0.014353  0.534793 -0.293491  0.140201 -0.113866   \n",
      "4  0.132871 -0.061383 -0.014353  0.534793 -0.293491  0.140201 -0.113866   \n",
      "\n",
      "        317       318       319       320       321       322       323  \\\n",
      "0 -0.126543 -0.386856 -0.037366 -0.301225  0.413762 -0.058374  0.088823   \n",
      "1 -0.126543 -0.386856 -0.037366 -0.301225  0.413762 -0.058374  0.088823   \n",
      "2 -0.126543 -0.386856 -0.037366 -0.301225  0.413762 -0.058374  0.088823   \n",
      "3 -0.126543 -0.386856 -0.037366 -0.301225  0.413762 -0.058374  0.088823   \n",
      "4 -0.126543 -0.386856 -0.037366 -0.301225  0.413762 -0.058374  0.088823   \n",
      "\n",
      "        324       325       326       327       328       329       330  \\\n",
      "0 -0.176258  0.654107  0.149328  0.059822  0.182614 -0.340799 -0.044868   \n",
      "1 -0.176258  0.654107  0.149328  0.059822  0.182614 -0.340799 -0.044868   \n",
      "2 -0.176258  0.654107  0.149328  0.059822  0.182614 -0.340799 -0.044868   \n",
      "3 -0.176258  0.654107  0.149328  0.059822  0.182614 -0.340799 -0.044868   \n",
      "4 -0.176258  0.654107  0.149328  0.059822  0.182614 -0.340799 -0.044868   \n",
      "\n",
      "        331       332       333       334       335       336       337  \\\n",
      "0 -0.149339  0.037009 -0.065774  0.353375 -0.264494 -0.219562 -0.176395   \n",
      "1 -0.149339  0.037009 -0.065774  0.353375 -0.264494 -0.219562 -0.176395   \n",
      "2 -0.149339  0.037009 -0.065774  0.353375 -0.264494 -0.219562 -0.176395   \n",
      "3 -0.149339  0.037009 -0.065774  0.353375 -0.264494 -0.219562 -0.176395   \n",
      "4 -0.149339  0.037009 -0.065774  0.353375 -0.264494 -0.219562 -0.176395   \n",
      "\n",
      "        338       339       340       341       342       343       344  \\\n",
      "0  0.087554 -0.370701 -0.170382  0.218103  0.011778 -0.431525  0.146278   \n",
      "1  0.087554 -0.370701 -0.170382  0.218103  0.011778 -0.431525  0.146278   \n",
      "2  0.087554 -0.370701 -0.170382  0.218103  0.011778 -0.431525  0.146278   \n",
      "3  0.087554 -0.370701 -0.170382  0.218103  0.011778 -0.431525  0.146278   \n",
      "4  0.087554 -0.370701 -0.170382  0.218103  0.011778 -0.431525  0.146278   \n",
      "\n",
      "        345       346      347       348       349       350       351  \\\n",
      "0  0.070232  0.054128  0.13274  0.134886  0.169073  0.031976 -0.022907   \n",
      "1  0.070232  0.054128  0.13274  0.134886  0.169073  0.031976 -0.022907   \n",
      "2  0.070232  0.054128  0.13274  0.134886  0.169073  0.031976 -0.022907   \n",
      "3  0.070232  0.054128  0.13274  0.134886  0.169073  0.031976 -0.022907   \n",
      "4  0.070232  0.054128  0.13274  0.134886  0.169073  0.031976 -0.022907   \n",
      "\n",
      "        352       353       354      355     356       357       358  \\\n",
      "0  0.017253  0.086656 -0.206048 -0.18228 -0.0363 -0.166411 -0.076478   \n",
      "1  0.017253  0.086656 -0.206048 -0.18228 -0.0363 -0.166411 -0.076478   \n",
      "2  0.017253  0.086656 -0.206048 -0.18228 -0.0363 -0.166411 -0.076478   \n",
      "3  0.017253  0.086656 -0.206048 -0.18228 -0.0363 -0.166411 -0.076478   \n",
      "4  0.017253  0.086656 -0.206048 -0.18228 -0.0363 -0.166411 -0.076478   \n",
      "\n",
      "        359       360       361       362       363       364       365  \\\n",
      "0 -0.015374  0.180042 -0.160943  0.122516 -0.063186  0.026511  0.087042   \n",
      "1 -0.015374  0.180042 -0.160943  0.122516 -0.063186  0.026511  0.087042   \n",
      "2 -0.015374  0.180042 -0.160943  0.122516 -0.063186  0.026511  0.087042   \n",
      "3 -0.015374  0.180042 -0.160943  0.122516 -0.063186  0.026511  0.087042   \n",
      "4 -0.015374  0.180042 -0.160943  0.122516 -0.063186  0.026511  0.087042   \n",
      "\n",
      "        366       367       368       369       370       371       372  \\\n",
      "0  0.199265  0.020813  0.038935 -0.024631  0.090639 -0.086253 -0.060596   \n",
      "1  0.199265  0.020813  0.038935 -0.024631  0.090639 -0.086253 -0.060596   \n",
      "2  0.199265  0.020813  0.038935 -0.024631  0.090639 -0.086253 -0.060596   \n",
      "3  0.199265  0.020813  0.038935 -0.024631  0.090639 -0.086253 -0.060596   \n",
      "4  0.199265  0.020813  0.038935 -0.024631  0.090639 -0.086253 -0.060596   \n",
      "\n",
      "        373       374      375       376       377       378       379  \\\n",
      "0 -0.065373  0.083748  0.13175  0.161078  0.313459  0.294454  0.583119   \n",
      "1 -0.065373  0.083748  0.13175  0.161078  0.313459  0.294454  0.583119   \n",
      "2 -0.065373  0.083748  0.13175  0.161078  0.313459  0.294454  0.583119   \n",
      "3 -0.065373  0.083748  0.13175  0.161078  0.313459  0.294454  0.583119   \n",
      "4 -0.065373  0.083748  0.13175  0.161078  0.313459  0.294454  0.583119   \n",
      "\n",
      "        380       381       382       383       384       385       386  \\\n",
      "0  0.472158 -0.303565  0.607227  0.463773  0.133229 -0.142877  0.479119   \n",
      "1  0.472158 -0.303565  0.607227  0.463773  0.207794 -0.220453 -0.170302   \n",
      "2  0.472158 -0.303565  0.607227  0.463773  0.006388  0.288860  0.130277   \n",
      "3  0.472158 -0.303565  0.607227  0.463773  0.196263 -0.017139 -0.286895   \n",
      "4  0.472158 -0.303565  0.607227  0.463773 -0.008708 -0.061923  0.357593   \n",
      "\n",
      "        387       388       389       390       391       392       393  \\\n",
      "0  0.093402  0.139723 -0.205360 -0.153792  0.035812  0.235407  0.059106   \n",
      "1  0.287403 -0.484713  0.238278 -0.106940 -0.268917  0.320219  0.471174   \n",
      "2 -0.235906 -0.281979 -0.006940  0.551823  0.233068 -0.034466 -0.039953   \n",
      "3 -0.180835  0.484876 -0.322001  0.232030 -0.177828 -0.025211  0.080362   \n",
      "4  0.206153 -0.020560 -0.234677  0.131255  0.274354 -0.046566 -0.062825   \n",
      "\n",
      "        394       395       396       397       398       399       400  \\\n",
      "0 -0.138560  0.118369 -0.317939  0.039955  0.248569  0.237272 -0.130483   \n",
      "1 -0.192289 -0.014233 -0.239947 -0.170339  0.095127 -0.333341  0.053410   \n",
      "2  0.045138  0.003202 -0.089897 -0.272990 -0.351690  0.303032 -0.045649   \n",
      "3 -0.177561 -0.063092  0.108262 -0.216676  0.092993  0.133032  0.089771   \n",
      "4  0.255001 -0.112166  0.259275  0.219177  0.076673 -0.219373  0.110561   \n",
      "\n",
      "        401       402       403       404       405       406       407  \\\n",
      "0 -0.085553  0.060170 -0.094740  0.197184  0.078081 -0.360613  0.281846   \n",
      "1 -0.431935 -0.224283 -0.034757  0.365467  0.282094  0.299784 -0.383676   \n",
      "2 -0.306893 -0.248421  0.267758 -0.285847  0.140170  0.173219 -0.409507   \n",
      "3  0.330402 -0.128648  0.200730 -0.054400 -0.107225 -0.127493  0.102366   \n",
      "4 -0.086518  0.210776  0.005513 -0.151627  0.139849 -0.414367 -0.132452   \n",
      "\n",
      "        408       409       410       411       412       413       414  \\\n",
      "0  0.342090 -0.574868 -0.441713  0.226396  0.074945  0.190568 -0.291997   \n",
      "1  0.054381  0.256046  0.032670 -0.063087  0.220145 -0.269361  0.451532   \n",
      "2 -0.238013 -0.111173 -0.055908  0.117917  0.040686  0.294217  0.254460   \n",
      "3  0.058646 -0.243275 -0.009561  0.149451 -0.377659 -0.062149  0.128442   \n",
      "4 -0.089764  0.352538  0.173300 -0.287698  0.130823 -0.291061  0.067577   \n",
      "\n",
      "        415       416       417       418       419       420       421  \\\n",
      "0  0.003903  0.257569  0.384676  0.159396 -0.190657 -0.097034 -0.121496   \n",
      "1  0.022349 -0.052112 -0.169092 -0.115385 -0.381163 -0.299685  0.342551   \n",
      "2  0.329826 -0.035983  0.234120 -0.551995  0.056888  0.066946  0.177690   \n",
      "3  0.136668 -0.062670  0.051829  0.197446  0.174560 -0.048273 -0.119558   \n",
      "4 -0.110635  0.283758  0.109981  0.123393 -0.247092  0.196576 -0.039147   \n",
      "\n",
      "        422       423       424       425       426       427       428  \\\n",
      "0 -0.166353  0.292199 -0.009223  0.240323 -0.263271 -0.158000  0.097445   \n",
      "1 -0.018233 -0.234252  0.104248  0.112559 -0.303063 -0.297875  0.195948   \n",
      "2 -0.119363 -0.494213  0.510022 -0.136202 -0.075496 -0.270310 -0.103186   \n",
      "3  0.227490 -0.190411  0.065061 -0.302824 -0.167585  0.044086 -0.081147   \n",
      "4  0.003470 -0.255259  0.353532 -0.222170 -0.109076 -0.127922  0.013840   \n",
      "\n",
      "        429       430       431       432       433       434       435  \\\n",
      "0  0.162608  0.389918  0.173110  0.219956 -0.093999 -0.208930  0.377203   \n",
      "1 -0.338821 -0.126741  0.066813 -0.473695  0.113708  0.738919 -0.097907   \n",
      "2  0.180829  0.102701 -0.050014 -0.640362 -0.243091  0.349535  0.293157   \n",
      "3 -0.113095  0.008495  0.244954  0.009475  0.024997  0.117606  0.168715   \n",
      "4  0.073627 -0.304590  0.303537 -0.000605 -0.304747  0.136940 -0.204744   \n",
      "\n",
      "        436       437       438       439       440       441       442  \\\n",
      "0  0.262842 -0.072874 -0.476378  0.060782 -0.088464  0.278558 -0.029740   \n",
      "1 -0.181578 -0.146501 -0.229618 -0.100667 -0.066639 -0.368104  0.310521   \n",
      "2 -0.444755  0.411355  0.162902  0.184483 -0.248345 -0.482547  0.174549   \n",
      "3  0.061832 -0.219857  0.203268  0.287196 -0.034412  0.372257 -0.112125   \n",
      "4 -0.172095 -0.139891 -0.109370  0.023265 -0.101736 -0.096090 -0.262669   \n",
      "\n",
      "        443       444       445       446       447       448       449  \\\n",
      "0 -0.188873  0.113879 -0.434704  0.006032 -0.056008 -0.179371  0.136081   \n",
      "1  0.066487  0.208120  0.166577  0.215446  0.086132  0.025498 -0.286595   \n",
      "2  0.131923 -0.243030  0.029105 -0.369384 -0.030860 -0.174743 -0.033120   \n",
      "3 -0.048050 -0.160680  0.165294 -0.176731  0.185666 -0.293579 -0.164498   \n",
      "4 -0.062039  0.161396 -0.252649  0.166776 -0.046835  0.481433  0.300422   \n",
      "\n",
      "        450       451       452       453       454       455       456  \\\n",
      "0 -0.417277  0.063527 -0.133192  0.050617  0.068944 -0.016631 -0.258978   \n",
      "1  0.147038  0.029180 -0.305131 -0.071334 -0.657961  0.128663 -0.535045   \n",
      "2  0.010293 -0.289280  0.054515 -0.077975 -0.412180  0.087013 -0.082317   \n",
      "3  0.091785 -0.159181 -0.167766  0.164492  0.076285 -0.181617  0.024514   \n",
      "4 -0.077198  0.081970  0.301223  0.470493 -0.182292 -0.234160  0.354990   \n",
      "\n",
      "        457       458       459       460       461       462       463  \\\n",
      "0 -0.249832  0.094185  0.409396  0.249711  0.105914  0.251260  0.398110   \n",
      "1 -0.020565 -0.253119 -0.135060  0.196633 -0.042250 -0.603844  0.041921   \n",
      "2 -0.048575 -0.259247  0.093475 -0.191109  0.273178  0.268480  0.336732   \n",
      "3 -0.085613 -0.307650 -0.277965  0.442637  0.032367 -0.177720 -0.270720   \n",
      "4 -0.195752  0.064221  0.029556  0.295810 -0.032123  0.018875  0.086022   \n",
      "\n",
      "        464       465       466       467       468       469       470  \\\n",
      "0 -0.216393 -0.151247 -0.091002 -0.010099 -0.497047 -0.137455 -0.000697   \n",
      "1  0.009440 -0.069388 -0.243949 -0.170955 -0.100342  0.085992 -0.452814   \n",
      "2 -0.087570 -0.467349 -0.002814 -0.145885 -0.004061  0.203819 -0.034412   \n",
      "3 -0.231258 -0.013160 -0.384996  0.449510 -0.327373  0.227403 -0.134818   \n",
      "4  0.102480 -0.179967 -0.093478  0.193553 -0.138314 -0.276377 -0.069330   \n",
      "\n",
      "        471       472       473       474       475       476       477  \\\n",
      "0  0.322132 -0.192393 -0.289292  0.148800 -0.074274  0.269083 -0.265078   \n",
      "1  0.196892  0.021737 -0.088772  0.212652  0.059460 -0.112335  0.346123   \n",
      "2  0.110052  0.156360 -0.073076  0.211198 -0.063636 -0.578161 -0.297688   \n",
      "3  0.085144  0.038374 -0.082004  0.148557  0.296717 -0.221803 -0.441617   \n",
      "4  0.513747  0.443818  0.179447 -0.070235 -0.214728  0.172312 -0.559034   \n",
      "\n",
      "        478       479       480       481       482       483       484  \\\n",
      "0  0.498081  0.122825  0.042973  0.244462 -0.084801 -0.077661  0.135355   \n",
      "1 -0.250716 -0.236150 -0.361811 -0.087480 -0.153575 -0.281641  0.222474   \n",
      "2 -0.025257  0.521314  0.031582 -0.546255  0.087774 -0.083063  0.331982   \n",
      "3 -0.193341  0.035337  0.166692 -0.074284  0.252887  0.290722 -0.161109   \n",
      "4  0.010216 -0.305666 -0.236148  0.153991  0.202718  0.117283  0.186817   \n",
      "\n",
      "        485       486       487       488       489       490       491  \\\n",
      "0  0.072691 -0.093006  0.235658  0.057341 -0.040729 -0.434394  0.191098   \n",
      "1 -0.560787  0.038735  0.048343 -0.046397  0.050783 -0.039007  0.526539   \n",
      "2 -0.004895  0.006213 -0.362636  0.292486  0.043943  0.102270  0.038510   \n",
      "3  0.402888  0.196483  0.007305 -0.053355  0.192242 -0.305105 -0.103157   \n",
      "4  0.231747 -0.192317 -0.087201 -0.229465 -0.335982  0.139776  0.191934   \n",
      "\n",
      "        492       493       494       495       496       497       498  \\\n",
      "0  0.069396 -0.077678  0.385370 -0.147741 -0.091877  0.131895 -0.070179   \n",
      "1 -0.312192 -0.055120 -0.075026 -0.083108 -0.290294 -0.140904  0.098165   \n",
      "2  0.496989 -0.210879 -0.611147 -0.134501 -0.077389 -0.037867  0.060701   \n",
      "3  0.076218  0.393691 -0.260119 -0.085066 -0.250816  0.081816  0.245180   \n",
      "4  0.044263 -0.029100  0.036321  0.031775 -0.196654 -0.095830 -0.417318   \n",
      "\n",
      "        499       500       501       502       503       504       505  \\\n",
      "0  0.029780 -0.403236 -0.253169  0.013974 -0.588007  0.247388 -0.257971   \n",
      "1  0.165549 -0.053023 -0.128898  0.425674  0.137993  0.125539 -0.045404   \n",
      "2 -0.345894 -0.030105  0.151465  0.514932 -0.173787 -0.028632 -0.195383   \n",
      "3  0.269995 -0.017620  0.073006  0.016795  0.191219 -0.041458  0.053518   \n",
      "4 -0.455122 -0.205522  0.021845 -0.242461 -0.267214 -0.377602 -0.272841   \n",
      "\n",
      "        506       507       508       509       510       511       512  \\\n",
      "0 -0.465474 -0.287462 -0.209444  0.480981  0.183273  0.231670 -0.168268   \n",
      "1  0.032820  0.198403  0.012855  0.072369 -0.353961  0.061989  0.195779   \n",
      "2 -0.016572 -0.210592 -0.450738  0.204451 -0.103760 -0.511393 -0.260217   \n",
      "3 -0.248048  0.180833  0.020084  0.238510  0.008257 -0.056848 -0.434828   \n",
      "4  0.132984 -0.429184 -0.261322 -0.237334  0.121567 -0.250918 -0.243024   \n",
      "\n",
      "        513       514       515       516       517       518       519  \\\n",
      "0 -0.002043  0.042981  0.014493  0.402858 -0.484284 -0.041995 -0.046739   \n",
      "1 -0.094055  0.303521 -0.300899 -0.289091  0.230305 -0.174414 -0.188714   \n",
      "2  0.071515  0.251550  0.145165 -0.226363 -0.152764  0.335870  0.055612   \n",
      "3 -0.294689  0.059376  0.214315  0.453105  0.243101  0.255242 -0.139005   \n",
      "4  0.029676 -0.297711  0.144500 -0.224841  0.161945 -0.114525 -0.291231   \n",
      "\n",
      "        520       521       522       523       524       525       526  \\\n",
      "0  0.210776 -0.341266 -0.025796 -0.251306  0.012207  0.061302 -0.064348   \n",
      "1  0.246142  0.328503 -0.164418 -0.189837  0.211465 -0.236602  0.258169   \n",
      "2  0.092129 -0.120497 -0.236641 -0.167634 -0.133466  0.137326 -0.350091   \n",
      "3  0.141528  0.149729  0.024579 -0.315655 -0.133145  0.069835 -0.018774   \n",
      "4  0.243777 -0.275315 -0.167017  0.186311  0.073627  0.191272  0.387671   \n",
      "\n",
      "        527       528       529       530       531       532       533  \\\n",
      "0 -0.101330  0.233740  0.201147 -0.072897 -0.003252 -0.205620 -0.028990   \n",
      "1  0.463163  0.346381 -0.115455 -0.366101  0.126126 -0.230324  0.035946   \n",
      "2 -0.117155 -0.121453  0.097484  0.358031  0.015944 -0.051653 -0.351954   \n",
      "3 -0.012289 -0.033261  0.054935  0.155001 -0.101330 -0.262661  0.344017   \n",
      "4 -0.115868 -0.094816  0.129644 -0.296333 -0.111575 -0.192070  0.172783   \n",
      "\n",
      "        534       535       536       537       538       539       540  \\\n",
      "0 -0.218833 -0.294831 -0.415974 -0.296585  0.217518 -0.027557  0.000667   \n",
      "1 -0.002056 -0.076228 -0.263146 -0.036806  0.210915 -0.033640  0.045462   \n",
      "2  0.257268  0.089209  0.108104 -0.282617  0.115878 -0.457268 -0.119728   \n",
      "3 -0.101876  0.204368  0.051136  0.347331  0.320590 -0.229268 -0.162575   \n",
      "4 -0.165756 -0.051576 -0.257632  0.272272 -0.312114 -0.085694 -0.024486   \n",
      "\n",
      "        541       542       543       544       545       546       547  \\\n",
      "0  0.464050  0.359081  0.183901  0.029632 -0.051492  0.292166 -0.386180   \n",
      "1  0.235836  0.266876  0.008144  0.064451  0.078305  0.350124 -0.002009   \n",
      "2  0.157270 -0.064934  0.036795 -0.234062  0.016977 -0.446981 -0.119785   \n",
      "3  0.128579  0.223016  0.383079  0.366395 -0.431790 -0.072370 -0.025070   \n",
      "4 -0.050502 -0.470367  0.033302 -0.009886 -0.030274  0.132991  0.024871   \n",
      "\n",
      "        548       549       550       551       552       553       554  \\\n",
      "0 -0.052371  0.039618 -0.156217 -0.346753  0.069484  0.295156  0.214232   \n",
      "1  0.167791  0.298676  0.123591 -0.276305  0.013950 -0.144771 -0.301467   \n",
      "2  0.168707  0.237914  0.019239  0.121597  0.102981 -0.267055 -0.363729   \n",
      "3  0.217611  0.083783 -0.097561  0.016042 -0.229052 -0.075258 -0.370894   \n",
      "4 -0.191648 -0.148700  0.099337 -0.265504 -0.237510  0.221893  0.379603   \n",
      "\n",
      "        555       556       557       558       559       560       561  \\\n",
      "0  0.308698 -0.049230 -0.106294 -0.212015 -0.285877 -0.135308 -0.035562   \n",
      "1  0.093400 -0.157007  0.005752 -0.020865 -0.063144 -0.357425  0.095294   \n",
      "2  0.121620  0.400904  0.311988 -0.064749 -0.033652  0.232505 -0.310838   \n",
      "3 -0.208043  0.089542 -0.182633  0.212037 -0.384031 -0.287402 -0.251623   \n",
      "4 -0.048692 -0.180045 -0.075914 -0.106078  0.101861 -0.046196  0.487428   \n",
      "\n",
      "        562       563       564       565       566       567       568  \\\n",
      "0 -0.293822  0.235596  0.200211  0.265570  0.098149 -0.222250  0.514790   \n",
      "1  0.317165 -0.347201 -0.417721  0.152498 -0.398277 -0.107993  0.229136   \n",
      "2 -0.129794 -0.299557 -0.014282 -0.148850 -0.212622 -0.078629  0.130034   \n",
      "3  0.241060 -0.133108 -0.025756 -0.009484 -0.154309  0.018283  0.255320   \n",
      "4  0.073130 -0.055038 -0.391086  0.284886 -0.002433 -0.046950 -0.444631   \n",
      "\n",
      "        569       570       571       572       573       574       575  \\\n",
      "0  0.374474 -0.059786  0.027017  0.015778 -0.357456  0.094364  0.321455   \n",
      "1  0.423431 -0.236429  0.168763 -0.016052  0.124465 -0.864119 -0.217317   \n",
      "2 -0.411556  0.018420 -0.069335  0.326136  0.249864 -0.306810 -0.232574   \n",
      "3 -0.188755 -0.287991  0.244539  0.166571  0.490782  0.098405 -0.160200   \n",
      "4 -0.118106 -0.077549 -0.398730  0.159312  0.301399 -0.318463 -0.132829   \n",
      "\n",
      "        576       577       578       579       580       581       582  \\\n",
      "0  0.178971  0.231602  0.369302  0.388486 -0.489134  0.777990  0.013082   \n",
      "1 -0.229819 -0.391023 -0.359719 -0.037799  0.010084  0.063744  0.301414   \n",
      "2 -0.180846  0.092248 -0.062507  0.030326  0.075948 -0.167720 -0.176251   \n",
      "3 -0.259953 -0.315758  0.098778 -0.132487 -0.052936  0.018742 -0.402637   \n",
      "4  0.218260 -0.168813 -0.091865  0.183968 -0.268925 -0.141051 -0.066444   \n",
      "\n",
      "        583       584       585       586       587       588       589  \\\n",
      "0  0.098980 -0.264407 -0.008142 -0.011935 -0.156649 -0.294525  0.193395   \n",
      "1  0.098443 -0.052912 -0.155555  0.169237  0.677396 -0.406517  0.244519   \n",
      "2 -0.165238  0.138458  0.215780 -0.193145 -0.164709  0.230900  0.027617   \n",
      "3 -0.036983  0.085232  0.290376 -0.199372  0.070346 -0.329527 -0.118391   \n",
      "4 -0.269103  0.147990  0.020860  0.329959 -0.582519 -0.074478 -0.356281   \n",
      "\n",
      "        590       591       592       593       594       595       596  \\\n",
      "0 -0.350459 -0.087953 -0.246804  0.111844  0.400216  0.249167 -0.108998   \n",
      "1  0.321051 -0.087893 -0.058044 -0.214156  0.089801 -0.347683 -0.311041   \n",
      "2  0.435862  0.063842  0.286745 -0.295756 -0.089344  0.050006  0.087465   \n",
      "3  0.439570  0.026614 -0.111788  0.005898 -0.139627 -0.325717  0.223700   \n",
      "4 -0.332563 -0.417206 -0.431702 -0.321131 -0.233243 -0.231976 -0.004698   \n",
      "\n",
      "        597       598       599       600       601       602       603  \\\n",
      "0  0.086470  0.106311  0.263175  0.048011 -0.090007  0.152824 -0.124570   \n",
      "1  0.065970 -0.484776  0.290853  0.078298 -0.413041  0.094833 -0.109125   \n",
      "2  0.083135 -0.045717  0.072540  0.069051  0.253118 -0.407088  0.194906   \n",
      "3 -0.273701  0.193564  0.354710  0.004545 -0.264934  0.245572 -0.352579   \n",
      "4  0.103017  0.309974  0.314556  0.442878  0.091958 -0.063226  0.189906   \n",
      "\n",
      "        604       605       606       607       608       609       610  \\\n",
      "0  0.312987  0.052341  0.154921  0.101203 -0.086878 -0.066799  0.160633   \n",
      "1 -0.086053 -0.109824  0.020196 -0.192819  0.485299 -0.328870  0.194046   \n",
      "2 -0.176717 -0.131838 -0.397916 -0.203503 -0.066093  0.136179  0.044532   \n",
      "3  0.369393 -0.306632 -0.251541 -0.090382  0.406330 -0.047738 -0.126536   \n",
      "4 -0.032679  0.157767 -0.083142 -0.396042 -0.115730 -0.106748  0.008781   \n",
      "\n",
      "        611       612       613       614       615       616       617  \\\n",
      "0 -0.033593  0.167191  0.091838  0.374183  0.007010 -0.164229 -0.039861   \n",
      "1 -0.340784  0.389954 -0.242783  0.133726  0.375016 -0.654049 -0.212327   \n",
      "2  0.121585  0.063361 -0.223312 -0.003433  0.056524  0.385563 -0.391306   \n",
      "3 -0.193280  0.153619  0.409076 -0.279586  0.053003 -0.073161  0.328867   \n",
      "4 -0.061622  0.284881 -0.219376 -0.079471  0.057767  0.240738 -0.144394   \n",
      "\n",
      "        618       619       620       621       622       623       624  \\\n",
      "0  0.182546 -0.238948  0.039962 -0.426168 -0.130875  0.455940  0.037592   \n",
      "1 -0.169710  0.047123  0.211535  0.045985 -0.017491 -0.159108  0.175294   \n",
      "2 -0.313587 -0.030269 -0.185811  0.236887 -0.217392 -0.121532  0.072383   \n",
      "3  0.287424  0.122678 -0.199203  0.014631 -0.409081  0.172836  0.334472   \n",
      "4  0.442391  0.057360 -0.351653  0.081963  0.481633  0.290474 -0.109621   \n",
      "\n",
      "        625       626       627       628       629       630       631  \\\n",
      "0 -0.552643  0.070162 -0.125953 -0.390453  0.032870 -0.198575  0.111218   \n",
      "1  0.231986 -0.129625  0.088415 -0.147224  0.226137  0.185426  0.112513   \n",
      "2  0.035492  0.233257  0.206809 -0.040539 -0.366459  0.118285  0.261865   \n",
      "3  0.285929  0.068948 -0.304186 -0.054716 -0.070620  0.397564 -0.563541   \n",
      "4 -0.220123 -0.031289  0.271478  0.266791  0.388821  0.072493 -0.601038   \n",
      "\n",
      "        632       633       634       635       636       637       638  \\\n",
      "0 -0.253541 -0.033836  0.065285  0.071863 -0.000501 -0.239504  0.060084   \n",
      "1  0.234701 -0.270957  0.101292  0.118082 -0.161697 -0.003218  0.075370   \n",
      "2  0.393662 -0.258090 -0.077719  0.096287  0.002402 -0.119501  0.012495   \n",
      "3  0.101737 -0.238865  0.124908 -0.114282  0.162318 -0.341121  0.309351   \n",
      "4 -0.078590  0.095300  0.444413  0.368184 -0.185443  0.000758 -0.474814   \n",
      "\n",
      "        639       640       641       642       643       644       645  \\\n",
      "0 -0.012615 -0.079164 -0.056617  0.079366 -0.108658  0.178124 -0.145794   \n",
      "1  0.112950  0.334223 -0.125980  0.091203 -0.121314  0.130420 -0.392335   \n",
      "2  0.150826 -0.457720 -0.172154 -0.095754 -0.166977  0.307167  0.089650   \n",
      "3  0.183918  0.262356  0.006877 -0.138267  0.323102 -0.236544 -0.213144   \n",
      "4  0.433275 -0.085675 -0.440184  0.065917  0.049529 -0.022612  0.009098   \n",
      "\n",
      "        646       647       648       649       650       651       652  \\\n",
      "0  0.486524 -0.143467 -0.098701  0.032902  0.118530 -0.036255 -0.056137   \n",
      "1 -0.265552 -0.211173 -0.025466  0.165442 -0.248449  0.155747  0.128348   \n",
      "2  0.059101 -0.058569  0.274918 -0.053473  0.317558  0.216843  0.200523   \n",
      "3  0.051982  0.026313  0.250517 -0.003310  0.555701 -0.282812  0.405167   \n",
      "4 -0.012189  0.293842 -0.103598  0.295619  0.033837 -0.083954 -0.029013   \n",
      "\n",
      "        653       654       655       656       657       658       659  \\\n",
      "0  0.075477 -0.251671 -0.117543 -0.548797 -0.049099  0.101017 -0.270976   \n",
      "1  0.106339  0.290728  0.146042 -0.175763  0.010743 -0.116055 -0.074182   \n",
      "2 -0.257404  0.254077 -0.052682 -0.003043  0.196024  0.064492  0.150738   \n",
      "3 -0.117785  0.478625 -0.136238  0.273213  0.297410 -0.338868  0.019788   \n",
      "4 -0.209182 -0.283571  0.209604 -0.180848  0.093569  0.037886 -0.087866   \n",
      "\n",
      "        660       661       662       663       664       665       666  \\\n",
      "0  0.052086  0.385232 -0.385763  0.242579 -0.073653  0.160603 -0.035131   \n",
      "1  0.104924  0.182476  0.167796 -0.103960 -0.260277  0.011248 -0.238451   \n",
      "2 -0.089843 -0.239931 -0.402981  0.002592  0.046785  0.140208 -0.209939   \n",
      "3  0.386116  0.014095 -0.266255 -0.146234  0.295715  0.103488 -0.206861   \n",
      "4 -0.141297 -0.046350  0.332358  0.184865  0.087990  0.236657 -0.297300   \n",
      "\n",
      "        667       668       669       670       671       672       673  \\\n",
      "0  0.142729  0.169279  0.144256  0.187037 -0.142817  0.218321 -0.000259   \n",
      "1 -0.157266 -0.159268  0.050243 -0.168717 -0.495615 -0.180962 -0.147638   \n",
      "2  0.004013  0.288369 -0.162370 -0.200408  0.310028 -0.357128 -0.031483   \n",
      "3 -0.124367  0.187998  0.088404 -0.170996  0.121427  0.051819 -0.031836   \n",
      "4 -0.027791  0.023761  0.457483 -0.089950 -0.424520  0.188801  0.088194   \n",
      "\n",
      "        674       675       676       677       678       679       680  \\\n",
      "0 -0.100716  0.044267 -0.095630  0.560569 -0.211355  0.383093 -0.169008   \n",
      "1 -0.020081 -0.143817 -0.039624 -0.267727 -0.095359  0.163016 -0.198112   \n",
      "2 -0.031647  0.488619 -0.227536 -0.004881  0.061456 -0.290245 -0.286776   \n",
      "3 -0.079674  0.377539 -0.008256  0.325526 -0.265295 -0.156718 -0.165130   \n",
      "4 -0.077294  0.084537  0.357424  0.160845  0.070797  0.016374 -0.035708   \n",
      "\n",
      "        681       682       683       684       685       686       687  \\\n",
      "0  0.046269  0.506837 -0.243000 -0.058113 -0.080602  0.368781 -0.252491   \n",
      "1  0.435144  0.368759  0.402709  0.082790  0.358733 -0.334727  0.171672   \n",
      "2 -0.468417  0.023163  0.235612  0.008204 -0.260565  0.316894 -0.065265   \n",
      "3  0.089950 -0.205745  0.068183  0.184120 -0.134503  0.107613 -0.179215   \n",
      "4 -0.047443  0.448121  0.149870  0.240003 -0.513225  0.070477  0.318692   \n",
      "\n",
      "        688       689       690       691       692       693       694  \\\n",
      "0 -0.115868  0.057606 -0.477563 -0.393149 -0.330215  0.152118  0.186013   \n",
      "1 -0.198082 -0.433932  0.035449  0.252611  0.045118 -0.123961  0.506765   \n",
      "2 -0.101716 -0.278847  0.290269  0.209822 -0.238829 -0.198631 -0.195628   \n",
      "3 -0.229417  0.029910  0.043954 -0.003555 -0.136157  0.009610  0.024373   \n",
      "4  0.141609 -0.042842 -0.048368  0.404337 -0.530940 -0.140663 -0.030417   \n",
      "\n",
      "        695       696       697       698       699       700       701  \\\n",
      "0 -0.003380 -0.227748  0.285923 -0.143332 -0.282099 -0.018774 -0.011101   \n",
      "1 -0.248429 -0.091167 -0.132037 -0.035296 -0.145775  0.255930  0.231191   \n",
      "2 -0.044416  0.257869  0.037475 -0.380800 -0.370078  0.199730  0.013144   \n",
      "3 -0.524101 -0.084996 -0.225480 -0.068561 -0.376667 -0.027077  0.155246   \n",
      "4  0.072441 -0.256882  0.158250 -0.124021 -0.444219 -0.014201 -0.327761   \n",
      "\n",
      "        702       703       704       705       706       707       708  \\\n",
      "0  0.241697 -0.238861 -0.044080 -0.261023  0.113406  0.190977  0.100073   \n",
      "1  0.058683 -0.315467  0.497863  0.382198  0.130141 -0.414665  0.128387   \n",
      "2 -0.218062 -0.117631 -0.296535  0.628266 -0.185286 -0.283389  0.374565   \n",
      "3 -0.054446 -0.199804 -0.122787  0.143028  0.148616 -0.048728  0.026890   \n",
      "4 -0.251788  0.095296  0.144733  0.299973  0.248379  0.151189  0.137932   \n",
      "\n",
      "        709       710       711       712       713       714       715  \\\n",
      "0  0.210249 -0.182931  0.058284  0.059275 -0.056616  0.038554 -0.008525   \n",
      "1  0.037269 -0.104753 -0.110350 -0.246491 -0.344741  0.035530  0.523086   \n",
      "2  0.041862 -0.343463 -0.113955 -0.215748  0.069898 -0.168093 -0.033785   \n",
      "3  0.082551  0.173268  0.009716 -0.083840 -0.137081  0.213742 -0.086363   \n",
      "4 -0.018145 -0.264639  0.155342 -0.309547 -0.224000  0.487957 -0.196909   \n",
      "\n",
      "        716       717       718       719       720       721       722  \\\n",
      "0 -0.309255 -0.035327 -0.171944  0.302501 -0.284340  0.088965  0.136705   \n",
      "1 -0.285843 -0.041147  0.211087  0.066945  0.103674  0.124549  0.426126   \n",
      "2  0.071083 -0.024998  0.368864  0.081407 -0.021614 -0.214301  0.085884   \n",
      "3 -0.034678 -0.313791 -0.118695 -0.178926  0.065838  0.062595 -0.125039   \n",
      "4 -0.004054 -0.001980 -0.287121 -0.180376  0.066862  0.210417  0.316332   \n",
      "\n",
      "        723       724       725       726       727       728       729  \\\n",
      "0  0.157365 -0.369500 -0.111188  0.176910 -0.224182 -0.371674  0.300690   \n",
      "1  0.087761 -0.012610 -0.112825  0.089184 -0.422640  0.065784 -0.291282   \n",
      "2  0.019088 -0.010634 -0.516414 -0.028824 -0.235739  0.072872  0.203074   \n",
      "3 -0.019234  0.489372 -0.197251 -0.260781  0.195805  0.022199 -0.321302   \n",
      "4 -0.621087  0.215280 -0.054723  0.107305  0.041397 -0.142451  0.105340   \n",
      "\n",
      "        730       731       732       733       734       735       736  \\\n",
      "0  0.016863  0.188025 -0.222160 -0.220051  0.048218  0.010209  0.453682   \n",
      "1 -0.217896  0.146388  0.111590 -0.200038 -0.046719  0.142726 -0.140180   \n",
      "2 -0.187585  0.231033  0.610965  0.113118  0.087355  0.079254  0.232797   \n",
      "3  0.533522  0.208538  0.217792 -0.162515  0.102166  0.284781 -0.338346   \n",
      "4  0.149112  0.086848 -0.043997 -0.019126 -0.012629 -0.006759  0.318448   \n",
      "\n",
      "        737       738       739       740       741       742       743  \\\n",
      "0 -0.308361 -0.065344  0.241223 -0.170462 -0.276685  0.167863 -0.193647   \n",
      "1 -0.029158 -0.057603 -0.275380 -0.054830 -0.282636 -0.160758  0.166575   \n",
      "2 -0.309481  0.072881 -0.073023  0.226107 -0.054403  0.224312 -0.129877   \n",
      "3  0.096200 -0.047357 -0.395772  0.053043  0.220681  0.179882  0.017691   \n",
      "4  0.182285  0.040184  0.285411  0.072790  0.050111  0.049713 -0.047059   \n",
      "\n",
      "        744       745       746       747       748       749       750  \\\n",
      "0  0.738408  0.305784 -0.332660  0.249544  0.060786  0.359194 -0.047445   \n",
      "1 -0.284589 -0.095728 -0.259925  0.246575 -0.435503  0.321572  0.089528   \n",
      "2 -0.044072  0.135016  0.104175  0.011962 -0.183686  0.119846 -0.089526   \n",
      "3  0.092321  0.244583  0.197536  0.007210 -0.052589  0.169653  0.064554   \n",
      "4  0.080093 -0.101336  0.341636 -0.300021 -0.304076  0.362728  0.005519   \n",
      "\n",
      "        751       752       753       754       755       756       757  \\\n",
      "0  0.181679  0.196386 -0.038403  0.261694 -0.026308 -0.104024  0.288764   \n",
      "1 -0.345381  0.064380  0.074156 -0.061514  0.062606 -0.053837 -0.466646   \n",
      "2 -0.079611 -0.100087  0.069138  0.202856  0.117368  0.009861  0.244657   \n",
      "3 -0.109177 -0.304830  0.224531  0.159704 -0.166254 -0.164497 -0.106574   \n",
      "4  0.172513 -0.518530  0.023794  0.064829 -0.395606  0.034481 -0.290985   \n",
      "\n",
      "        758       759       760       761       762       763       764  \\\n",
      "0 -0.168523  0.189696  0.448754 -0.319799 -0.129202 -0.311737  0.145812   \n",
      "1  0.284125  0.170353 -0.035016  0.489892  0.247992  0.212585  0.371248   \n",
      "2 -0.108115 -0.083584  0.191634  0.462222  0.175747 -0.495133  0.225336   \n",
      "3  0.211273 -0.149778  0.090686  0.010583  0.113679 -0.172161  0.198930   \n",
      "4 -0.396825  0.149638  0.117300 -0.590846 -0.058776 -0.330682  0.150427   \n",
      "\n",
      "        765       766       767  \n",
      "0  0.330308 -0.322078  0.082552  \n",
      "1 -0.267340 -0.242153  0.200902  \n",
      "2 -0.010376 -0.003385 -0.069778  \n",
      "3  0.453372  0.472176  0.016301  \n",
      "4  0.413755 -0.379759 -0.103892  \n"
     ]
    }
   ],
   "source": [
    "# Create X data using embeddings for catalyst, imine, thiol, and product\n",
    "X_data = []\n",
    "Y_data = []\n",
    "\n",
    "for _, row in Y_df.iterrows():\n",
    "    catalyst_id = row['catalyst_id']\n",
    "    imine_id = row['imine_id']\n",
    "    thiol_id = row['thiol_id']\n",
    "    product_id = row['product_id']\n",
    "    \n",
    "    if all(id in embeddings for id in [catalyst_id, imine_id, thiol_id, product_id]):\n",
    "        combined_embedding = np.concatenate([\n",
    "            embeddings[catalyst_id],\n",
    "            embeddings[imine_id],\n",
    "            embeddings[thiol_id],\n",
    "            embeddings[product_id]\n",
    "        ])\n",
    "        X_data.append(combined_embedding)\n",
    "        Y_data.append(row['selectivity_ddGact_kcal'])\n",
    "    else:\n",
    "        print(f\"Missing embedding for reaction: {row['reaction_handle']} - Missing IDs: {[id for id in [catalyst_id, imine_id, thiol_id, product_id] if id not in embeddings]}\")\n",
    "\n",
    "X_df = pd.DataFrame(X_data)\n",
    "Y_series = pd.Series(Y_data)\n",
    "\n",
    "print(f\"Created dataset with {len(X_df)} samples and {X_df.shape[1]} features\")\n",
    "print(\"Sample rows from X_df:\")\n",
    "print(X_df.head())\n",
    "\n",
    "if len(X_df) == 0:\n",
    "    print(\"Error: No matching data found. Please check if the IDs in Y_DATA.csv match the keys in the embeddings file.\")\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting started...\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "[CV 1/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.7777777777777777, model__learning_rate=0.3792690190732246, model__max_depth=5, model__min_child_weight=10.0, model__n_estimators=300, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.199) r2: (test=0.847) total time= 3.3min\n",
      "[CV 3/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.7777777777777777, model__learning_rate=0.3792690190732246, model__max_depth=5, model__min_child_weight=10.0, model__n_estimators=300, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.196) r2: (test=0.879) total time= 3.8min\n",
      "[CV 2/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.7777777777777777, model__learning_rate=0.3792690190732246, model__max_depth=5, model__min_child_weight=10.0, model__n_estimators=300, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.168) r2: (test=0.884) total time= 3.9min\n",
      "[CV 4/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.7777777777777777, model__learning_rate=0.3792690190732246, model__max_depth=5, model__min_child_weight=10.0, model__n_estimators=300, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.178) r2: (test=0.861) total time= 3.9min\n",
      "[CV 5/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.7777777777777777, model__learning_rate=0.3792690190732246, model__max_depth=5, model__min_child_weight=10.0, model__n_estimators=300, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.184) r2: (test=0.872) total time= 4.0min\n",
      "[CV 3/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.0, model__learning_rate=0.0001623776739188721, model__max_depth=4, model__min_child_weight=8.0, model__n_estimators=600, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.566) r2: (test=0.121) total time= 4.0min\n",
      "[CV 5/5] END model__colsample_bytree=0.2, model__gamma=0.6666666666666666, model__learning_rate=0.0006951927961775605, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=800, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.375) r2: (test=0.487) total time= 4.0min\n",
      "[CV 2/5] END model__colsample_bytree=0.2, model__gamma=0.6666666666666666, model__learning_rate=0.0006951927961775605, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=800, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.379) r2: (test=0.501) total time= 4.0min\n",
      "[CV 1/5] END model__colsample_bytree=0.2, model__gamma=0.6666666666666666, model__learning_rate=0.0006951927961775605, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=800, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.387) r2: (test=0.488) total time= 4.0min\n",
      "[CV 4/5] END model__colsample_bytree=0.2, model__gamma=0.6666666666666666, model__learning_rate=0.0006951927961775605, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=800, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.395) r2: (test=0.464) total time= 4.1min\n",
      "[CV 2/5] END model__colsample_bytree=0.5, model__gamma=0.1111111111111111, model__learning_rate=0.03359818286283781, model__max_depth=4, model__min_child_weight=10.0, model__n_estimators=700, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.145) r2: (test=0.904) total time= 4.1min\n",
      "[CV 1/5] END model__colsample_bytree=0.5, model__gamma=0.1111111111111111, model__learning_rate=0.03359818286283781, model__max_depth=4, model__min_child_weight=10.0, model__n_estimators=700, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.158) r2: (test=0.890) total time= 4.1min\n",
      "[CV 3/5] END model__colsample_bytree=0.2, model__gamma=0.6666666666666666, model__learning_rate=0.0006951927961775605, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=800, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.423) r2: (test=0.488) total time= 4.1min\n",
      "[CV 1/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.0, model__learning_rate=0.0001623776739188721, model__max_depth=4, model__min_child_weight=8.0, model__n_estimators=600, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.520) r2: (test=0.127) total time= 4.1min\n",
      "[CV 5/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.0, model__learning_rate=0.0001623776739188721, model__max_depth=4, model__min_child_weight=8.0, model__n_estimators=600, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.510) r2: (test=0.121) total time= 4.1min\n",
      "[CV 2/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.0, model__learning_rate=0.0001623776739188721, model__max_depth=4, model__min_child_weight=8.0, model__n_estimators=600, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.510) r2: (test=0.123) total time= 4.1min\n",
      "[CV 4/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.0, model__learning_rate=0.0001623776739188721, model__max_depth=4, model__min_child_weight=8.0, model__n_estimators=600, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.521) r2: (test=0.115) total time= 4.1min\n",
      "[CV 4/5] END model__colsample_bytree=0.8, model__gamma=0.1111111111111111, model__learning_rate=0.03359818286283781, model__max_depth=None, model__min_child_weight=8.0, model__n_estimators=200, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.165) r2: (test=0.877) total time=11.3min\n",
      "[CV 1/5] END model__colsample_bytree=0.6, model__gamma=0.0, model__learning_rate=0.0001623776739188721, model__max_depth=None, model__min_child_weight=6.0, model__n_estimators=300, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.539) r2: (test=0.064) total time=11.4min\n",
      "[CV 3/5] END model__colsample_bytree=0.8, model__gamma=1.0, model__learning_rate=0.05455594781168514, model__max_depth=10, model__min_child_weight=10.0, model__n_estimators=300, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.190) r2: (test=0.886) total time=11.5min\n",
      "[CV 1/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.1111111111111111, model__learning_rate=0.3792690190732246, model__max_depth=8, model__min_child_weight=4.0, model__n_estimators=500, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.166) r2: (test=0.880) total time=11.6min\n",
      "[CV 3/5] END model__colsample_bytree=0.5, model__gamma=0.1111111111111111, model__learning_rate=0.03359818286283781, model__max_depth=4, model__min_child_weight=10.0, model__n_estimators=700, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.160) r2: (test=0.916) total time=11.8min\n",
      "[CV 2/5] END model__colsample_bytree=0.6, model__gamma=0.6666666666666666, model__learning_rate=0.23357214690901212, model__max_depth=9, model__min_child_weight=3.0, model__n_estimators=700, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.159) r2: (test=0.897) total time=11.4min\n",
      "[CV 1/5] END model__colsample_bytree=0.6, model__gamma=0.6666666666666666, model__learning_rate=0.23357214690901212, model__max_depth=9, model__min_child_weight=3.0, model__n_estimators=700, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.179) r2: (test=0.872) total time=11.3min\n",
      "[CV 4/5] END model__colsample_bytree=0.5, model__gamma=0.1111111111111111, model__learning_rate=0.03359818286283781, model__max_depth=4, model__min_child_weight=10.0, model__n_estimators=700, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.165) r2: (test=0.875) total time=11.5min\n",
      "[CV 4/5] END model__colsample_bytree=0.6, model__gamma=0.6666666666666666, model__learning_rate=0.23357214690901212, model__max_depth=9, model__min_child_weight=3.0, model__n_estimators=700, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.181) r2: (test=0.861) total time=11.4min\n",
      "[CV 4/5] END model__colsample_bytree=0.1, model__gamma=0.2222222222222222, model__learning_rate=0.14384498882876628, model__max_depth=5, model__min_child_weight=10.0, model__n_estimators=100, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.182) r2: (test=0.858) total time=11.1min\n",
      "[CV 4/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.5555555555555556, model__learning_rate=0.007847599703514606, model__max_depth=9, model__min_child_weight=1.0, model__n_estimators=400, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.190) r2: (test=0.853) total time=11.7min\n",
      "[CV 5/5] END model__colsample_bytree=0.6, model__gamma=0.6666666666666666, model__learning_rate=0.23357214690901212, model__max_depth=9, model__min_child_weight=3.0, model__n_estimators=700, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.181) r2: (test=0.878) total time=11.4min\n",
      "[CV 2/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.5555555555555556, model__learning_rate=0.007847599703514606, model__max_depth=9, model__min_child_weight=1.0, model__n_estimators=400, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.164) r2: (test=0.888) total time=11.4min\n",
      "[CV 1/5] END model__colsample_bytree=0.9, model__gamma=0.0, model__learning_rate=0.012742749857031334, model__max_depth=5, model__min_child_weight=3.0, model__n_estimators=200, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.177) r2: (test=0.875) total time=11.4min\n",
      "[CV 3/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.5555555555555556, model__learning_rate=0.007847599703514606, model__max_depth=9, model__min_child_weight=1.0, model__n_estimators=400, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.189) r2: (test=0.887) total time=11.5min\n",
      "[CV 1/5] END model__colsample_bytree=0.8, model__gamma=0.1111111111111111, model__learning_rate=0.03359818286283781, model__max_depth=None, model__min_child_weight=8.0, model__n_estimators=200, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.164) r2: (test=0.882) total time=11.5min\n",
      "[CV 2/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.7777777777777777, model__learning_rate=0.0006951927961775605, model__max_depth=6, model__min_child_weight=9.0, model__n_estimators=200, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.497) r2: (test=0.163) total time=11.3min\n",
      "[CV 4/5] END model__colsample_bytree=0.6, model__gamma=0.0, model__learning_rate=0.0001623776739188721, model__max_depth=None, model__min_child_weight=6.0, model__n_estimators=300, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.538) r2: (test=0.066) total time=11.4min\n",
      "[CV 2/5] END model__colsample_bytree=0.8, model__gamma=0.1111111111111111, model__learning_rate=0.03359818286283781, model__max_depth=None, model__min_child_weight=8.0, model__n_estimators=200, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.149) r2: (test=0.900) total time=11.5min\n",
      "[CV 5/5] END model__colsample_bytree=0.7000000000000001, model__gamma=1.0, model__learning_rate=0.14384498882876628, model__max_depth=9, model__min_child_weight=3.0, model__n_estimators=200, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.197) r2: (test=0.861) total time=11.4min\n",
      "[CV 3/5] END model__colsample_bytree=0.7000000000000001, model__gamma=1.0, model__learning_rate=0.14384498882876628, model__max_depth=9, model__min_child_weight=3.0, model__n_estimators=200, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.195) r2: (test=0.882) total time=11.4min\n",
      "[CV 3/5] END model__colsample_bytree=0.8, model__gamma=0.1111111111111111, model__learning_rate=0.03359818286283781, model__max_depth=None, model__min_child_weight=8.0, model__n_estimators=200, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.165) r2: (test=0.911) total time=11.5min\n",
      "[CV 2/5] END model__colsample_bytree=0.6, model__gamma=0.0, model__learning_rate=0.0001623776739188721, model__max_depth=None, model__min_child_weight=6.0, model__n_estimators=300, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.528) r2: (test=0.062) total time=11.7min\n",
      "[CV 5/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.5555555555555556, model__learning_rate=0.007847599703514606, model__max_depth=9, model__min_child_weight=1.0, model__n_estimators=400, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.179) r2: (test=0.880) total time=11.4min\n",
      "[CV 1/5] END model__colsample_bytree=0.7000000000000001, model__gamma=1.0, model__learning_rate=0.14384498882876628, model__max_depth=9, model__min_child_weight=3.0, model__n_estimators=200, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.192) r2: (test=0.853) total time=11.4min\n",
      "[CV 1/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.5555555555555556, model__learning_rate=0.007847599703514606, model__max_depth=9, model__min_child_weight=1.0, model__n_estimators=400, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.184) r2: (test=0.863) total time=11.6min\n",
      "[CV 5/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.1111111111111111, model__learning_rate=0.3792690190732246, model__max_depth=8, model__min_child_weight=4.0, model__n_estimators=500, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.166) r2: (test=0.889) total time=11.2min\n",
      "[CV 3/5] END model__colsample_bytree=0.9, model__gamma=0.0, model__learning_rate=0.012742749857031334, model__max_depth=5, model__min_child_weight=3.0, model__n_estimators=200, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.183) r2: (test=0.890) total time=11.5min\n",
      "[CV 4/5] END model__colsample_bytree=0.7000000000000001, model__gamma=1.0, model__learning_rate=0.14384498882876628, model__max_depth=9, model__min_child_weight=3.0, model__n_estimators=200, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.198) r2: (test=0.845) total time=11.4min\n",
      "[CV 1/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.2222222222222222, model__learning_rate=1.0, model__max_depth=5, model__min_child_weight=9.0, model__n_estimators=600, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.197) r2: (test=0.860) total time=11.3min\n",
      "[CV 5/5] END model__colsample_bytree=0.5, model__gamma=0.1111111111111111, model__learning_rate=0.03359818286283781, model__max_depth=4, model__min_child_weight=10.0, model__n_estimators=700, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.158) r2: (test=0.898) total time=11.6min\n",
      "[CV 5/5] END model__colsample_bytree=0.5, model__gamma=0.4444444444444444, model__learning_rate=0.03359818286283781, model__max_depth=7, model__min_child_weight=8.0, model__n_estimators=300, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.177) r2: (test=0.883) total time=11.2min\n",
      "[CV 3/5] END model__colsample_bytree=0.6, model__gamma=0.6666666666666666, model__learning_rate=0.23357214690901212, model__max_depth=9, model__min_child_weight=3.0, model__n_estimators=700, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.180) r2: (test=0.898) total time=11.6min\n",
      "[CV 1/5] END model__colsample_bytree=0.1, model__gamma=0.2222222222222222, model__learning_rate=0.14384498882876628, model__max_depth=5, model__min_child_weight=10.0, model__n_estimators=100, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.170) r2: (test=0.881) total time=11.2min\n",
      "[CV 3/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.1111111111111111, model__learning_rate=0.3792690190732246, model__max_depth=8, model__min_child_weight=4.0, model__n_estimators=500, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.166) r2: (test=0.910) total time=11.4min\n",
      "[CV 2/5] END model__colsample_bytree=0.1, model__gamma=0.2222222222222222, model__learning_rate=0.14384498882876628, model__max_depth=5, model__min_child_weight=10.0, model__n_estimators=100, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.148) r2: (test=0.909) total time=11.1min\n",
      "[CV 3/5] END model__colsample_bytree=0.5, model__gamma=0.4444444444444444, model__learning_rate=0.03359818286283781, model__max_depth=7, model__min_child_weight=8.0, model__n_estimators=300, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.179) r2: (test=0.900) total time=11.3min\n",
      "[CV 2/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.1111111111111111, model__learning_rate=0.3792690190732246, model__max_depth=8, model__min_child_weight=4.0, model__n_estimators=500, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.157) r2: (test=0.891) total time=11.5min\n",
      "[CV 2/5] END model__colsample_bytree=0.6, model__gamma=0.7777777777777777, model__learning_rate=0.0001, model__max_depth=3, model__min_child_weight=2.0, model__n_estimators=500, model__subsample=1.0; neg_mean_absolute_error: (test=-0.532) r2: (test=0.049) total time=11.4min\n",
      "[CV 5/5] END model__colsample_bytree=0.6, model__gamma=0.7777777777777777, model__learning_rate=0.0001, model__max_depth=3, model__min_child_weight=2.0, model__n_estimators=500, model__subsample=1.0; neg_mean_absolute_error: (test=-0.532) r2: (test=0.051) total time=11.4min\n",
      "[CV 4/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.7777777777777777, model__learning_rate=0.0006951927961775605, model__max_depth=6, model__min_child_weight=9.0, model__n_estimators=200, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.509) r2: (test=0.157) total time=11.4min\n",
      "[CV 4/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.1111111111111111, model__learning_rate=0.3792690190732246, model__max_depth=8, model__min_child_weight=4.0, model__n_estimators=500, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.161) r2: (test=0.875) total time=11.4min\n",
      "[CV 5/5] END model__colsample_bytree=0.6, model__gamma=0.0, model__learning_rate=0.0001623776739188721, model__max_depth=None, model__min_child_weight=6.0, model__n_estimators=300, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.527) r2: (test=0.068) total time=11.5min\n",
      "[CV 1/5] END model__colsample_bytree=0.5, model__gamma=0.4444444444444444, model__learning_rate=0.03359818286283781, model__max_depth=7, model__min_child_weight=8.0, model__n_estimators=300, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.174) r2: (test=0.872) total time=11.3min\n",
      "[CV 5/5] END model__colsample_bytree=0.1, model__gamma=0.2222222222222222, model__learning_rate=0.14384498882876628, model__max_depth=5, model__min_child_weight=10.0, model__n_estimators=100, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.171) r2: (test=0.889) total time=11.0min\n",
      "[CV 3/5] END model__colsample_bytree=0.6, model__gamma=0.0, model__learning_rate=0.0001623776739188721, model__max_depth=None, model__min_child_weight=6.0, model__n_estimators=300, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.585) r2: (test=0.067) total time=11.6min\n",
      "[CV 2/5] END model__colsample_bytree=0.5, model__gamma=0.4444444444444444, model__learning_rate=0.03359818286283781, model__max_depth=7, model__min_child_weight=8.0, model__n_estimators=300, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.153) r2: (test=0.901) total time=11.4min\n",
      "[CV 3/5] END model__colsample_bytree=0.1, model__gamma=0.2222222222222222, model__learning_rate=0.14384498882876628, model__max_depth=5, model__min_child_weight=10.0, model__n_estimators=100, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.158) r2: (test=0.916) total time=11.1min\n",
      "[CV 4/5] END model__colsample_bytree=0.5, model__gamma=0.4444444444444444, model__learning_rate=0.03359818286283781, model__max_depth=7, model__min_child_weight=8.0, model__n_estimators=300, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.179) r2: (test=0.866) total time=11.4min\n",
      "[CV 2/5] END model__colsample_bytree=0.8, model__gamma=1.0, model__learning_rate=0.05455594781168514, model__max_depth=10, model__min_child_weight=10.0, model__n_estimators=300, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.168) r2: (test=0.888) total time=10.9min\n",
      "[CV 1/5] END model__colsample_bytree=0.8, model__gamma=1.0, model__learning_rate=0.05455594781168514, model__max_depth=10, model__min_child_weight=10.0, model__n_estimators=300, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.194) r2: (test=0.853) total time=11.3min\n",
      "[CV 4/5] END model__colsample_bytree=0.8, model__gamma=1.0, model__learning_rate=0.05455594781168514, model__max_depth=10, model__min_child_weight=10.0, model__n_estimators=300, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.202) r2: (test=0.841) total time=10.9min\n",
      "[CV 5/5] END model__colsample_bytree=0.8, model__gamma=1.0, model__learning_rate=0.05455594781168514, model__max_depth=10, model__min_child_weight=10.0, model__n_estimators=300, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.189) r2: (test=0.863) total time=11.2min\n",
      "[CV 5/5] END model__colsample_bytree=0.8, model__gamma=0.1111111111111111, model__learning_rate=0.03359818286283781, model__max_depth=None, model__min_child_weight=8.0, model__n_estimators=200, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.164) r2: (test=0.897) total time=18.4min\n",
      "[CV 1/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.7777777777777777, model__learning_rate=0.0006951927961775605, model__max_depth=6, model__min_child_weight=9.0, model__n_estimators=200, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.507) r2: (test=0.164) total time=19.1min\n",
      "[CV 2/5] END model__colsample_bytree=0.9, model__gamma=0.0, model__learning_rate=0.012742749857031334, model__max_depth=5, model__min_child_weight=3.0, model__n_estimators=200, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.161) r2: (test=0.890) total time=19.0min\n",
      "[CV 4/5] END model__colsample_bytree=0.9, model__gamma=0.0, model__learning_rate=0.012742749857031334, model__max_depth=5, model__min_child_weight=3.0, model__n_estimators=200, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.181) r2: (test=0.860) total time=19.8min\n",
      "[CV 1/5] END model__colsample_bytree=0.6, model__gamma=0.7777777777777777, model__learning_rate=0.0001, model__max_depth=3, model__min_child_weight=2.0, model__n_estimators=500, model__subsample=1.0; neg_mean_absolute_error: (test=-0.542) r2: (test=0.053) total time=18.5min\n",
      "[CV 4/5] END model__colsample_bytree=0.6, model__gamma=0.7777777777777777, model__learning_rate=0.0001, model__max_depth=3, model__min_child_weight=2.0, model__n_estimators=500, model__subsample=1.0; neg_mean_absolute_error: (test=-0.543) r2: (test=0.051) total time=18.1min\n",
      "[CV 3/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.7777777777777777, model__learning_rate=0.0006951927961775605, model__max_depth=6, model__min_child_weight=9.0, model__n_estimators=200, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.551) r2: (test=0.166) total time=19.1min\n",
      "[CV 5/5] END model__colsample_bytree=0.9, model__gamma=0.0, model__learning_rate=0.012742749857031334, model__max_depth=5, model__min_child_weight=3.0, model__n_estimators=200, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.171) r2: (test=0.885) total time=18.9min\n",
      "[CV 5/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.7777777777777777, model__learning_rate=0.0006951927961775605, model__max_depth=6, model__min_child_weight=9.0, model__n_estimators=200, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.496) r2: (test=0.165) total time=19.0min\n",
      "[CV 2/5] END model__colsample_bytree=0.7000000000000001, model__gamma=1.0, model__learning_rate=0.14384498882876628, model__max_depth=9, model__min_child_weight=3.0, model__n_estimators=200, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.165) r2: (test=0.893) total time=18.5min\n",
      "[CV 3/5] END model__colsample_bytree=0.6, model__gamma=0.7777777777777777, model__learning_rate=0.0001, model__max_depth=3, model__min_child_weight=2.0, model__n_estimators=500, model__subsample=1.0; neg_mean_absolute_error: (test=-0.589) r2: (test=0.054) total time=19.4min\n",
      "[CV 2/5] END model__colsample_bytree=0.1, model__gamma=0.2222222222222222, model__learning_rate=0.0001623776739188721, model__max_depth=7, model__min_child_weight=4.0, model__n_estimators=400, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.529) r2: (test=0.062) total time= 9.9min\n",
      "[CV 1/5] END model__colsample_bytree=0.4, model__gamma=0.2222222222222222, model__learning_rate=0.3792690190732246, model__max_depth=8, model__min_child_weight=3.0, model__n_estimators=900, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.163) r2: (test=0.886) total time=10.0min\n",
      "[CV 4/5] END model__colsample_bytree=0.30000000000000004, model__gamma=1.0, model__learning_rate=0.08858667904100823, model__max_depth=10, model__min_child_weight=2.0, model__n_estimators=100, model__subsample=0.5; neg_mean_absolute_error: (test=-0.209) r2: (test=0.839) total time= 9.7min\n",
      "[CV 2/5] END model__colsample_bytree=0.9, model__gamma=0.3333333333333333, model__learning_rate=0.05455594781168514, model__max_depth=6, model__min_child_weight=6.0, model__n_estimators=500, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.156) r2: (test=0.895) total time= 9.7min\n",
      "[CV 4/5] END model__colsample_bytree=1.0, model__gamma=0.8888888888888888, model__learning_rate=0.00026366508987303583, model__max_depth=3, model__min_child_weight=4.0, model__n_estimators=800, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.494) r2: (test=0.196) total time= 9.8min\n",
      "[CV 3/5] END model__colsample_bytree=0.5, model__gamma=0.3333333333333333, model__learning_rate=0.0011288378916846883, model__max_depth=None, model__min_child_weight=1.0, model__n_estimators=100, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.556) r2: (test=0.155) total time= 9.6min\n",
      "[CV 4/5] END model__colsample_bytree=0.9, model__gamma=0.3333333333333333, model__learning_rate=0.05455594781168514, model__max_depth=6, model__min_child_weight=6.0, model__n_estimators=500, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.174) r2: (test=0.867) total time= 9.7min\n",
      "[CV 2/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.2222222222222222, model__learning_rate=1.0, model__max_depth=5, model__min_child_weight=9.0, model__n_estimators=600, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.230) r2: (test=0.805) total time=10.2min\n",
      "[CV 3/5] END model__colsample_bytree=0.1, model__gamma=0.5555555555555556, model__learning_rate=0.03359818286283781, model__max_depth=8, model__min_child_weight=5.0, model__n_estimators=800, model__subsample=0.5; neg_mean_absolute_error: (test=-0.184) r2: (test=0.898) total time= 9.7min\n",
      "[CV 5/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.2222222222222222, model__learning_rate=1.0, model__max_depth=5, model__min_child_weight=9.0, model__n_estimators=600, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.193) r2: (test=0.856) total time=10.0min\n",
      "[CV 3/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.2222222222222222, model__learning_rate=1.0, model__max_depth=5, model__min_child_weight=9.0, model__n_estimators=600, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.195) r2: (test=0.892) total time=10.1min\n",
      "[CV 1/5] END model__colsample_bytree=0.1, model__gamma=0.2222222222222222, model__learning_rate=0.0001623776739188721, model__max_depth=7, model__min_child_weight=4.0, model__n_estimators=400, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.539) r2: (test=0.060) total time=10.0min\n",
      "[CV 5/5] END model__colsample_bytree=1.0, model__gamma=0.8888888888888888, model__learning_rate=0.00026366508987303583, model__max_depth=3, model__min_child_weight=4.0, model__n_estimators=800, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.477) r2: (test=0.207) total time= 9.8min\n",
      "[CV 5/5] END model__colsample_bytree=0.4, model__gamma=0.2222222222222222, model__learning_rate=0.3792690190732246, model__max_depth=8, model__min_child_weight=3.0, model__n_estimators=900, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.162) r2: (test=0.896) total time=10.0min\n",
      "[CV 4/5] END model__colsample_bytree=0.4, model__gamma=0.2222222222222222, model__learning_rate=0.3792690190732246, model__max_depth=8, model__min_child_weight=3.0, model__n_estimators=900, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.170) r2: (test=0.872) total time=10.0min\n",
      "[CV 5/5] END model__colsample_bytree=0.8, model__gamma=0.0, model__learning_rate=0.00026366508987303583, model__max_depth=5, model__min_child_weight=5.0, model__n_estimators=600, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.480) r2: (test=0.213) total time= 9.8min\n",
      "[CV 5/5] END model__colsample_bytree=0.1, model__gamma=0.2222222222222222, model__learning_rate=0.0001623776739188721, model__max_depth=7, model__min_child_weight=4.0, model__n_estimators=400, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.528) r2: (test=0.066) total time= 9.9min\n",
      "[CV 4/5] END model__colsample_bytree=0.1, model__gamma=0.2222222222222222, model__learning_rate=0.0001623776739188721, model__max_depth=7, model__min_child_weight=4.0, model__n_estimators=400, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.538) r2: (test=0.068) total time= 9.9min\n",
      "[CV 1/5] END model__colsample_bytree=0.8, model__gamma=0.0, model__learning_rate=0.00026366508987303583, model__max_depth=5, model__min_child_weight=5.0, model__n_estimators=600, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.493) r2: (test=0.211) total time= 9.9min\n",
      "[CV 2/5] END model__colsample_bytree=0.8, model__gamma=0.0, model__learning_rate=0.00026366508987303583, model__max_depth=5, model__min_child_weight=5.0, model__n_estimators=600, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.481) r2: (test=0.214) total time= 9.9min\n",
      "[CV 3/5] END model__colsample_bytree=0.30000000000000004, model__gamma=1.0, model__learning_rate=0.08858667904100823, model__max_depth=10, model__min_child_weight=2.0, model__n_estimators=100, model__subsample=0.5; neg_mean_absolute_error: (test=-0.202) r2: (test=0.879) total time= 9.8min\n",
      "[CV 2/5] END model__colsample_bytree=0.4, model__gamma=0.2222222222222222, model__learning_rate=0.3792690190732246, model__max_depth=8, model__min_child_weight=3.0, model__n_estimators=900, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.159) r2: (test=0.888) total time=10.0min\n",
      "[CV 2/5] END model__colsample_bytree=0.30000000000000004, model__gamma=1.0, model__learning_rate=0.08858667904100823, model__max_depth=10, model__min_child_weight=2.0, model__n_estimators=100, model__subsample=0.5; neg_mean_absolute_error: (test=-0.173) r2: (test=0.888) total time= 9.8min\n",
      "[CV 5/5] END model__colsample_bytree=0.9, model__gamma=0.3333333333333333, model__learning_rate=0.05455594781168514, model__max_depth=6, model__min_child_weight=6.0, model__n_estimators=500, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.169) r2: (test=0.892) total time= 9.7min\n",
      "[CV 3/5] END model__colsample_bytree=0.4, model__gamma=0.2222222222222222, model__learning_rate=0.3792690190732246, model__max_depth=8, model__min_child_weight=3.0, model__n_estimators=900, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.180) r2: (test=0.901) total time=10.1min\n",
      "[CV 4/5] END model__colsample_bytree=0.1, model__gamma=0.3333333333333333, model__learning_rate=0.05455594781168514, model__max_depth=None, model__min_child_weight=5.0, model__n_estimators=900, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.175) r2: (test=0.866) total time= 9.7min\n",
      "[CV 3/5] END model__colsample_bytree=0.9, model__gamma=0.3333333333333333, model__learning_rate=0.05455594781168514, model__max_depth=6, model__min_child_weight=6.0, model__n_estimators=500, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.174) r2: (test=0.901) total time= 9.8min\n",
      "[CV 4/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.2222222222222222, model__learning_rate=1.0, model__max_depth=5, model__min_child_weight=9.0, model__n_estimators=600, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.178) r2: (test=0.865) total time=10.1min\n",
      "[CV 2/5] END model__colsample_bytree=1.0, model__gamma=0.8888888888888888, model__learning_rate=0.00026366508987303583, model__max_depth=3, model__min_child_weight=4.0, model__n_estimators=800, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.473) r2: (test=0.232) total time= 9.8min\n",
      "[CV 3/5] END model__colsample_bytree=0.1, model__gamma=0.2222222222222222, model__learning_rate=0.0001623776739188721, model__max_depth=7, model__min_child_weight=4.0, model__n_estimators=400, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.584) r2: (test=0.071) total time=10.0min\n",
      "[CV 3/5] END model__colsample_bytree=0.8, model__gamma=0.0, model__learning_rate=0.00026366508987303583, model__max_depth=5, model__min_child_weight=5.0, model__n_estimators=600, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.537) r2: (test=0.206) total time= 9.9min\n",
      "[CV 4/5] END model__colsample_bytree=0.8, model__gamma=0.0, model__learning_rate=0.00026366508987303583, model__max_depth=5, model__min_child_weight=5.0, model__n_estimators=600, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.494) r2: (test=0.201) total time= 9.9min\n",
      "[CV 3/5] END model__colsample_bytree=1.0, model__gamma=0.8888888888888888, model__learning_rate=0.00026366508987303583, model__max_depth=3, model__min_child_weight=4.0, model__n_estimators=800, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.535) r2: (test=0.212) total time= 9.9min\n",
      "[CV 5/5] END model__colsample_bytree=0.30000000000000004, model__gamma=1.0, model__learning_rate=0.08858667904100823, model__max_depth=10, model__min_child_weight=2.0, model__n_estimators=100, model__subsample=0.5; neg_mean_absolute_error: (test=-0.199) r2: (test=0.856) total time= 9.8min\n",
      "[CV 1/5] END model__colsample_bytree=0.30000000000000004, model__gamma=1.0, model__learning_rate=0.08858667904100823, model__max_depth=10, model__min_child_weight=2.0, model__n_estimators=100, model__subsample=0.5; neg_mean_absolute_error: (test=-0.207) r2: (test=0.838) total time= 9.8min\n",
      "[CV 4/5] END model__colsample_bytree=0.5, model__gamma=0.3333333333333333, model__learning_rate=0.0011288378916846883, model__max_depth=None, model__min_child_weight=1.0, model__n_estimators=100, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.510) r2: (test=0.154) total time= 9.6min\n",
      "[CV 2/5] END model__colsample_bytree=0.1, model__gamma=0.5555555555555556, model__learning_rate=0.03359818286283781, model__max_depth=8, model__min_child_weight=5.0, model__n_estimators=800, model__subsample=0.5; neg_mean_absolute_error: (test=-0.159) r2: (test=0.899) total time= 9.7min\n",
      "[CV 1/5] END model__colsample_bytree=0.1, model__gamma=0.3333333333333333, model__learning_rate=0.05455594781168514, model__max_depth=None, model__min_child_weight=5.0, model__n_estimators=900, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.166) r2: (test=0.884) total time= 9.8min\n",
      "[CV 3/5] END model__colsample_bytree=0.1, model__gamma=0.3333333333333333, model__learning_rate=0.05455594781168514, model__max_depth=None, model__min_child_weight=5.0, model__n_estimators=900, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.167) r2: (test=0.910) total time= 9.8min\n",
      "[CV 1/5] END model__colsample_bytree=0.5, model__gamma=0.3333333333333333, model__learning_rate=0.0011288378916846883, model__max_depth=None, model__min_child_weight=1.0, model__n_estimators=100, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.510) r2: (test=0.158) total time= 9.7min\n",
      "[CV 2/5] END model__colsample_bytree=0.1, model__gamma=0.4444444444444444, model__learning_rate=0.23357214690901212, model__max_depth=None, model__min_child_weight=6.0, model__n_estimators=200, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.157) r2: (test=0.901) total time= 9.6min\n",
      "[CV 1/5] END model__colsample_bytree=0.1, model__gamma=0.4444444444444444, model__learning_rate=0.23357214690901212, model__max_depth=None, model__min_child_weight=6.0, model__n_estimators=200, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.170) r2: (test=0.885) total time= 9.6min\n",
      "[CV 1/5] END model__colsample_bytree=0.9, model__gamma=0.3333333333333333, model__learning_rate=0.05455594781168514, model__max_depth=6, model__min_child_weight=6.0, model__n_estimators=500, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.173) r2: (test=0.870) total time= 9.8min\n",
      "[CV 1/5] END model__colsample_bytree=0.1, model__gamma=0.5555555555555556, model__learning_rate=0.03359818286283781, model__max_depth=8, model__min_child_weight=5.0, model__n_estimators=800, model__subsample=0.5; neg_mean_absolute_error: (test=-0.185) r2: (test=0.859) total time= 9.8min\n",
      "[CV 4/5] END model__colsample_bytree=0.1, model__gamma=0.5555555555555556, model__learning_rate=0.03359818286283781, model__max_depth=8, model__min_child_weight=5.0, model__n_estimators=800, model__subsample=0.5; neg_mean_absolute_error: (test=-0.195) r2: (test=0.853) total time= 9.8min\n",
      "[CV 2/5] END model__colsample_bytree=0.1, model__gamma=0.3333333333333333, model__learning_rate=0.05455594781168514, model__max_depth=None, model__min_child_weight=5.0, model__n_estimators=900, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.148) r2: (test=0.908) total time= 9.8min\n",
      "[CV 5/5] END model__colsample_bytree=0.5, model__gamma=0.3333333333333333, model__learning_rate=0.0011288378916846883, model__max_depth=None, model__min_child_weight=1.0, model__n_estimators=100, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.499) r2: (test=0.160) total time= 9.6min\n",
      "[CV 2/5] END model__colsample_bytree=0.5, model__gamma=0.3333333333333333, model__learning_rate=0.0011288378916846883, model__max_depth=None, model__min_child_weight=1.0, model__n_estimators=100, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.500) r2: (test=0.155) total time= 9.8min\n",
      "[CV 5/5] END model__colsample_bytree=0.1, model__gamma=0.5555555555555556, model__learning_rate=0.03359818286283781, model__max_depth=8, model__min_child_weight=5.0, model__n_estimators=800, model__subsample=0.5; neg_mean_absolute_error: (test=-0.191) r2: (test=0.866) total time= 9.8min\n",
      "[CV 1/5] END model__colsample_bytree=1.0, model__gamma=0.8888888888888888, model__learning_rate=0.00026366508987303583, model__max_depth=3, model__min_child_weight=4.0, model__n_estimators=800, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.485) r2: (test=0.235) total time=10.0min\n",
      "[CV 3/5] END model__colsample_bytree=0.1, model__gamma=0.4444444444444444, model__learning_rate=0.23357214690901212, model__max_depth=None, model__min_child_weight=6.0, model__n_estimators=200, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.171) r2: (test=0.905) total time= 9.5min\n",
      "[CV 4/5] END model__colsample_bytree=0.1, model__gamma=0.4444444444444444, model__learning_rate=0.23357214690901212, model__max_depth=None, model__min_child_weight=6.0, model__n_estimators=200, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.186) r2: (test=0.858) total time= 9.4min\n",
      "[CV 5/5] END model__colsample_bytree=0.1, model__gamma=0.3333333333333333, model__learning_rate=0.05455594781168514, model__max_depth=None, model__min_child_weight=5.0, model__n_estimators=900, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.173) r2: (test=0.890) total time= 9.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/utkarsh/miniconda3/lib/python3.11/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END model__colsample_bytree=1.0, model__gamma=0.6666666666666666, model__learning_rate=0.14384498882876628, model__max_depth=None, model__min_child_weight=2.0, model__n_estimators=1000, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.177) r2: (test=0.903) total time= 7.9min\n",
      "[CV 3/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.5555555555555556, model__learning_rate=0.08858667904100823, model__max_depth=8, model__min_child_weight=1.0, model__n_estimators=800, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.176) r2: (test=0.905) total time= 8.2min\n",
      "[CV 1/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.5555555555555556, model__learning_rate=0.08858667904100823, model__max_depth=8, model__min_child_weight=1.0, model__n_estimators=800, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.178) r2: (test=0.868) total time= 8.3min\n",
      "[CV 2/5] END model__colsample_bytree=1.0, model__gamma=0.7777777777777777, model__learning_rate=0.0011288378916846883, model__max_depth=7, model__min_child_weight=1.0, model__n_estimators=100, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.497) r2: (test=0.163) total time= 8.0min\n",
      "[CV 3/5] END model__colsample_bytree=1.0, model__gamma=0.7777777777777777, model__learning_rate=0.0011288378916846883, model__max_depth=7, model__min_child_weight=1.0, model__n_estimators=100, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.554) r2: (test=0.160) total time= 8.0min\n",
      "[CV 2/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.1111111111111111, model__learning_rate=0.0011288378916846883, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=500, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.354) r2: (test=0.562) total time= 8.0min\n",
      "[CV 5/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.5555555555555556, model__learning_rate=0.08858667904100823, model__max_depth=8, model__min_child_weight=1.0, model__n_estimators=800, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.176) r2: (test=0.888) total time= 8.2min\n",
      "[CV 4/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.5555555555555556, model__learning_rate=0.08858667904100823, model__max_depth=8, model__min_child_weight=1.0, model__n_estimators=800, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.181) r2: (test=0.864) total time= 8.2min\n",
      "[CV 5/5] END model__colsample_bytree=0.5, model__gamma=0.8888888888888888, model__learning_rate=0.007847599703514606, model__max_depth=6, model__min_child_weight=10.0, model__n_estimators=1000, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.197) r2: (test=0.858) total time= 8.1min\n",
      "[CV 1/5] END model__colsample_bytree=0.1, model__gamma=1.0, model__learning_rate=0.0206913808111479, model__max_depth=7, model__min_child_weight=3.0, model__n_estimators=600, model__subsample=1.0; neg_mean_absolute_error: (test=-0.186) r2: (test=0.864) total time= 7.9min\n",
      "[CV 2/5] END model__colsample_bytree=0.5, model__gamma=0.8888888888888888, model__learning_rate=0.007847599703514606, model__max_depth=6, model__min_child_weight=10.0, model__n_estimators=1000, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.171) r2: (test=0.888) total time= 8.2min\n",
      "[CV 3/5] END model__colsample_bytree=0.5, model__gamma=0.8888888888888888, model__learning_rate=0.007847599703514606, model__max_depth=6, model__min_child_weight=10.0, model__n_estimators=1000, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.198) r2: (test=0.880) total time= 8.2min\n",
      "[CV 4/5] END model__colsample_bytree=0.8, model__gamma=0.6666666666666666, model__learning_rate=0.002976351441631319, model__max_depth=8, model__min_child_weight=1.0, model__n_estimators=500, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.238) r2: (test=0.781) total time= 8.1min\n",
      "[CV 4/5] END model__colsample_bytree=1.0, model__gamma=0.7777777777777777, model__learning_rate=0.0011288378916846883, model__max_depth=7, model__min_child_weight=1.0, model__n_estimators=100, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.508) r2: (test=0.157) total time= 8.0min\n",
      "[CV 5/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.1111111111111111, model__learning_rate=0.0011288378916846883, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=500, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.349) r2: (test=0.556) total time= 8.1min\n",
      "[CV 5/5] END model__colsample_bytree=0.1, model__gamma=0.4444444444444444, model__learning_rate=0.23357214690901212, model__max_depth=None, model__min_child_weight=6.0, model__n_estimators=200, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.190) r2: (test=0.864) total time= 8.5min\n",
      "[CV 3/5] END model__colsample_bytree=0.6, model__gamma=0.1111111111111111, model__learning_rate=0.00026366508987303583, model__max_depth=6, model__min_child_weight=9.0, model__n_estimators=700, model__subsample=1.0; neg_mean_absolute_error: (test=-0.525) r2: (test=0.239) total time= 8.1min\n",
      "[CV 2/5] END model__colsample_bytree=1.0, model__gamma=0.6666666666666666, model__learning_rate=0.14384498882876628, model__max_depth=None, model__min_child_weight=2.0, model__n_estimators=1000, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.158) r2: (test=0.896) total time= 8.1min\n",
      "[CV 2/5] END model__colsample_bytree=0.6, model__gamma=0.1111111111111111, model__learning_rate=0.00026366508987303583, model__max_depth=6, model__min_child_weight=9.0, model__n_estimators=700, model__subsample=1.0; neg_mean_absolute_error: (test=-0.470) r2: (test=0.245) total time= 8.2min\n",
      "[CV 5/5] END model__colsample_bytree=1.0, model__gamma=0.6666666666666666, model__learning_rate=0.14384498882876628, model__max_depth=None, model__min_child_weight=2.0, model__n_estimators=1000, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.184) r2: (test=0.881) total time= 8.1min\n",
      "[CV 5/5] END model__colsample_bytree=0.6, model__gamma=0.1111111111111111, model__learning_rate=0.00026366508987303583, model__max_depth=6, model__min_child_weight=9.0, model__n_estimators=700, model__subsample=1.0; neg_mean_absolute_error: (test=-0.469) r2: (test=0.245) total time= 8.1min\n",
      "[CV 1/5] END model__colsample_bytree=1.0, model__gamma=0.7777777777777777, model__learning_rate=0.0011288378916846883, model__max_depth=7, model__min_child_weight=1.0, model__n_estimators=100, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.509) r2: (test=0.158) total time= 8.1min\n",
      "[CV 1/5] END model__colsample_bytree=0.5, model__gamma=0.8888888888888888, model__learning_rate=0.007847599703514606, model__max_depth=6, model__min_child_weight=10.0, model__n_estimators=1000, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.193) r2: (test=0.853) total time= 8.3min\n",
      "[CV 4/5] END model__colsample_bytree=0.5, model__gamma=0.8888888888888888, model__learning_rate=0.007847599703514606, model__max_depth=6, model__min_child_weight=10.0, model__n_estimators=1000, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.203) r2: (test=0.841) total time= 8.2min\n",
      "[CV 2/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.5555555555555556, model__learning_rate=0.08858667904100823, model__max_depth=8, model__min_child_weight=1.0, model__n_estimators=800, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.156) r2: (test=0.897) total time= 8.3min\n",
      "[CV 4/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.1111111111111111, model__learning_rate=0.0011288378916846883, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=500, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.369) r2: (test=0.530) total time= 8.1min\n",
      "[CV 2/5] END model__colsample_bytree=1.0, model__gamma=0.6666666666666666, model__learning_rate=0.007847599703514606, model__max_depth=3, model__min_child_weight=1.0, model__n_estimators=500, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.173) r2: (test=0.887) total time= 8.1min\n",
      "[CV 1/5] END model__colsample_bytree=1.0, model__gamma=0.6666666666666666, model__learning_rate=0.14384498882876628, model__max_depth=None, model__min_child_weight=2.0, model__n_estimators=1000, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.177) r2: (test=0.868) total time= 8.1min\n",
      "[CV 1/5] END model__colsample_bytree=0.6, model__gamma=0.1111111111111111, model__learning_rate=0.00026366508987303583, model__max_depth=6, model__min_child_weight=9.0, model__n_estimators=700, model__subsample=1.0; neg_mean_absolute_error: (test=-0.479) r2: (test=0.251) total time= 8.2min\n",
      "[CV 1/5] END model__colsample_bytree=1.0, model__gamma=0.6666666666666666, model__learning_rate=0.007847599703514606, model__max_depth=3, model__min_child_weight=1.0, model__n_estimators=500, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.189) r2: (test=0.858) total time= 8.1min\n",
      "[CV 1/5] END model__colsample_bytree=0.8, model__gamma=0.6666666666666666, model__learning_rate=0.002976351441631319, model__max_depth=8, model__min_child_weight=1.0, model__n_estimators=500, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.229) r2: (test=0.804) total time= 8.2min\n",
      "[CV 5/5] END model__colsample_bytree=0.8, model__gamma=0.6666666666666666, model__learning_rate=0.002976351441631319, model__max_depth=8, model__min_child_weight=1.0, model__n_estimators=500, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.221) r2: (test=0.816) total time= 8.2min\n",
      "[CV 4/5] END model__colsample_bytree=0.6, model__gamma=0.1111111111111111, model__learning_rate=0.00026366508987303583, model__max_depth=6, model__min_child_weight=9.0, model__n_estimators=700, model__subsample=1.0; neg_mean_absolute_error: (test=-0.483) r2: (test=0.232) total time= 8.2min\n",
      "[CV 2/5] END model__colsample_bytree=0.8, model__gamma=0.6666666666666666, model__learning_rate=0.002976351441631319, model__max_depth=8, model__min_child_weight=1.0, model__n_estimators=500, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.217) r2: (test=0.823) total time= 8.2min\n",
      "[CV 4/5] END model__colsample_bytree=1.0, model__gamma=0.6666666666666666, model__learning_rate=0.007847599703514606, model__max_depth=3, model__min_child_weight=1.0, model__n_estimators=500, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.208) r2: (test=0.837) total time= 8.1min\n",
      "[CV 3/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.1111111111111111, model__learning_rate=0.0011288378916846883, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=500, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.400) r2: (test=0.547) total time= 8.2min\n",
      "[CV 4/5] END model__colsample_bytree=1.0, model__gamma=0.6666666666666666, model__learning_rate=0.14384498882876628, model__max_depth=None, model__min_child_weight=2.0, model__n_estimators=1000, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.184) r2: (test=0.862) total time= 8.2min\n",
      "[CV 1/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.1111111111111111, model__learning_rate=0.0011288378916846883, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=500, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.359) r2: (test=0.560) total time= 8.2min\n",
      "[CV 3/5] END model__colsample_bytree=0.8, model__gamma=0.6666666666666666, model__learning_rate=0.002976351441631319, model__max_depth=8, model__min_child_weight=1.0, model__n_estimators=500, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.253) r2: (test=0.809) total time= 8.2min\n",
      "[CV 3/5] END model__colsample_bytree=1.0, model__gamma=0.6666666666666666, model__learning_rate=0.007847599703514606, model__max_depth=3, model__min_child_weight=1.0, model__n_estimators=500, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.192) r2: (test=0.886) total time= 8.1min\n",
      "[CV 2/5] END model__colsample_bytree=0.1, model__gamma=1.0, model__learning_rate=0.0206913808111479, model__max_depth=7, model__min_child_weight=3.0, model__n_estimators=600, model__subsample=1.0; neg_mean_absolute_error: (test=-0.170) r2: (test=0.890) total time= 8.2min\n",
      "[CV 5/5] END model__colsample_bytree=1.0, model__gamma=0.7777777777777777, model__learning_rate=0.0011288378916846883, model__max_depth=7, model__min_child_weight=1.0, model__n_estimators=100, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.495) r2: (test=0.171) total time= 8.2min\n",
      "[CV 3/5] END model__colsample_bytree=0.1, model__gamma=1.0, model__learning_rate=0.0206913808111479, model__max_depth=7, model__min_child_weight=3.0, model__n_estimators=600, model__subsample=1.0; neg_mean_absolute_error: (test=-0.198) r2: (test=0.880) total time= 8.1min\n",
      "[CV 4/5] END model__colsample_bytree=0.1, model__gamma=1.0, model__learning_rate=0.0206913808111479, model__max_depth=7, model__min_child_weight=3.0, model__n_estimators=600, model__subsample=1.0; neg_mean_absolute_error: (test=-0.203) r2: (test=0.840) total time= 8.1min\n",
      "[CV 4/5] END model__colsample_bytree=0.6, model__gamma=0.2222222222222222, model__learning_rate=0.3792690190732246, model__max_depth=9, model__min_child_weight=4.0, model__n_estimators=600, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.170) r2: (test=0.872) total time= 8.1min\n",
      "[CV 5/5] END model__colsample_bytree=0.1, model__gamma=1.0, model__learning_rate=0.0206913808111479, model__max_depth=7, model__min_child_weight=3.0, model__n_estimators=600, model__subsample=1.0; neg_mean_absolute_error: (test=-0.189) r2: (test=0.864) total time= 8.3min\n",
      "[CV 2/5] END model__colsample_bytree=0.6, model__gamma=0.2222222222222222, model__learning_rate=0.3792690190732246, model__max_depth=9, model__min_child_weight=4.0, model__n_estimators=600, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.162) r2: (test=0.883) total time= 8.3min\n",
      "[CV 3/5] END model__colsample_bytree=0.6, model__gamma=0.2222222222222222, model__learning_rate=0.3792690190732246, model__max_depth=9, model__min_child_weight=4.0, model__n_estimators=600, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.171) r2: (test=0.903) total time= 8.4min\n",
      "[CV 1/5] END model__colsample_bytree=0.6, model__gamma=0.2222222222222222, model__learning_rate=0.3792690190732246, model__max_depth=9, model__min_child_weight=4.0, model__n_estimators=600, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.167) r2: (test=0.880) total time= 8.4min\n",
      "[CV 5/5] END model__colsample_bytree=1.0, model__gamma=0.6666666666666666, model__learning_rate=0.007847599703514606, model__max_depth=3, model__min_child_weight=1.0, model__n_estimators=500, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.191) r2: (test=0.864) total time= 8.5min\n",
      "[CV 5/5] END model__colsample_bytree=0.6, model__gamma=0.2222222222222222, model__learning_rate=0.3792690190732246, model__max_depth=9, model__min_child_weight=4.0, model__n_estimators=600, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.177) r2: (test=0.878) total time=14.6min\n",
      "[CV 1/5] END model__colsample_bytree=0.5, model__gamma=0.8888888888888888, model__learning_rate=0.00026366508987303583, model__max_depth=7, model__min_child_weight=2.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.485) r2: (test=0.228) total time=13.2min\n",
      "[CV 2/5] END model__colsample_bytree=0.5, model__gamma=0.8888888888888888, model__learning_rate=0.00026366508987303583, model__max_depth=7, model__min_child_weight=2.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.474) r2: (test=0.232) total time= 9.9min\n",
      "[CV 2/5] END model__colsample_bytree=0.6, model__gamma=0.7777777777777777, model__learning_rate=0.05455594781168514, model__max_depth=7, model__min_child_weight=10.0, model__n_estimators=1000, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.167) r2: (test=0.891) total time= 7.4min\n",
      "[CV 1/5] END model__colsample_bytree=1.0, model__gamma=0.1111111111111111, model__learning_rate=0.0001623776739188721, model__max_depth=6, model__min_child_weight=9.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.512) r2: (test=0.149) total time= 7.6min\n",
      "[CV 5/5] END model__colsample_bytree=0.5, model__gamma=0.8888888888888888, model__learning_rate=0.00026366508987303583, model__max_depth=7, model__min_child_weight=2.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.472) r2: (test=0.234) total time= 7.6min\n",
      "[CV 3/5] END model__colsample_bytree=0.6, model__gamma=0.7777777777777777, model__learning_rate=0.05455594781168514, model__max_depth=7, model__min_child_weight=10.0, model__n_estimators=1000, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.186) r2: (test=0.894) total time= 7.5min\n",
      "[CV 4/5] END model__colsample_bytree=0.4, model__gamma=0.7777777777777777, model__learning_rate=0.3792690190732246, model__max_depth=3, model__min_child_weight=6.0, model__n_estimators=600, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.192) r2: (test=0.856) total time= 7.5min\n",
      "[CV 3/5] END model__colsample_bytree=0.8, model__gamma=0.5555555555555556, model__learning_rate=0.0006951927961775605, model__max_depth=3, model__min_child_weight=5.0, model__n_estimators=500, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.497) r2: (test=0.313) total time= 7.6min\n",
      "[CV 1/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.1111111111111111, model__learning_rate=1.0, model__max_depth=5, model__min_child_weight=6.0, model__n_estimators=800, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.198) r2: (test=0.834) total time= 7.5min\n",
      "[CV 5/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.1111111111111111, model__learning_rate=1.0, model__max_depth=5, model__min_child_weight=6.0, model__n_estimators=800, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.203) r2: (test=0.841) total time= 7.5min\n",
      "[CV 3/5] END model__colsample_bytree=1.0, model__gamma=0.1111111111111111, model__learning_rate=0.0001623776739188721, model__max_depth=6, model__min_child_weight=9.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.558) r2: (test=0.146) total time= 7.6min\n",
      "[CV 1/5] END model__colsample_bytree=0.8, model__gamma=0.5555555555555556, model__learning_rate=0.0006951927961775605, model__max_depth=3, model__min_child_weight=5.0, model__n_estimators=500, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.445) r2: (test=0.346) total time= 7.7min\n",
      "[CV 2/5] END model__colsample_bytree=0.8, model__gamma=0.5555555555555556, model__learning_rate=0.0006951927961775605, model__max_depth=3, model__min_child_weight=5.0, model__n_estimators=500, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.437) r2: (test=0.338) total time= 7.7min\n",
      "[CV 3/5] END model__colsample_bytree=0.5, model__gamma=0.8888888888888888, model__learning_rate=0.00026366508987303583, model__max_depth=7, model__min_child_weight=2.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.530) r2: (test=0.222) total time= 7.8min\n",
      "[CV 4/5] END model__colsample_bytree=0.6, model__gamma=0.7777777777777777, model__learning_rate=0.05455594781168514, model__max_depth=7, model__min_child_weight=10.0, model__n_estimators=1000, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.189) r2: (test=0.859) total time= 7.6min\n",
      "[CV 5/5] END model__colsample_bytree=1.0, model__gamma=0.0, model__learning_rate=0.012742749857031334, model__max_depth=6, model__min_child_weight=4.0, model__n_estimators=1000, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.169) r2: (test=0.880) total time= 7.6min\n",
      "[CV 2/5] END model__colsample_bytree=1.0, model__gamma=0.1111111111111111, model__learning_rate=0.0001623776739188721, model__max_depth=6, model__min_child_weight=9.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.500) r2: (test=0.149) total time= 7.7min\n",
      "[CV 4/5] END model__colsample_bytree=0.5, model__gamma=0.8888888888888888, model__learning_rate=0.00026366508987303583, model__max_depth=7, model__min_child_weight=2.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.488) r2: (test=0.218) total time= 7.8min\n",
      "[CV 5/5] END model__colsample_bytree=1.0, model__gamma=0.1111111111111111, model__learning_rate=0.0001623776739188721, model__max_depth=6, model__min_child_weight=9.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.500) r2: (test=0.151) total time= 7.7min\n",
      "[CV 5/5] END model__colsample_bytree=0.6, model__gamma=0.7777777777777777, model__learning_rate=0.05455594781168514, model__max_depth=7, model__min_child_weight=10.0, model__n_estimators=1000, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.187) r2: (test=0.872) total time= 7.6min\n",
      "[CV 2/5] END model__colsample_bytree=0.1, model__gamma=0.6666666666666666, model__learning_rate=0.012742749857031334, model__max_depth=5, model__min_child_weight=9.0, model__n_estimators=600, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.175) r2: (test=0.885) total time= 7.6min\n",
      "[CV 3/5] END model__colsample_bytree=0.4, model__gamma=0.7777777777777777, model__learning_rate=0.3792690190732246, model__max_depth=3, model__min_child_weight=6.0, model__n_estimators=600, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.191) r2: (test=0.892) total time= 7.6min\n",
      "[CV 1/5] END model__colsample_bytree=0.6, model__gamma=0.7777777777777777, model__learning_rate=0.05455594781168514, model__max_depth=7, model__min_child_weight=10.0, model__n_estimators=1000, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.187) r2: (test=0.858) total time= 7.6min\n",
      "[CV 1/5] END model__colsample_bytree=0.4, model__gamma=0.7777777777777777, model__learning_rate=0.3792690190732246, model__max_depth=3, model__min_child_weight=6.0, model__n_estimators=600, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.194) r2: (test=0.860) total time= 7.6min\n",
      "[CV 4/5] END model__colsample_bytree=1.0, model__gamma=0.1111111111111111, model__learning_rate=0.0001623776739188721, model__max_depth=6, model__min_child_weight=9.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.512) r2: (test=0.143) total time= 7.7min\n",
      "[CV 5/5] END model__colsample_bytree=0.8, model__gamma=0.5555555555555556, model__learning_rate=0.0006951927961775605, model__max_depth=3, model__min_child_weight=5.0, model__n_estimators=500, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.441) r2: (test=0.307) total time= 7.7min\n",
      "[CV 4/5] END model__colsample_bytree=0.8, model__gamma=0.5555555555555556, model__learning_rate=0.0006951927961775605, model__max_depth=3, model__min_child_weight=5.0, model__n_estimators=500, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.460) r2: (test=0.295) total time= 7.7min\n",
      "[CV 4/5] END model__colsample_bytree=0.1, model__gamma=0.6666666666666666, model__learning_rate=0.012742749857031334, model__max_depth=5, model__min_child_weight=9.0, model__n_estimators=600, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.204) r2: (test=0.836) total time= 7.6min\n",
      "[CV 4/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.1111111111111111, model__learning_rate=1.0, model__max_depth=5, model__min_child_weight=6.0, model__n_estimators=800, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.183) r2: (test=0.855) total time= 7.7min\n",
      "[CV 2/5] END model__colsample_bytree=0.4, model__gamma=0.7777777777777777, model__learning_rate=0.3792690190732246, model__max_depth=3, model__min_child_weight=6.0, model__n_estimators=600, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.182) r2: (test=0.871) total time= 7.8min\n",
      "[CV 1/5] END model__colsample_bytree=0.2, model__gamma=0.1111111111111111, model__learning_rate=0.3792690190732246, model__max_depth=8, model__min_child_weight=3.0, model__n_estimators=300, model__subsample=0.5; neg_mean_absolute_error: (test=-0.182) r2: (test=0.869) total time= 8.0min\n",
      "[CV 3/5] END model__colsample_bytree=1.0, model__gamma=0.0, model__learning_rate=0.012742749857031334, model__max_depth=6, model__min_child_weight=4.0, model__n_estimators=1000, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.175) r2: (test=0.890) total time= 8.4min\n",
      "[CV 4/5] END model__colsample_bytree=1.0, model__gamma=0.0, model__learning_rate=0.012742749857031334, model__max_depth=6, model__min_child_weight=4.0, model__n_estimators=1000, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.172) r2: (test=0.867) total time= 8.3min\n",
      "[CV 3/5] END model__colsample_bytree=0.2, model__gamma=0.1111111111111111, model__learning_rate=0.3792690190732246, model__max_depth=8, model__min_child_weight=3.0, model__n_estimators=300, model__subsample=0.5; neg_mean_absolute_error: (test=-0.179) r2: (test=0.892) total time= 8.1min\n",
      "[CV 2/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.1111111111111111, model__learning_rate=1.0, model__max_depth=5, model__min_child_weight=6.0, model__n_estimators=800, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.201) r2: (test=0.847) total time= 8.5min\n",
      "[CV 1/5] END model__colsample_bytree=1.0, model__gamma=0.0, model__learning_rate=0.012742749857031334, model__max_depth=6, model__min_child_weight=4.0, model__n_estimators=1000, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.169) r2: (test=0.874) total time= 9.2min\n",
      "[CV 3/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.1111111111111111, model__learning_rate=1.0, model__max_depth=5, model__min_child_weight=6.0, model__n_estimators=800, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.181) r2: (test=0.899) total time=10.3min\n",
      "[CV 3/5] END model__colsample_bytree=0.1, model__gamma=0.6666666666666666, model__learning_rate=0.012742749857031334, model__max_depth=5, model__min_child_weight=9.0, model__n_estimators=600, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.195) r2: (test=0.881) total time=10.8min\n",
      "[CV 2/5] END model__colsample_bytree=1.0, model__gamma=0.0, model__learning_rate=0.012742749857031334, model__max_depth=6, model__min_child_weight=4.0, model__n_estimators=1000, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.152) r2: (test=0.891) total time=11.5min\n",
      "[CV 2/5] END model__colsample_bytree=0.2, model__gamma=0.1111111111111111, model__learning_rate=0.3792690190732246, model__max_depth=8, model__min_child_weight=3.0, model__n_estimators=300, model__subsample=0.5; neg_mean_absolute_error: (test=-0.176) r2: (test=0.872) total time=12.3min\n",
      "[CV 5/5] END model__colsample_bytree=0.4, model__gamma=0.7777777777777777, model__learning_rate=0.3792690190732246, model__max_depth=3, model__min_child_weight=6.0, model__n_estimators=600, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.200) r2: (test=0.863) total time=13.9min\n",
      "[CV 4/5] END model__colsample_bytree=0.2, model__gamma=0.1111111111111111, model__learning_rate=0.3792690190732246, model__max_depth=8, model__min_child_weight=3.0, model__n_estimators=300, model__subsample=0.5; neg_mean_absolute_error: (test=-0.171) r2: (test=0.874) total time=14.4min\n",
      "[CV 5/5] END model__colsample_bytree=0.2, model__gamma=0.1111111111111111, model__learning_rate=0.3792690190732246, model__max_depth=8, model__min_child_weight=3.0, model__n_estimators=300, model__subsample=0.5; neg_mean_absolute_error: (test=-0.176) r2: (test=0.884) total time=14.6min\n",
      "[CV 1/5] END model__colsample_bytree=0.1, model__gamma=0.6666666666666666, model__learning_rate=0.012742749857031334, model__max_depth=5, model__min_child_weight=9.0, model__n_estimators=600, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.197) r2: (test=0.848) total time=14.7min\n",
      "[CV 1/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.0, model__learning_rate=0.615848211066026, model__max_depth=10, model__min_child_weight=1.0, model__n_estimators=700, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.199) r2: (test=0.848) total time=14.7min\n",
      "[CV 5/5] END model__colsample_bytree=0.1, model__gamma=0.6666666666666666, model__learning_rate=0.012742749857031334, model__max_depth=5, model__min_child_weight=9.0, model__n_estimators=600, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.205) r2: (test=0.849) total time=14.9min\n",
      "[CV 2/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.0, model__learning_rate=0.615848211066026, model__max_depth=10, model__min_child_weight=1.0, model__n_estimators=700, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.190) r2: (test=0.859) total time=14.4min\n",
      "[CV 2/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.6666666666666666, model__learning_rate=0.05455594781168514, model__max_depth=None, model__min_child_weight=3.0, model__n_estimators=200, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.159) r2: (test=0.900) total time= 7.7min\n",
      "[CV 5/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.6666666666666666, model__learning_rate=0.05455594781168514, model__max_depth=None, model__min_child_weight=3.0, model__n_estimators=200, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.178) r2: (test=0.880) total time= 7.7min\n",
      "[CV 2/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.0, model__learning_rate=0.08858667904100823, model__max_depth=5, model__min_child_weight=1.0, model__n_estimators=600, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.164) r2: (test=0.882) total time= 7.6min\n",
      "[CV 1/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.7777777777777777, model__learning_rate=1.0, model__max_depth=6, model__min_child_weight=10.0, model__n_estimators=500, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.210) r2: (test=0.805) total time= 7.8min\n",
      "[CV 2/5] END model__colsample_bytree=0.2, model__gamma=0.1111111111111111, model__learning_rate=0.05455594781168514, model__max_depth=9, model__min_child_weight=6.0, model__n_estimators=400, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.145) r2: (test=0.903) total time= 7.5min\n",
      "[CV 4/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.7777777777777777, model__learning_rate=1.0, model__max_depth=6, model__min_child_weight=10.0, model__n_estimators=500, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.199) r2: (test=0.833) total time= 7.9min\n",
      "[CV 4/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.0, model__learning_rate=0.08858667904100823, model__max_depth=5, model__min_child_weight=1.0, model__n_estimators=600, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.188) r2: (test=0.847) total time= 7.7min\n",
      "[CV 3/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.7777777777777777, model__learning_rate=1.0, model__max_depth=6, model__min_child_weight=10.0, model__n_estimators=500, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.236) r2: (test=0.851) total time= 8.1min\n",
      "[CV 3/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.6666666666666666, model__learning_rate=0.05455594781168514, model__max_depth=None, model__min_child_weight=3.0, model__n_estimators=200, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.185) r2: (test=0.894) total time= 7.8min\n",
      "[CV 1/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.0, model__learning_rate=0.08858667904100823, model__max_depth=5, model__min_child_weight=1.0, model__n_estimators=600, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.186) r2: (test=0.863) total time= 7.7min\n",
      "[CV 1/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.6666666666666666, model__learning_rate=0.05455594781168514, model__max_depth=None, model__min_child_weight=3.0, model__n_estimators=200, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.181) r2: (test=0.869) total time= 7.8min\n",
      "[CV 2/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.7777777777777777, model__learning_rate=1.0, model__max_depth=6, model__min_child_weight=10.0, model__n_estimators=500, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.197) r2: (test=0.842) total time= 7.8min\n",
      "[CV 4/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.6666666666666666, model__learning_rate=0.05455594781168514, model__max_depth=None, model__min_child_weight=3.0, model__n_estimators=200, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.188) r2: (test=0.855) total time= 7.7min\n",
      "[CV 5/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.0, model__learning_rate=0.08858667904100823, model__max_depth=5, model__min_child_weight=1.0, model__n_estimators=600, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.190) r2: (test=0.838) total time= 7.7min\n",
      "[CV 5/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.7777777777777777, model__learning_rate=1.0, model__max_depth=6, model__min_child_weight=10.0, model__n_estimators=500, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.215) r2: (test=0.846) total time= 7.9min\n",
      "[CV 3/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.0, model__learning_rate=0.08858667904100823, model__max_depth=5, model__min_child_weight=1.0, model__n_estimators=600, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.187) r2: (test=0.860) total time= 7.7min\n",
      "[CV 1/5] END model__colsample_bytree=0.9, model__gamma=0.0, model__learning_rate=0.14384498882876628, model__max_depth=5, model__min_child_weight=9.0, model__n_estimators=800, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.210) r2: (test=0.827) total time= 7.7min\n",
      "[CV 5/5] END model__colsample_bytree=0.2, model__gamma=0.1111111111111111, model__learning_rate=0.05455594781168514, model__max_depth=9, model__min_child_weight=6.0, model__n_estimators=400, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.159) r2: (test=0.902) total time= 7.6min\n",
      "[CV 2/5] END model__colsample_bytree=0.9, model__gamma=0.0, model__learning_rate=0.14384498882876628, model__max_depth=5, model__min_child_weight=9.0, model__n_estimators=800, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.180) r2: (test=0.863) total time= 7.7min\n",
      "[CV 4/5] END model__colsample_bytree=0.2, model__gamma=0.1111111111111111, model__learning_rate=0.05455594781168514, model__max_depth=9, model__min_child_weight=6.0, model__n_estimators=400, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.166) r2: (test=0.874) total time= 7.6min\n",
      "[CV 5/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.0, model__learning_rate=0.615848211066026, model__max_depth=10, model__min_child_weight=1.0, model__n_estimators=700, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.214) r2: (test=0.815) total time= 8.1min\n",
      "[CV 3/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.0, model__learning_rate=0.615848211066026, model__max_depth=10, model__min_child_weight=1.0, model__n_estimators=700, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.226) r2: (test=0.789) total time=12.4min\n",
      "[CV 4/5] END model__colsample_bytree=0.9, model__gamma=0.0, model__learning_rate=0.14384498882876628, model__max_depth=5, model__min_child_weight=9.0, model__n_estimators=800, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.184) r2: (test=0.852) total time= 7.8min\n",
      "[CV 3/5] END model__colsample_bytree=0.9, model__gamma=0.0, model__learning_rate=0.14384498882876628, model__max_depth=5, model__min_child_weight=9.0, model__n_estimators=800, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.190) r2: (test=0.857) total time= 7.8min\n",
      "[CV 1/5] END model__colsample_bytree=0.6, model__gamma=0.0, model__learning_rate=0.0006951927961775605, model__max_depth=8, model__min_child_weight=1.0, model__n_estimators=500, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.416) r2: (test=0.425) total time= 7.9min\n",
      "[CV 3/5] END model__colsample_bytree=0.6, model__gamma=0.0, model__learning_rate=0.0006951927961775605, model__max_depth=8, model__min_child_weight=1.0, model__n_estimators=500, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.460) r2: (test=0.410) total time= 7.9min\n",
      "[CV 5/5] END model__colsample_bytree=0.9, model__gamma=0.0, model__learning_rate=0.14384498882876628, model__max_depth=5, model__min_child_weight=9.0, model__n_estimators=800, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.202) r2: (test=0.823) total time= 7.9min\n",
      "[CV 1/5] END model__colsample_bytree=0.2, model__gamma=0.1111111111111111, model__learning_rate=0.05455594781168514, model__max_depth=9, model__min_child_weight=6.0, model__n_estimators=400, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.162) r2: (test=0.887) total time= 7.9min\n",
      "[CV 2/5] END model__colsample_bytree=0.6, model__gamma=0.0, model__learning_rate=0.0006951927961775605, model__max_depth=8, model__min_child_weight=1.0, model__n_estimators=500, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.412) r2: (test=0.419) total time= 7.9min\n",
      "[CV 4/5] END model__colsample_bytree=0.6, model__gamma=0.0, model__learning_rate=0.0006951927961775605, model__max_depth=8, model__min_child_weight=1.0, model__n_estimators=500, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.421) r2: (test=0.405) total time= 8.2min\n",
      "[CV 1/5] END model__colsample_bytree=0.9, model__gamma=0.3333333333333333, model__learning_rate=0.0001, model__max_depth=9, model__min_child_weight=9.0, model__n_estimators=600, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.532) r2: (test=0.085) total time= 8.3min\n",
      "[CV 3/5] END model__colsample_bytree=0.9, model__gamma=0.3333333333333333, model__learning_rate=0.0001, model__max_depth=9, model__min_child_weight=9.0, model__n_estimators=600, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.579) r2: (test=0.086) total time= 9.1min\n",
      "[CV 4/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.0, model__learning_rate=0.615848211066026, model__max_depth=10, model__min_child_weight=1.0, model__n_estimators=700, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.220) r2: (test=0.796) total time=11.7min\n",
      "[CV 3/5] END model__colsample_bytree=0.2, model__gamma=0.1111111111111111, model__learning_rate=0.05455594781168514, model__max_depth=9, model__min_child_weight=6.0, model__n_estimators=400, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.164) r2: (test=0.913) total time=11.6min\n",
      "[CV 2/5] END model__colsample_bytree=0.9, model__gamma=0.3333333333333333, model__learning_rate=0.0001, model__max_depth=9, model__min_child_weight=9.0, model__n_estimators=600, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.521) r2: (test=0.084) total time=11.6min\n",
      "[CV 5/5] END model__colsample_bytree=0.6, model__gamma=0.0, model__learning_rate=0.0006951927961775605, model__max_depth=8, model__min_child_weight=1.0, model__n_estimators=500, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.407) r2: (test=0.424) total time=13.3min\n",
      "[CV 1/5] END model__colsample_bytree=0.1, model__gamma=0.8888888888888888, model__learning_rate=0.007847599703514606, model__max_depth=5, model__min_child_weight=8.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.220) r2: (test=0.817) total time=13.2min\n",
      "[CV 5/5] END model__colsample_bytree=0.9, model__gamma=0.3333333333333333, model__learning_rate=0.0001, model__max_depth=9, model__min_child_weight=9.0, model__n_estimators=600, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.520) r2: (test=0.091) total time=12.9min\n",
      "[CV 2/5] END model__colsample_bytree=0.1, model__gamma=0.8888888888888888, model__learning_rate=0.007847599703514606, model__max_depth=5, model__min_child_weight=8.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.198) r2: (test=0.859) total time=12.3min\n",
      "[CV 4/5] END model__colsample_bytree=0.9, model__gamma=0.3333333333333333, model__learning_rate=0.0001, model__max_depth=9, model__min_child_weight=9.0, model__n_estimators=600, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.532) r2: (test=0.085) total time=13.0min\n",
      "[CV 3/5] END model__colsample_bytree=1.0, model__gamma=0.2222222222222222, model__learning_rate=0.3792690190732246, model__max_depth=5, model__min_child_weight=4.0, model__n_estimators=900, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.157) r2: (test=0.917) total time= 6.6min\n",
      "[CV 1/5] END model__colsample_bytree=0.9, model__gamma=0.3333333333333333, model__learning_rate=0.23357214690901212, model__max_depth=3, model__min_child_weight=3.0, model__n_estimators=500, model__subsample=0.5; neg_mean_absolute_error: (test=-0.178) r2: (test=0.864) total time= 8.1min\n",
      "[CV 4/5] END model__colsample_bytree=0.1, model__gamma=0.8888888888888888, model__learning_rate=0.007847599703514606, model__max_depth=5, model__min_child_weight=8.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.233) r2: (test=0.800) total time=10.5min\n",
      "[CV 5/5] END model__colsample_bytree=0.1, model__gamma=0.8888888888888888, model__learning_rate=0.007847599703514606, model__max_depth=5, model__min_child_weight=8.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.227) r2: (test=0.812) total time= 7.2min\n",
      "[CV 5/5] END model__colsample_bytree=1.0, model__gamma=0.2222222222222222, model__learning_rate=0.3792690190732246, model__max_depth=5, model__min_child_weight=4.0, model__n_estimators=900, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.171) r2: (test=0.880) total time= 6.6min\n",
      "[CV 4/5] END model__colsample_bytree=0.9, model__gamma=0.3333333333333333, model__learning_rate=0.23357214690901212, model__max_depth=3, model__min_child_weight=3.0, model__n_estimators=500, model__subsample=0.5; neg_mean_absolute_error: (test=-0.184) r2: (test=0.859) total time= 7.1min\n",
      "[CV 3/5] END model__colsample_bytree=0.8, model__gamma=0.8888888888888888, model__learning_rate=0.012742749857031334, model__max_depth=10, model__min_child_weight=5.0, model__n_estimators=200, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.208) r2: (test=0.867) total time= 7.0min\n",
      "[CV 1/5] END model__colsample_bytree=0.8, model__gamma=0.8888888888888888, model__learning_rate=0.012742749857031334, model__max_depth=10, model__min_child_weight=5.0, model__n_estimators=200, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.198) r2: (test=0.847) total time= 7.0min\n",
      "[CV 1/5] END model__colsample_bytree=0.5, model__gamma=0.8888888888888888, model__learning_rate=0.0001623776739188721, model__max_depth=None, model__min_child_weight=8.0, model__n_estimators=800, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.506) r2: (test=0.168) total time= 7.0min\n",
      "[CV 3/5] END model__colsample_bytree=0.9, model__gamma=0.3333333333333333, model__learning_rate=0.23357214690901212, model__max_depth=3, model__min_child_weight=3.0, model__n_estimators=500, model__subsample=0.5; neg_mean_absolute_error: (test=-0.164) r2: (test=0.911) total time= 7.1min\n",
      "[CV 5/5] END model__colsample_bytree=0.8, model__gamma=0.4444444444444444, model__learning_rate=1.0, model__max_depth=5, model__min_child_weight=4.0, model__n_estimators=500, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.201) r2: (test=0.846) total time= 6.7min\n",
      "[CV 5/5] END model__colsample_bytree=0.9, model__gamma=0.3333333333333333, model__learning_rate=0.23357214690901212, model__max_depth=3, model__min_child_weight=3.0, model__n_estimators=500, model__subsample=0.5; neg_mean_absolute_error: (test=-0.168) r2: (test=0.895) total time= 7.1min\n",
      "[CV 4/5] END model__colsample_bytree=0.8, model__gamma=0.8888888888888888, model__learning_rate=0.012742749857031334, model__max_depth=10, model__min_child_weight=5.0, model__n_estimators=200, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.207) r2: (test=0.832) total time= 7.0min\n",
      "[CV 3/5] END model__colsample_bytree=0.5, model__gamma=0.8888888888888888, model__learning_rate=0.0001623776739188721, model__max_depth=None, model__min_child_weight=8.0, model__n_estimators=800, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.552) r2: (test=0.164) total time= 6.9min\n",
      "[CV 3/5] END model__colsample_bytree=0.1, model__gamma=0.8888888888888888, model__learning_rate=0.007847599703514606, model__max_depth=5, model__min_child_weight=8.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.220) r2: (test=0.852) total time= 8.5min\n",
      "[CV 2/5] END model__colsample_bytree=0.8, model__gamma=0.8888888888888888, model__learning_rate=0.012742749857031334, model__max_depth=10, model__min_child_weight=5.0, model__n_estimators=200, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.180) r2: (test=0.874) total time= 6.7min\n",
      "[CV 4/5] END model__colsample_bytree=1.0, model__gamma=0.2222222222222222, model__learning_rate=0.3792690190732246, model__max_depth=5, model__min_child_weight=4.0, model__n_estimators=900, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.171) r2: (test=0.878) total time= 6.7min\n",
      "[CV 1/5] END model__colsample_bytree=0.8, model__gamma=0.4444444444444444, model__learning_rate=1.0, model__max_depth=5, model__min_child_weight=4.0, model__n_estimators=500, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.180) r2: (test=0.871) total time= 6.8min\n",
      "[CV 4/5] END model__colsample_bytree=0.9, model__gamma=0.2222222222222222, model__learning_rate=0.0006951927961775605, model__max_depth=5, model__min_child_weight=2.0, model__n_estimators=400, model__subsample=0.5; neg_mean_absolute_error: (test=-0.453) r2: (test=0.312) total time= 6.8min\n",
      "[CV 2/5] END model__colsample_bytree=0.5, model__gamma=0.8888888888888888, model__learning_rate=0.0001623776739188721, model__max_depth=None, model__min_child_weight=8.0, model__n_estimators=800, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.496) r2: (test=0.167) total time= 7.0min\n",
      "[CV 4/5] END model__colsample_bytree=0.5, model__gamma=0.8888888888888888, model__learning_rate=0.0001623776739188721, model__max_depth=None, model__min_child_weight=8.0, model__n_estimators=800, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.508) r2: (test=0.159) total time= 7.0min\n",
      "[CV 3/5] END model__colsample_bytree=0.8, model__gamma=0.4444444444444444, model__learning_rate=1.0, model__max_depth=5, model__min_child_weight=4.0, model__n_estimators=500, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.192) r2: (test=0.885) total time= 6.8min\n",
      "[CV 2/5] END model__colsample_bytree=0.9, model__gamma=0.2222222222222222, model__learning_rate=0.0006951927961775605, model__max_depth=5, model__min_child_weight=2.0, model__n_estimators=400, model__subsample=0.5; neg_mean_absolute_error: (test=-0.437) r2: (test=0.337) total time= 6.9min\n",
      "[CV 2/5] END model__colsample_bytree=0.9, model__gamma=0.3333333333333333, model__learning_rate=0.23357214690901212, model__max_depth=3, model__min_child_weight=3.0, model__n_estimators=500, model__subsample=0.5; neg_mean_absolute_error: (test=-0.163) r2: (test=0.893) total time= 6.9min\n",
      "[CV 5/5] END model__colsample_bytree=0.5, model__gamma=0.8888888888888888, model__learning_rate=0.0001623776739188721, model__max_depth=None, model__min_child_weight=8.0, model__n_estimators=800, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.495) r2: (test=0.169) total time= 7.0min\n",
      "[CV 5/5] END model__colsample_bytree=0.8, model__gamma=0.8888888888888888, model__learning_rate=0.012742749857031334, model__max_depth=10, model__min_child_weight=5.0, model__n_estimators=200, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.195) r2: (test=0.859) total time= 6.7min\n",
      "[CV 1/5] END model__colsample_bytree=0.2, model__gamma=0.6666666666666666, model__learning_rate=0.14384498882876628, model__max_depth=4, model__min_child_weight=1.0, model__n_estimators=300, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.188) r2: (test=0.868) total time= 6.8min\n",
      "[CV 1/5] END model__colsample_bytree=0.9, model__gamma=0.2222222222222222, model__learning_rate=0.0006951927961775605, model__max_depth=5, model__min_child_weight=2.0, model__n_estimators=400, model__subsample=0.5; neg_mean_absolute_error: (test=-0.449) r2: (test=0.330) total time= 7.0min\n",
      "[CV 5/5] END model__colsample_bytree=0.9, model__gamma=0.2222222222222222, model__learning_rate=0.0006951927961775605, model__max_depth=5, model__min_child_weight=2.0, model__n_estimators=400, model__subsample=0.5; neg_mean_absolute_error: (test=-0.436) r2: (test=0.331) total time= 6.9min\n",
      "[CV 3/5] END model__colsample_bytree=0.2, model__gamma=0.6666666666666666, model__learning_rate=0.14384498882876628, model__max_depth=4, model__min_child_weight=1.0, model__n_estimators=300, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.192) r2: (test=0.887) total time= 6.7min\n",
      "[CV 2/5] END model__colsample_bytree=0.8, model__gamma=0.4444444444444444, model__learning_rate=1.0, model__max_depth=5, model__min_child_weight=4.0, model__n_estimators=500, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.204) r2: (test=0.843) total time= 6.9min\n",
      "[CV 4/5] END model__colsample_bytree=0.8, model__gamma=0.4444444444444444, model__learning_rate=1.0, model__max_depth=5, model__min_child_weight=4.0, model__n_estimators=500, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.192) r2: (test=0.856) total time= 7.0min\n",
      "[CV 2/5] END model__colsample_bytree=1.0, model__gamma=0.2222222222222222, model__learning_rate=0.3792690190732246, model__max_depth=5, model__min_child_weight=4.0, model__n_estimators=900, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.166) r2: (test=0.885) total time= 7.1min\n",
      "[CV 1/5] END model__colsample_bytree=1.0, model__gamma=0.2222222222222222, model__learning_rate=0.3792690190732246, model__max_depth=5, model__min_child_weight=4.0, model__n_estimators=900, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.171) r2: (test=0.878) total time= 7.2min\n",
      "[CV 2/5] END model__colsample_bytree=0.2, model__gamma=0.6666666666666666, model__learning_rate=0.14384498882876628, model__max_depth=4, model__min_child_weight=1.0, model__n_estimators=300, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.163) r2: (test=0.894) total time= 8.2min\n",
      "[CV 3/5] END model__colsample_bytree=0.9, model__gamma=0.2222222222222222, model__learning_rate=0.0006951927961775605, model__max_depth=5, model__min_child_weight=2.0, model__n_estimators=400, model__subsample=0.5; neg_mean_absolute_error: (test=-0.494) r2: (test=0.318) total time=14.3min\n",
      "[CV 4/5] END model__colsample_bytree=0.2, model__gamma=0.6666666666666666, model__learning_rate=0.14384498882876628, model__max_depth=4, model__min_child_weight=1.0, model__n_estimators=300, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.189) r2: (test=0.856) total time=16.0min\n",
      "[CV 5/5] END model__colsample_bytree=0.2, model__gamma=0.6666666666666666, model__learning_rate=0.14384498882876628, model__max_depth=4, model__min_child_weight=1.0, model__n_estimators=300, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.189) r2: (test=0.871) total time=15.8min\n",
      "[CV 3/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.1111111111111111, model__learning_rate=0.05455594781168514, model__max_depth=9, model__min_child_weight=6.0, model__n_estimators=700, model__subsample=1.0; neg_mean_absolute_error: (test=-0.170) r2: (test=0.904) total time=10.0min\n",
      "[CV 4/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.1111111111111111, model__learning_rate=0.05455594781168514, model__max_depth=9, model__min_child_weight=6.0, model__n_estimators=700, model__subsample=1.0; neg_mean_absolute_error: (test=-0.169) r2: (test=0.873) total time=10.0min\n",
      "[CV 1/5] END model__colsample_bytree=1.0, model__gamma=1.0, model__learning_rate=0.0006951927961775605, model__max_depth=5, model__min_child_weight=4.0, model__n_estimators=300, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.474) r2: (test=0.260) total time=14.2min\n",
      "[CV 2/5] END model__colsample_bytree=1.0, model__gamma=1.0, model__learning_rate=0.0006951927961775605, model__max_depth=5, model__min_child_weight=4.0, model__n_estimators=300, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.459) r2: (test=0.273) total time=12.9min\n",
      "[CV 1/5] END model__colsample_bytree=0.30000000000000004, model__gamma=1.0, model__learning_rate=0.0206913808111479, model__max_depth=6, model__min_child_weight=4.0, model__n_estimators=100, model__subsample=0.5; neg_mean_absolute_error: (test=-0.236) r2: (test=0.795) total time=10.0min\n",
      "[CV 3/5] END model__colsample_bytree=0.5, model__gamma=1.0, model__learning_rate=0.3792690190732246, model__max_depth=10, model__min_child_weight=5.0, model__n_estimators=300, model__subsample=0.5; neg_mean_absolute_error: (test=-0.193) r2: (test=0.889) total time= 9.9min\n",
      "[CV 5/5] END model__colsample_bytree=1.0, model__gamma=1.0, model__learning_rate=0.00026366508987303583, model__max_depth=10, model__min_child_weight=8.0, model__n_estimators=200, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.524) r2: (test=0.079) total time=10.1min\n",
      "[CV 3/5] END model__colsample_bytree=0.4, model__gamma=0.0, model__learning_rate=0.3792690190732246, model__max_depth=4, model__min_child_weight=1.0, model__n_estimators=200, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.189) r2: (test=0.854) total time= 9.9min\n",
      "[CV 3/5] END model__colsample_bytree=1.0, model__gamma=1.0, model__learning_rate=0.0006951927961775605, model__max_depth=5, model__min_child_weight=4.0, model__n_estimators=300, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.519) r2: (test=0.251) total time=11.5min\n",
      "[CV 1/5] END model__colsample_bytree=0.4, model__gamma=0.0, model__learning_rate=0.3792690190732246, model__max_depth=4, model__min_child_weight=1.0, model__n_estimators=200, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.202) r2: (test=0.832) total time=10.0min\n",
      "[CV 5/5] END model__colsample_bytree=0.4, model__gamma=0.0, model__learning_rate=0.3792690190732246, model__max_depth=4, model__min_child_weight=1.0, model__n_estimators=200, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.211) r2: (test=0.827) total time= 9.9min\n",
      "[CV 4/5] END model__colsample_bytree=1.0, model__gamma=1.0, model__learning_rate=0.0006951927961775605, model__max_depth=5, model__min_child_weight=4.0, model__n_estimators=300, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.476) r2: (test=0.247) total time=10.1min\n",
      "[CV 2/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.1111111111111111, model__learning_rate=0.05455594781168514, model__max_depth=9, model__min_child_weight=6.0, model__n_estimators=700, model__subsample=1.0; neg_mean_absolute_error: (test=-0.150) r2: (test=0.898) total time=10.2min\n",
      "[CV 5/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.1111111111111111, model__learning_rate=0.05455594781168514, model__max_depth=9, model__min_child_weight=6.0, model__n_estimators=700, model__subsample=1.0; neg_mean_absolute_error: (test=-0.163) r2: (test=0.895) total time=10.1min\n",
      "[CV 4/5] END model__colsample_bytree=0.5, model__gamma=1.0, model__learning_rate=0.3792690190732246, model__max_depth=10, model__min_child_weight=5.0, model__n_estimators=300, model__subsample=0.5; neg_mean_absolute_error: (test=-0.185) r2: (test=0.854) total time= 9.9min\n",
      "[CV 1/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.1111111111111111, model__learning_rate=0.23357214690901212, model__max_depth=5, model__min_child_weight=7.0, model__n_estimators=100, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.165) r2: (test=0.882) total time=10.0min\n",
      "[CV 2/5] END model__colsample_bytree=0.5, model__gamma=1.0, model__learning_rate=0.3792690190732246, model__max_depth=10, model__min_child_weight=5.0, model__n_estimators=300, model__subsample=0.5; neg_mean_absolute_error: (test=-0.178) r2: (test=0.882) total time= 9.9min\n",
      "[CV 3/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.1111111111111111, model__learning_rate=0.23357214690901212, model__max_depth=5, model__min_child_weight=7.0, model__n_estimators=100, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.169) r2: (test=0.909) total time=10.2min\n",
      "[CV 3/5] END model__colsample_bytree=0.30000000000000004, model__gamma=1.0, model__learning_rate=0.0206913808111479, model__max_depth=6, model__min_child_weight=4.0, model__n_estimators=100, model__subsample=0.5; neg_mean_absolute_error: (test=-0.253) r2: (test=0.811) total time=10.0min\n",
      "[CV 5/5] END model__colsample_bytree=1.0, model__gamma=1.0, model__learning_rate=0.0006951927961775605, model__max_depth=5, model__min_child_weight=4.0, model__n_estimators=300, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.459) r2: (test=0.265) total time=10.4min\n",
      "[CV 5/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.1111111111111111, model__learning_rate=0.23357214690901212, model__max_depth=5, model__min_child_weight=7.0, model__n_estimators=100, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.167) r2: (test=0.890) total time=10.3min\n",
      "[CV 2/5] END model__colsample_bytree=0.30000000000000004, model__gamma=1.0, model__learning_rate=0.0206913808111479, model__max_depth=6, model__min_child_weight=4.0, model__n_estimators=100, model__subsample=0.5; neg_mean_absolute_error: (test=-0.220) r2: (test=0.827) total time=10.1min\n",
      "[CV 4/5] END model__colsample_bytree=1.0, model__gamma=1.0, model__learning_rate=0.00026366508987303583, model__max_depth=10, model__min_child_weight=8.0, model__n_estimators=200, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.535) r2: (test=0.074) total time=10.1min\n",
      "[CV 2/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.1111111111111111, model__learning_rate=0.23357214690901212, model__max_depth=5, model__min_child_weight=7.0, model__n_estimators=100, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.155) r2: (test=0.890) total time=10.3min\n",
      "[CV 5/5] END model__colsample_bytree=0.30000000000000004, model__gamma=1.0, model__learning_rate=0.0206913808111479, model__max_depth=6, model__min_child_weight=4.0, model__n_estimators=100, model__subsample=0.5; neg_mean_absolute_error: (test=-0.230) r2: (test=0.799) total time=10.0min\n",
      "[CV 2/5] END model__colsample_bytree=0.4, model__gamma=0.0, model__learning_rate=0.3792690190732246, model__max_depth=4, model__min_child_weight=1.0, model__n_estimators=200, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.196) r2: (test=0.849) total time=10.0min\n",
      "[CV 4/5] END model__colsample_bytree=0.4, model__gamma=0.0, model__learning_rate=0.3792690190732246, model__max_depth=4, model__min_child_weight=1.0, model__n_estimators=200, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.187) r2: (test=0.848) total time=10.0min\n",
      "[CV 2/5] END model__colsample_bytree=0.9, model__gamma=0.5555555555555556, model__learning_rate=0.23357214690901212, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=600, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.165) r2: (test=0.893) total time= 9.9min\n",
      "[CV 4/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.1111111111111111, model__learning_rate=0.23357214690901212, model__max_depth=5, model__min_child_weight=7.0, model__n_estimators=100, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.169) r2: (test=0.870) total time= 9.9min\n",
      "[CV 1/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.1111111111111111, model__learning_rate=0.05455594781168514, model__max_depth=9, model__min_child_weight=6.0, model__n_estimators=700, model__subsample=1.0; neg_mean_absolute_error: (test=-0.164) r2: (test=0.879) total time= 9.9min\n",
      "[CV 1/5] END model__colsample_bytree=1.0, model__gamma=0.5555555555555556, model__learning_rate=0.004832930238571752, model__max_depth=None, model__min_child_weight=2.0, model__n_estimators=1000, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.182) r2: (test=0.863) total time=10.0min\n",
      "[CV 5/5] END model__colsample_bytree=0.5, model__gamma=1.0, model__learning_rate=0.3792690190732246, model__max_depth=10, model__min_child_weight=5.0, model__n_estimators=300, model__subsample=0.5; neg_mean_absolute_error: (test=-0.195) r2: (test=0.873) total time=10.0min\n",
      "[CV 1/5] END model__colsample_bytree=0.9, model__gamma=0.7777777777777777, model__learning_rate=0.00026366508987303583, model__max_depth=7, model__min_child_weight=8.0, model__n_estimators=1000, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.450) r2: (test=0.333) total time=10.0min\n",
      "[CV 2/5] END model__colsample_bytree=1.0, model__gamma=0.5555555555555556, model__learning_rate=0.004832930238571752, model__max_depth=None, model__min_child_weight=2.0, model__n_estimators=1000, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.161) r2: (test=0.894) total time=10.0min\n",
      "[CV 4/5] END model__colsample_bytree=0.30000000000000004, model__gamma=1.0, model__learning_rate=0.0206913808111479, model__max_depth=6, model__min_child_weight=4.0, model__n_estimators=100, model__subsample=0.5; neg_mean_absolute_error: (test=-0.250) r2: (test=0.772) total time=10.2min\n",
      "[CV 1/5] END model__colsample_bytree=0.9, model__gamma=0.5555555555555556, model__learning_rate=0.23357214690901212, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=600, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.175) r2: (test=0.870) total time=10.1min\n",
      "[CV 4/5] END model__colsample_bytree=0.9, model__gamma=0.7777777777777777, model__learning_rate=0.00026366508987303583, model__max_depth=7, model__min_child_weight=8.0, model__n_estimators=1000, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.453) r2: (test=0.311) total time=10.2min\n",
      "[CV 4/5] END model__colsample_bytree=0.4, model__gamma=0.0, model__learning_rate=0.00026366508987303583, model__max_depth=10, model__min_child_weight=2.0, model__n_estimators=600, model__subsample=1.0; neg_mean_absolute_error: (test=-0.489) r2: (test=0.220) total time=10.3min\n",
      "[CV 1/5] END model__colsample_bytree=0.4, model__gamma=0.0, model__learning_rate=0.00026366508987303583, model__max_depth=10, model__min_child_weight=2.0, model__n_estimators=600, model__subsample=1.0; neg_mean_absolute_error: (test=-0.487) r2: (test=0.228) total time=10.4min\n",
      "[CV 5/5] END model__colsample_bytree=1.0, model__gamma=0.5555555555555556, model__learning_rate=0.004832930238571752, model__max_depth=None, model__min_child_weight=2.0, model__n_estimators=1000, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.178) r2: (test=0.881) total time=10.2min\n",
      "[CV 2/5] END model__colsample_bytree=0.9, model__gamma=0.7777777777777777, model__learning_rate=0.00026366508987303583, model__max_depth=7, model__min_child_weight=8.0, model__n_estimators=1000, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.437) r2: (test=0.340) total time=10.3min\n",
      "[CV 2/5] END model__colsample_bytree=0.4, model__gamma=0.0, model__learning_rate=0.00026366508987303583, model__max_depth=10, model__min_child_weight=2.0, model__n_estimators=600, model__subsample=1.0; neg_mean_absolute_error: (test=-0.480) r2: (test=0.221) total time=10.4min\n",
      "[CV 5/5] END model__colsample_bytree=0.9, model__gamma=0.7777777777777777, model__learning_rate=0.00026366508987303583, model__max_depth=7, model__min_child_weight=8.0, model__n_estimators=1000, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.435) r2: (test=0.338) total time=10.3min\n",
      "[CV 4/5] END model__colsample_bytree=1.0, model__gamma=0.5555555555555556, model__learning_rate=0.004832930238571752, model__max_depth=None, model__min_child_weight=2.0, model__n_estimators=1000, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.187) r2: (test=0.857) total time=10.3min\n",
      "[CV 3/5] END model__colsample_bytree=0.4, model__gamma=0.0, model__learning_rate=0.00026366508987303583, model__max_depth=10, model__min_child_weight=2.0, model__n_estimators=600, model__subsample=1.0; neg_mean_absolute_error: (test=-0.532) r2: (test=0.222) total time=10.9min\n",
      "[CV 3/5] END model__colsample_bytree=1.0, model__gamma=0.5555555555555556, model__learning_rate=0.004832930238571752, model__max_depth=None, model__min_child_weight=2.0, model__n_estimators=1000, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.182) r2: (test=0.896) total time=10.9min\n",
      "[CV 3/5] END model__colsample_bytree=0.9, model__gamma=0.7777777777777777, model__learning_rate=0.00026366508987303583, model__max_depth=7, model__min_child_weight=8.0, model__n_estimators=1000, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.494) r2: (test=0.321) total time=13.2min\n",
      "[CV 1/5] END model__colsample_bytree=1.0, model__gamma=1.0, model__learning_rate=0.00026366508987303583, model__max_depth=10, model__min_child_weight=8.0, model__n_estimators=200, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.537) r2: (test=0.072) total time=13.7min\n",
      "[CV 5/5] END model__colsample_bytree=0.4, model__gamma=0.0, model__learning_rate=0.00026366508987303583, model__max_depth=10, model__min_child_weight=2.0, model__n_estimators=600, model__subsample=1.0; neg_mean_absolute_error: (test=-0.477) r2: (test=0.231) total time=14.3min\n",
      "[CV 3/5] END model__colsample_bytree=0.9, model__gamma=0.5555555555555556, model__learning_rate=0.23357214690901212, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=600, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.181) r2: (test=0.899) total time=18.6min\n",
      "[CV 3/5] END model__colsample_bytree=1.0, model__gamma=1.0, model__learning_rate=0.00026366508987303583, model__max_depth=10, model__min_child_weight=8.0, model__n_estimators=200, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.582) r2: (test=0.076) total time=18.2min\n",
      "[CV 2/5] END model__colsample_bytree=1.0, model__gamma=1.0, model__learning_rate=0.00026366508987303583, model__max_depth=10, model__min_child_weight=8.0, model__n_estimators=200, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.524) r2: (test=0.074) total time=18.1min\n",
      "[CV 4/5] END model__colsample_bytree=0.9, model__gamma=0.5555555555555556, model__learning_rate=0.23357214690901212, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=600, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.180) r2: (test=0.858) total time=18.2min\n",
      "[CV 1/5] END model__colsample_bytree=0.5, model__gamma=1.0, model__learning_rate=0.3792690190732246, model__max_depth=10, model__min_child_weight=5.0, model__n_estimators=300, model__subsample=0.5; neg_mean_absolute_error: (test=-0.190) r2: (test=0.851) total time=18.0min\n",
      "[CV 4/5] END model__colsample_bytree=1.0, model__gamma=0.0, model__learning_rate=0.05455594781168514, model__max_depth=None, model__min_child_weight=7.0, model__n_estimators=200, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.172) r2: (test=0.868) total time= 9.2min\n",
      "[CV 5/5] END model__colsample_bytree=0.9, model__gamma=0.5555555555555556, model__learning_rate=0.23357214690901212, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=600, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.184) r2: (test=0.875) total time=13.2min\n",
      "[CV 3/5] END model__colsample_bytree=0.4, model__gamma=0.7777777777777777, model__learning_rate=0.23357214690901212, model__max_depth=7, model__min_child_weight=4.0, model__n_estimators=100, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.197) r2: (test=0.888) total time= 9.1min\n",
      "[CV 5/5] END model__colsample_bytree=0.4, model__gamma=0.7777777777777777, model__learning_rate=0.23357214690901212, model__max_depth=7, model__min_child_weight=4.0, model__n_estimators=100, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.175) r2: (test=0.887) total time= 9.2min\n",
      "[CV 3/5] END model__colsample_bytree=0.1, model__gamma=0.8888888888888888, model__learning_rate=0.007847599703514606, model__max_depth=8, model__min_child_weight=9.0, model__n_estimators=500, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.213) r2: (test=0.864) total time= 9.2min\n",
      "[CV 5/5] END model__colsample_bytree=0.1, model__gamma=0.8888888888888888, model__learning_rate=0.007847599703514606, model__max_depth=8, model__min_child_weight=9.0, model__n_estimators=500, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.210) r2: (test=0.835) total time= 9.2min\n",
      "[CV 2/5] END model__colsample_bytree=1.0, model__gamma=0.0, model__learning_rate=0.05455594781168514, model__max_depth=None, model__min_child_weight=7.0, model__n_estimators=200, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.151) r2: (test=0.889) total time= 9.3min\n",
      "[CV 1/5] END model__colsample_bytree=0.1, model__gamma=0.8888888888888888, model__learning_rate=0.007847599703514606, model__max_depth=8, model__min_child_weight=9.0, model__n_estimators=500, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.209) r2: (test=0.834) total time= 9.2min\n",
      "[CV 2/5] END model__colsample_bytree=0.1, model__gamma=0.8888888888888888, model__learning_rate=0.00026366508987303583, model__max_depth=7, model__min_child_weight=6.0, model__n_estimators=400, model__subsample=0.5; neg_mean_absolute_error: (test=-0.520) r2: (test=0.091) total time= 9.2min\n",
      "[CV 1/5] END model__colsample_bytree=0.4, model__gamma=0.7777777777777777, model__learning_rate=0.23357214690901212, model__max_depth=7, model__min_child_weight=4.0, model__n_estimators=100, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.179) r2: (test=0.870) total time= 9.2min\n",
      "[CV 5/5] END model__colsample_bytree=0.1, model__gamma=0.8888888888888888, model__learning_rate=0.00026366508987303583, model__max_depth=7, model__min_child_weight=6.0, model__n_estimators=400, model__subsample=0.5; neg_mean_absolute_error: (test=-0.519) r2: (test=0.092) total time= 9.2min\n",
      "[CV 1/5] END model__colsample_bytree=0.1, model__gamma=0.8888888888888888, model__learning_rate=0.00026366508987303583, model__max_depth=7, model__min_child_weight=6.0, model__n_estimators=400, model__subsample=0.5; neg_mean_absolute_error: (test=-0.530) r2: (test=0.088) total time= 9.2min\n",
      "[CV 3/5] END model__colsample_bytree=0.1, model__gamma=0.8888888888888888, model__learning_rate=0.00026366508987303583, model__max_depth=7, model__min_child_weight=6.0, model__n_estimators=400, model__subsample=0.5; neg_mean_absolute_error: (test=-0.574) r2: (test=0.098) total time= 9.2min\n",
      "[CV 3/5] END model__colsample_bytree=0.8, model__gamma=0.3333333333333333, model__learning_rate=0.00042813323987193956, model__max_depth=10, model__min_child_weight=5.0, model__n_estimators=300, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.550) r2: (test=0.171) total time= 9.0min\n",
      "[CV 5/5] END model__colsample_bytree=1.0, model__gamma=0.5555555555555556, model__learning_rate=0.0001, model__max_depth=7, model__min_child_weight=1.0, model__n_estimators=900, model__subsample=0.5; neg_mean_absolute_error: (test=-0.507) r2: (test=0.130) total time= 9.6min\n",
      "[CV 2/5] END model__colsample_bytree=0.1, model__gamma=0.8888888888888888, model__learning_rate=0.007847599703514606, model__max_depth=8, model__min_child_weight=9.0, model__n_estimators=500, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.189) r2: (test=0.868) total time= 9.3min\n",
      "[CV 3/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.4444444444444444, model__learning_rate=0.0001, model__max_depth=7, model__min_child_weight=1.0, model__n_estimators=200, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.598) r2: (test=0.028) total time= 9.1min\n",
      "[CV 2/5] END model__colsample_bytree=0.9, model__gamma=0.6666666666666666, model__learning_rate=0.23357214690901212, model__max_depth=5, model__min_child_weight=1.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.159) r2: (test=0.894) total time= 9.2min\n",
      "[CV 3/5] END model__colsample_bytree=0.9, model__gamma=0.6666666666666666, model__learning_rate=0.23357214690901212, model__max_depth=5, model__min_child_weight=1.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.176) r2: (test=0.906) total time= 9.2min\n",
      "[CV 2/5] END model__colsample_bytree=0.2, model__gamma=0.4444444444444444, model__learning_rate=0.0018329807108324356, model__max_depth=7, model__min_child_weight=1.0, model__n_estimators=100, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.479) r2: (test=0.224) total time= 9.0min\n",
      "[CV 4/5] END model__colsample_bytree=0.1, model__gamma=0.8888888888888888, model__learning_rate=0.007847599703514606, model__max_depth=8, model__min_child_weight=9.0, model__n_estimators=500, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.220) r2: (test=0.814) total time= 9.3min\n",
      "[CV 2/5] END model__colsample_bytree=0.4, model__gamma=0.7777777777777777, model__learning_rate=0.23357214690901212, model__max_depth=7, model__min_child_weight=4.0, model__n_estimators=100, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.162) r2: (test=0.893) total time= 9.3min\n",
      "[CV 1/5] END model__colsample_bytree=1.0, model__gamma=0.5555555555555556, model__learning_rate=0.0001, model__max_depth=7, model__min_child_weight=1.0, model__n_estimators=900, model__subsample=0.5; neg_mean_absolute_error: (test=-0.521) r2: (test=0.120) total time=11.1min\n",
      "[CV 1/5] END model__colsample_bytree=1.0, model__gamma=0.0, model__learning_rate=0.05455594781168514, model__max_depth=None, model__min_child_weight=7.0, model__n_estimators=200, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.170) r2: (test=0.875) total time= 9.4min\n",
      "[CV 4/5] END model__colsample_bytree=0.4, model__gamma=0.7777777777777777, model__learning_rate=0.23357214690901212, model__max_depth=7, model__min_child_weight=4.0, model__n_estimators=100, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.197) r2: (test=0.846) total time= 9.3min\n",
      "[CV 4/5] END model__colsample_bytree=0.1, model__gamma=0.8888888888888888, model__learning_rate=0.00026366508987303583, model__max_depth=7, model__min_child_weight=6.0, model__n_estimators=400, model__subsample=0.5; neg_mean_absolute_error: (test=-0.529) r2: (test=0.093) total time= 9.3min\n",
      "[CV 4/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.4444444444444444, model__learning_rate=0.0001, model__max_depth=7, model__min_child_weight=1.0, model__n_estimators=200, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.550) r2: (test=0.028) total time= 9.1min\n",
      "[CV 5/5] END model__colsample_bytree=1.0, model__gamma=0.0, model__learning_rate=0.05455594781168514, model__max_depth=None, model__min_child_weight=7.0, model__n_estimators=200, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.171) r2: (test=0.882) total time= 9.4min\n",
      "[CV 1/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.4444444444444444, model__learning_rate=0.0001, model__max_depth=7, model__min_child_weight=1.0, model__n_estimators=200, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.552) r2: (test=0.021) total time= 9.2min\n",
      "[CV 4/5] END model__colsample_bytree=1.0, model__gamma=0.5555555555555556, model__learning_rate=0.0001, model__max_depth=7, model__min_child_weight=1.0, model__n_estimators=900, model__subsample=0.5; neg_mean_absolute_error: (test=-0.520) r2: (test=0.120) total time=10.7min\n",
      "[CV 3/5] END model__colsample_bytree=1.0, model__gamma=0.0, model__learning_rate=0.05455594781168514, model__max_depth=None, model__min_child_weight=7.0, model__n_estimators=200, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.174) r2: (test=0.895) total time= 9.4min\n",
      "[CV 5/5] END model__colsample_bytree=0.8, model__gamma=0.3333333333333333, model__learning_rate=0.00042813323987193956, model__max_depth=10, model__min_child_weight=5.0, model__n_estimators=300, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.491) r2: (test=0.180) total time= 9.0min\n",
      "[CV 3/5] END model__colsample_bytree=0.2, model__gamma=0.4444444444444444, model__learning_rate=0.0018329807108324356, model__max_depth=7, model__min_child_weight=1.0, model__n_estimators=100, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.529) r2: (test=0.228) total time= 9.0min\n",
      "[CV 5/5] END model__colsample_bytree=0.9, model__gamma=0.6666666666666666, model__learning_rate=0.23357214690901212, model__max_depth=5, model__min_child_weight=1.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.187) r2: (test=0.877) total time= 9.2min\n",
      "[CV 1/5] END model__colsample_bytree=0.8, model__gamma=0.3333333333333333, model__learning_rate=0.00042813323987193956, model__max_depth=10, model__min_child_weight=5.0, model__n_estimators=300, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.504) r2: (test=0.175) total time= 9.2min\n",
      "[CV 4/5] END model__colsample_bytree=0.9, model__gamma=0.6666666666666666, model__learning_rate=0.23357214690901212, model__max_depth=5, model__min_child_weight=1.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.182) r2: (test=0.869) total time= 9.3min\n",
      "[CV 4/5] END model__colsample_bytree=0.8, model__gamma=0.3333333333333333, model__learning_rate=0.00042813323987193956, model__max_depth=10, model__min_child_weight=5.0, model__n_estimators=300, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.505) r2: (test=0.168) total time= 9.2min\n",
      "[CV 2/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.4444444444444444, model__learning_rate=0.0001, model__max_depth=7, model__min_child_weight=1.0, model__n_estimators=200, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.541) r2: (test=0.019) total time= 9.3min\n",
      "[CV 5/5] END model__colsample_bytree=1.0, model__gamma=0.0, model__learning_rate=0.03359818286283781, model__max_depth=8, model__min_child_weight=3.0, model__n_estimators=800, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.189) r2: (test=0.851) total time= 9.6min\n",
      "[CV 1/5] END model__colsample_bytree=0.2, model__gamma=0.4444444444444444, model__learning_rate=0.0018329807108324356, model__max_depth=7, model__min_child_weight=1.0, model__n_estimators=100, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.486) r2: (test=0.228) total time= 9.1min\n",
      "[CV 2/5] END model__colsample_bytree=0.8, model__gamma=0.3333333333333333, model__learning_rate=0.00042813323987193956, model__max_depth=10, model__min_child_weight=5.0, model__n_estimators=300, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.492) r2: (test=0.177) total time= 9.3min\n",
      "[CV 4/5] END model__colsample_bytree=1.0, model__gamma=0.0, model__learning_rate=0.03359818286283781, model__max_depth=8, model__min_child_weight=3.0, model__n_estimators=800, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.183) r2: (test=0.852) total time= 9.6min\n",
      "[CV 2/5] END model__colsample_bytree=1.0, model__gamma=0.5555555555555556, model__learning_rate=0.0001, model__max_depth=7, model__min_child_weight=1.0, model__n_estimators=900, model__subsample=0.5; neg_mean_absolute_error: (test=-0.508) r2: (test=0.125) total time= 9.9min\n",
      "[CV 3/5] END model__colsample_bytree=1.0, model__gamma=0.5555555555555556, model__learning_rate=0.0001, model__max_depth=7, model__min_child_weight=1.0, model__n_estimators=900, model__subsample=0.5; neg_mean_absolute_error: (test=-0.566) r2: (test=0.121) total time= 9.8min\n",
      "[CV 1/5] END model__colsample_bytree=0.9, model__gamma=0.6666666666666666, model__learning_rate=0.23357214690901212, model__max_depth=5, model__min_child_weight=1.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.191) r2: (test=0.852) total time=13.0min\n",
      "[CV 1/5] END model__colsample_bytree=1.0, model__gamma=0.0, model__learning_rate=0.03359818286283781, model__max_depth=8, model__min_child_weight=3.0, model__n_estimators=800, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.185) r2: (test=0.852) total time=13.6min\n",
      "[CV 2/5] END model__colsample_bytree=1.0, model__gamma=0.0, model__learning_rate=0.03359818286283781, model__max_depth=8, model__min_child_weight=3.0, model__n_estimators=800, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.164) r2: (test=0.881) total time=14.2min\n",
      "[CV 3/5] END model__colsample_bytree=1.0, model__gamma=0.0, model__learning_rate=0.03359818286283781, model__max_depth=8, model__min_child_weight=3.0, model__n_estimators=800, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.189) r2: (test=0.858) total time=16.3min\n",
      "[CV 5/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.4444444444444444, model__learning_rate=0.0001, model__max_depth=7, model__min_child_weight=1.0, model__n_estimators=200, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.540) r2: (test=0.028) total time=17.8min\n",
      "[CV 5/5] END model__colsample_bytree=0.2, model__gamma=0.4444444444444444, model__learning_rate=0.0018329807108324356, model__max_depth=7, model__min_child_weight=1.0, model__n_estimators=100, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.476) r2: (test=0.228) total time=17.0min\n",
      "[CV 1/5] END model__colsample_bytree=1.0, model__gamma=0.5555555555555556, model__learning_rate=0.05455594781168514, model__max_depth=8, model__min_child_weight=1.0, model__n_estimators=600, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.180) r2: (test=0.865) total time=16.7min\n",
      "[CV 5/5] END model__colsample_bytree=0.5, model__gamma=0.1111111111111111, model__learning_rate=0.3792690190732246, model__max_depth=None, model__min_child_weight=8.0, model__n_estimators=100, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.160) r2: (test=0.898) total time= 9.2min\n",
      "[CV 4/5] END model__colsample_bytree=0.5, model__gamma=0.1111111111111111, model__learning_rate=0.3792690190732246, model__max_depth=None, model__min_child_weight=8.0, model__n_estimators=100, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.175) r2: (test=0.864) total time= 9.2min\n",
      "[CV 4/5] END model__colsample_bytree=0.2, model__gamma=0.4444444444444444, model__learning_rate=0.0018329807108324356, model__max_depth=7, model__min_child_weight=1.0, model__n_estimators=100, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.487) r2: (test=0.220) total time=15.3min\n",
      "[CV 3/5] END model__colsample_bytree=0.6, model__gamma=0.3333333333333333, model__learning_rate=0.03359818286283781, model__max_depth=3, model__min_child_weight=8.0, model__n_estimators=100, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.197) r2: (test=0.878) total time= 9.0min\n",
      "[CV 4/5] END model__colsample_bytree=1.0, model__gamma=0.5555555555555556, model__learning_rate=0.05455594781168514, model__max_depth=8, model__min_child_weight=1.0, model__n_estimators=600, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.180) r2: (test=0.863) total time=12.2min\n",
      "[CV 3/5] END model__colsample_bytree=0.5, model__gamma=0.1111111111111111, model__learning_rate=0.3792690190732246, model__max_depth=None, model__min_child_weight=8.0, model__n_estimators=100, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.174) r2: (test=0.904) total time= 9.3min\n",
      "[CV 1/5] END model__colsample_bytree=0.5, model__gamma=0.1111111111111111, model__learning_rate=0.3792690190732246, model__max_depth=None, model__min_child_weight=8.0, model__n_estimators=100, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.162) r2: (test=0.890) total time= 9.5min\n",
      "[CV 4/5] END model__colsample_bytree=0.6, model__gamma=0.3333333333333333, model__learning_rate=0.03359818286283781, model__max_depth=3, model__min_child_weight=8.0, model__n_estimators=100, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.202) r2: (test=0.841) total time= 9.1min\n",
      "[CV 1/5] END model__colsample_bytree=0.6, model__gamma=0.3333333333333333, model__learning_rate=0.03359818286283781, model__max_depth=3, model__min_child_weight=8.0, model__n_estimators=100, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.185) r2: (test=0.861) total time= 9.1min\n",
      "[CV 5/5] END model__colsample_bytree=1.0, model__gamma=0.5555555555555556, model__learning_rate=0.05455594781168514, model__max_depth=8, model__min_child_weight=1.0, model__n_estimators=600, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.176) r2: (test=0.884) total time=10.7min\n",
      "[CV 5/5] END model__colsample_bytree=0.1, model__gamma=0.1111111111111111, model__learning_rate=0.0011288378916846883, model__max_depth=None, model__min_child_weight=9.0, model__n_estimators=500, model__subsample=0.5; neg_mean_absolute_error: (test=-0.421) r2: (test=0.364) total time= 9.0min\n",
      "[CV 2/5] END model__colsample_bytree=0.6, model__gamma=0.3333333333333333, model__learning_rate=0.03359818286283781, model__max_depth=3, model__min_child_weight=8.0, model__n_estimators=100, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.174) r2: (test=0.885) total time= 9.2min\n",
      "[CV 3/5] END model__colsample_bytree=0.9, model__gamma=0.1111111111111111, model__learning_rate=0.002976351441631319, model__max_depth=3, model__min_child_weight=2.0, model__n_estimators=100, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.511) r2: (test=0.279) total time= 9.2min\n",
      "[CV 3/5] END model__colsample_bytree=1.0, model__gamma=0.5555555555555556, model__learning_rate=0.05455594781168514, model__max_depth=8, model__min_child_weight=1.0, model__n_estimators=600, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.178) r2: (test=0.899) total time= 9.5min\n",
      "[CV 1/5] END model__colsample_bytree=0.1, model__gamma=0.1111111111111111, model__learning_rate=0.0011288378916846883, model__max_depth=None, model__min_child_weight=9.0, model__n_estimators=500, model__subsample=0.5; neg_mean_absolute_error: (test=-0.428) r2: (test=0.372) total time= 9.0min\n",
      "[CV 4/5] END model__colsample_bytree=0.1, model__gamma=0.0, model__learning_rate=0.00026366508987303583, model__max_depth=8, model__min_child_weight=2.0, model__n_estimators=500, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.512) r2: (test=0.148) total time= 9.2min\n",
      "[CV 2/5] END model__colsample_bytree=0.5, model__gamma=0.1111111111111111, model__learning_rate=0.3792690190732246, model__max_depth=None, model__min_child_weight=8.0, model__n_estimators=100, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.170) r2: (test=0.879) total time= 9.4min\n",
      "[CV 1/5] END model__colsample_bytree=0.1, model__gamma=0.0, model__learning_rate=0.00026366508987303583, model__max_depth=8, model__min_child_weight=2.0, model__n_estimators=500, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.513) r2: (test=0.144) total time= 9.3min\n",
      "[CV 5/5] END model__colsample_bytree=0.9, model__gamma=0.1111111111111111, model__learning_rate=0.002976351441631319, model__max_depth=3, model__min_child_weight=2.0, model__n_estimators=100, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.455) r2: (test=0.275) total time= 9.2min\n",
      "[CV 2/5] END model__colsample_bytree=0.6, model__gamma=0.2222222222222222, model__learning_rate=0.0001623776739188721, model__max_depth=3, model__min_child_weight=3.0, model__n_estimators=300, model__subsample=1.0; neg_mean_absolute_error: (test=-0.532) r2: (test=0.047) total time= 9.0min\n",
      "[CV 2/5] END model__colsample_bytree=0.9, model__gamma=0.1111111111111111, model__learning_rate=0.002976351441631319, model__max_depth=3, model__min_child_weight=2.0, model__n_estimators=100, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.450) r2: (test=0.304) total time= 9.2min\n",
      "[CV 2/5] END model__colsample_bytree=1.0, model__gamma=0.5555555555555556, model__learning_rate=0.05455594781168514, model__max_depth=8, model__min_child_weight=1.0, model__n_estimators=600, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.159) r2: (test=0.899) total time=11.0min\n",
      "[CV 4/5] END model__colsample_bytree=0.2, model__gamma=0.3333333333333333, model__learning_rate=1.0, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.206) r2: (test=0.839) total time= 9.0min\n",
      "[CV 4/5] END model__colsample_bytree=0.9, model__gamma=0.1111111111111111, model__learning_rate=0.002976351441631319, model__max_depth=3, model__min_child_weight=2.0, model__n_estimators=100, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.472) r2: (test=0.264) total time= 9.2min\n",
      "[CV 2/5] END model__colsample_bytree=0.1, model__gamma=0.0, model__learning_rate=0.00026366508987303583, model__max_depth=8, model__min_child_weight=2.0, model__n_estimators=500, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.504) r2: (test=0.146) total time= 9.3min\n",
      "[CV 5/5] END model__colsample_bytree=0.6, model__gamma=0.3333333333333333, model__learning_rate=0.03359818286283781, model__max_depth=3, model__min_child_weight=8.0, model__n_estimators=100, model__subsample=0.8333333333333333; neg_mean_absolute_error: (test=-0.191) r2: (test=0.861) total time= 9.2min\n",
      "[CV 1/5] END model__colsample_bytree=0.6, model__gamma=0.2222222222222222, model__learning_rate=0.0001623776739188721, model__max_depth=3, model__min_child_weight=3.0, model__n_estimators=300, model__subsample=1.0; neg_mean_absolute_error: (test=-0.543) r2: (test=0.052) total time= 9.1min\n",
      "[CV 1/5] END model__colsample_bytree=0.9, model__gamma=0.1111111111111111, model__learning_rate=0.002976351441631319, model__max_depth=3, model__min_child_weight=2.0, model__n_estimators=100, model__subsample=0.5555555555555556; neg_mean_absolute_error: (test=-0.460) r2: (test=0.309) total time= 9.3min\n",
      "[CV 2/5] END model__colsample_bytree=0.2, model__gamma=0.3333333333333333, model__learning_rate=1.0, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.220) r2: (test=0.828) total time= 9.0min\n",
      "[CV 3/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.3333333333333333, model__learning_rate=0.0001623776739188721, model__max_depth=7, model__min_child_weight=3.0, model__n_estimators=500, model__subsample=1.0; neg_mean_absolute_error: (test=-0.569) r2: (test=0.117) total time= 9.1min\n",
      "[CV 2/5] END model__colsample_bytree=0.1, model__gamma=0.1111111111111111, model__learning_rate=0.0011288378916846883, model__max_depth=None, model__min_child_weight=9.0, model__n_estimators=500, model__subsample=0.5; neg_mean_absolute_error: (test=-0.421) r2: (test=0.389) total time= 9.1min\n",
      "[CV 4/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.3333333333333333, model__learning_rate=0.0001623776739188721, model__max_depth=7, model__min_child_weight=3.0, model__n_estimators=500, model__subsample=1.0; neg_mean_absolute_error: (test=-0.523) r2: (test=0.114) total time= 9.2min\n",
      "[CV 5/5] END model__colsample_bytree=0.1, model__gamma=0.0, model__learning_rate=0.00026366508987303583, model__max_depth=8, model__min_child_weight=2.0, model__n_estimators=500, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.503) r2: (test=0.148) total time= 9.3min\n",
      "[CV 4/5] END model__colsample_bytree=0.1, model__gamma=0.1111111111111111, model__learning_rate=0.0011288378916846883, model__max_depth=None, model__min_child_weight=9.0, model__n_estimators=500, model__subsample=0.5; neg_mean_absolute_error: (test=-0.430) r2: (test=0.373) total time= 9.1min\n",
      "[CV 2/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.3333333333333333, model__learning_rate=0.0001623776739188721, model__max_depth=7, model__min_child_weight=3.0, model__n_estimators=500, model__subsample=1.0; neg_mean_absolute_error: (test=-0.514) r2: (test=0.110) total time= 9.2min\n",
      "[CV 1/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.3333333333333333, model__learning_rate=0.0001623776739188721, model__max_depth=7, model__min_child_weight=3.0, model__n_estimators=500, model__subsample=1.0; neg_mean_absolute_error: (test=-0.523) r2: (test=0.115) total time= 9.2min\n",
      "[CV 1/5] END model__colsample_bytree=0.2, model__gamma=0.3333333333333333, model__learning_rate=1.0, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.211) r2: (test=0.836) total time= 9.1min\n",
      "[CV 4/5] END model__colsample_bytree=0.6, model__gamma=0.2222222222222222, model__learning_rate=0.0001623776739188721, model__max_depth=3, model__min_child_weight=3.0, model__n_estimators=300, model__subsample=1.0; neg_mean_absolute_error: (test=-0.543) r2: (test=0.049) total time= 9.1min\n",
      "[CV 3/5] END model__colsample_bytree=0.1, model__gamma=0.1111111111111111, model__learning_rate=0.0011288378916846883, model__max_depth=None, model__min_child_weight=9.0, model__n_estimators=500, model__subsample=0.5; neg_mean_absolute_error: (test=-0.463) r2: (test=0.390) total time= 9.2min\n",
      "[CV 3/5] END model__colsample_bytree=0.1, model__gamma=0.0, model__learning_rate=0.00026366508987303583, model__max_depth=8, model__min_child_weight=2.0, model__n_estimators=500, model__subsample=0.6666666666666666; neg_mean_absolute_error: (test=-0.557) r2: (test=0.152) total time= 9.4min\n",
      "[CV 1/5] END model__colsample_bytree=0.9, model__gamma=0.2222222222222222, model__learning_rate=0.615848211066026, model__max_depth=8, model__min_child_weight=5.0, model__n_estimators=300, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.181) r2: (test=0.866) total time= 9.0min\n",
      "[CV 4/5] END model__colsample_bytree=0.6, model__gamma=0.4444444444444444, model__learning_rate=0.0001623776739188721, model__max_depth=3, model__min_child_weight=3.0, model__n_estimators=400, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.538) r2: (test=0.065) total time= 9.0min\n",
      "[CV 3/5] END model__colsample_bytree=0.6, model__gamma=0.4444444444444444, model__learning_rate=0.0001623776739188721, model__max_depth=3, model__min_child_weight=3.0, model__n_estimators=400, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.584) r2: (test=0.069) total time= 9.1min\n",
      "[CV 5/5] END model__colsample_bytree=0.6, model__gamma=0.2222222222222222, model__learning_rate=0.0001623776739188721, model__max_depth=3, model__min_child_weight=3.0, model__n_estimators=300, model__subsample=1.0; neg_mean_absolute_error: (test=-0.533) r2: (test=0.050) total time= 9.2min\n",
      "[CV 5/5] END model__colsample_bytree=0.2, model__gamma=0.3333333333333333, model__learning_rate=1.0, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.200) r2: (test=0.845) total time= 9.2min\n",
      "[CV 3/5] END model__colsample_bytree=0.2, model__gamma=0.3333333333333333, model__learning_rate=1.0, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=700, model__subsample=0.5; neg_mean_absolute_error: (test=-0.211) r2: (test=0.864) total time= 9.2min\n",
      "[CV 1/5] END model__colsample_bytree=0.6, model__gamma=0.4444444444444444, model__learning_rate=0.0001623776739188721, model__max_depth=3, model__min_child_weight=3.0, model__n_estimators=400, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.537) r2: (test=0.071) total time= 9.2min\n",
      "[CV 2/5] END model__colsample_bytree=0.9, model__gamma=0.2222222222222222, model__learning_rate=0.615848211066026, model__max_depth=8, model__min_child_weight=5.0, model__n_estimators=300, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.158) r2: (test=0.891) total time= 9.1min\n",
      "[CV 3/5] END model__colsample_bytree=0.6, model__gamma=0.2222222222222222, model__learning_rate=0.0001623776739188721, model__max_depth=3, model__min_child_weight=3.0, model__n_estimators=300, model__subsample=1.0; neg_mean_absolute_error: (test=-0.590) r2: (test=0.053) total time= 9.1min\n",
      "[CV 5/5] END model__colsample_bytree=0.6, model__gamma=0.4444444444444444, model__learning_rate=0.0001623776739188721, model__max_depth=3, model__min_child_weight=3.0, model__n_estimators=400, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.527) r2: (test=0.066) total time=11.3min\n",
      "[CV 5/5] END model__colsample_bytree=0.30000000000000004, model__gamma=0.3333333333333333, model__learning_rate=0.0001623776739188721, model__max_depth=7, model__min_child_weight=3.0, model__n_estimators=500, model__subsample=1.0; neg_mean_absolute_error: (test=-0.513) r2: (test=0.117) total time=11.6min\n",
      "[CV 2/5] END model__colsample_bytree=0.6, model__gamma=0.4444444444444444, model__learning_rate=0.0001623776739188721, model__max_depth=3, model__min_child_weight=3.0, model__n_estimators=400, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.526) r2: (test=0.066) total time=12.0min\n",
      "[CV 3/5] END model__colsample_bytree=0.9, model__gamma=0.2222222222222222, model__learning_rate=0.615848211066026, model__max_depth=8, model__min_child_weight=5.0, model__n_estimators=300, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.174) r2: (test=0.908) total time=13.3min\n",
      "[CV 4/5] END model__colsample_bytree=0.9, model__gamma=0.2222222222222222, model__learning_rate=0.615848211066026, model__max_depth=8, model__min_child_weight=5.0, model__n_estimators=300, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.170) r2: (test=0.865) total time=12.7min\n",
      "[CV 5/5] END model__colsample_bytree=0.8, model__gamma=0.6666666666666666, model__learning_rate=0.14384498882876628, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=400, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.176) r2: (test=0.884) total time= 5.2min\n",
      "[CV 5/5] END model__colsample_bytree=0.9, model__gamma=0.2222222222222222, model__learning_rate=0.615848211066026, model__max_depth=8, model__min_child_weight=5.0, model__n_estimators=300, model__subsample=0.9444444444444444; neg_mean_absolute_error: (test=-0.168) r2: (test=0.893) total time= 6.3min\n",
      "[CV 2/5] END model__colsample_bytree=0.8, model__gamma=0.6666666666666666, model__learning_rate=0.14384498882876628, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=400, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.160) r2: (test=0.894) total time= 7.7min\n",
      "[CV 1/5] END model__colsample_bytree=0.8, model__gamma=0.6666666666666666, model__learning_rate=0.14384498882876628, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=400, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.175) r2: (test=0.869) total time= 9.5min\n",
      "[CV 4/5] END model__colsample_bytree=0.8, model__gamma=0.6666666666666666, model__learning_rate=0.14384498882876628, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=400, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.181) r2: (test=0.863) total time= 5.5min\n",
      "[CV 2/5] END model__colsample_bytree=1.0, model__gamma=0.2222222222222222, model__learning_rate=0.23357214690901212, model__max_depth=7, model__min_child_weight=10.0, model__n_estimators=500, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.167) r2: (test=0.872) total time= 4.9min\n",
      "[CV 3/5] END model__colsample_bytree=0.8, model__gamma=0.6666666666666666, model__learning_rate=0.14384498882876628, model__max_depth=10, model__min_child_weight=6.0, model__n_estimators=400, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.185) r2: (test=0.890) total time= 6.4min\n",
      "[CV 3/5] END model__colsample_bytree=0.8, model__gamma=0.1111111111111111, model__learning_rate=0.14384498882876628, model__max_depth=10, model__min_child_weight=2.0, model__n_estimators=700, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.170) r2: (test=0.903) total time= 5.1min\n",
      "[CV 5/5] END model__colsample_bytree=0.8, model__gamma=0.1111111111111111, model__learning_rate=0.14384498882876628, model__max_depth=10, model__min_child_weight=2.0, model__n_estimators=700, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.170) r2: (test=0.890) total time= 5.1min\n",
      "[CV 1/5] END model__colsample_bytree=0.8, model__gamma=0.1111111111111111, model__learning_rate=0.14384498882876628, model__max_depth=10, model__min_child_weight=2.0, model__n_estimators=700, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.164) r2: (test=0.881) total time= 5.2min\n",
      "[CV 1/5] END model__colsample_bytree=0.8, model__gamma=0.2222222222222222, model__learning_rate=0.007847599703514606, model__max_depth=8, model__min_child_weight=8.0, model__n_estimators=700, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.169) r2: (test=0.875) total time= 5.1min\n",
      "[CV 4/5] END model__colsample_bytree=0.8, model__gamma=0.1111111111111111, model__learning_rate=0.14384498882876628, model__max_depth=10, model__min_child_weight=2.0, model__n_estimators=700, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.160) r2: (test=0.885) total time= 5.2min\n",
      "[CV 2/5] END model__colsample_bytree=0.6, model__gamma=0.2222222222222222, model__learning_rate=0.14384498882876628, model__max_depth=5, model__min_child_weight=7.0, model__n_estimators=500, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.146) r2: (test=0.904) total time= 5.0min\n",
      "[CV 2/5] END model__colsample_bytree=0.8, model__gamma=0.1111111111111111, model__learning_rate=0.14384498882876628, model__max_depth=10, model__min_child_weight=2.0, model__n_estimators=700, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.152) r2: (test=0.894) total time= 5.3min\n",
      "[CV 5/5] END model__colsample_bytree=0.6, model__gamma=0.2222222222222222, model__learning_rate=0.14384498882876628, model__max_depth=5, model__min_child_weight=7.0, model__n_estimators=500, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.161) r2: (test=0.898) total time= 5.1min\n",
      "[CV 2/5] END model__colsample_bytree=0.8, model__gamma=0.2222222222222222, model__learning_rate=0.007847599703514606, model__max_depth=8, model__min_child_weight=8.0, model__n_estimators=700, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.152) r2: (test=0.898) total time= 5.1min\n",
      "[CV 4/5] END model__colsample_bytree=0.6, model__gamma=0.2222222222222222, model__learning_rate=0.14384498882876628, model__max_depth=5, model__min_child_weight=7.0, model__n_estimators=500, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.166) r2: (test=0.874) total time= 5.1min\n",
      "[CV 5/5] END model__colsample_bytree=1.0, model__gamma=0.2222222222222222, model__learning_rate=0.23357214690901212, model__max_depth=7, model__min_child_weight=10.0, model__n_estimators=500, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.170) r2: (test=0.888) total time= 5.0min\n",
      "[CV 5/5] END model__colsample_bytree=0.8, model__gamma=0.2222222222222222, model__learning_rate=0.007847599703514606, model__max_depth=8, model__min_child_weight=8.0, model__n_estimators=700, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.167) r2: (test=0.893) total time= 5.1min\n",
      "[CV 4/5] END model__colsample_bytree=1.0, model__gamma=0.2222222222222222, model__learning_rate=0.23357214690901212, model__max_depth=7, model__min_child_weight=10.0, model__n_estimators=500, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.166) r2: (test=0.879) total time= 5.1min\n",
      "[CV 3/5] END model__colsample_bytree=0.8, model__gamma=0.2222222222222222, model__learning_rate=0.007847599703514606, model__max_depth=8, model__min_child_weight=8.0, model__n_estimators=700, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.171) r2: (test=0.905) total time= 5.2min\n",
      "[CV 1/5] END model__colsample_bytree=1.0, model__gamma=0.2222222222222222, model__learning_rate=0.23357214690901212, model__max_depth=7, model__min_child_weight=10.0, model__n_estimators=500, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.167) r2: (test=0.876) total time= 5.1min\n",
      "[CV 3/5] END model__colsample_bytree=0.6, model__gamma=0.2222222222222222, model__learning_rate=0.14384498882876628, model__max_depth=5, model__min_child_weight=7.0, model__n_estimators=500, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.175) r2: (test=0.905) total time= 5.1min\n",
      "[CV 4/5] END model__colsample_bytree=0.8, model__gamma=0.2222222222222222, model__learning_rate=0.007847599703514606, model__max_depth=8, model__min_child_weight=8.0, model__n_estimators=700, model__subsample=0.7777777777777778; neg_mean_absolute_error: (test=-0.169) r2: (test=0.873) total time= 5.2min\n",
      "[CV 3/5] END model__colsample_bytree=1.0, model__gamma=0.2222222222222222, model__learning_rate=0.23357214690901212, model__max_depth=7, model__min_child_weight=10.0, model__n_estimators=500, model__subsample=0.6111111111111112; neg_mean_absolute_error: (test=-0.157) r2: (test=0.919) total time= 5.1min\n",
      "[CV 2/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.5555555555555556, model__learning_rate=0.004832930238571752, model__max_depth=6, model__min_child_weight=5.0, model__n_estimators=1000, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.160) r2: (test=0.895) total time= 5.0min\n",
      "[CV 4/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.5555555555555556, model__learning_rate=0.004832930238571752, model__max_depth=6, model__min_child_weight=5.0, model__n_estimators=1000, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.185) r2: (test=0.859) total time= 5.0min\n",
      "[CV 5/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.5555555555555556, model__learning_rate=0.004832930238571752, model__max_depth=6, model__min_child_weight=5.0, model__n_estimators=1000, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.178) r2: (test=0.882) total time= 5.0min\n",
      "[CV 3/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.5555555555555556, model__learning_rate=0.004832930238571752, model__max_depth=6, model__min_child_weight=5.0, model__n_estimators=1000, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.184) r2: (test=0.894) total time= 5.0min\n",
      "[CV 1/5] END model__colsample_bytree=0.6, model__gamma=0.2222222222222222, model__learning_rate=0.14384498882876628, model__max_depth=5, model__min_child_weight=7.0, model__n_estimators=500, model__subsample=0.8888888888888888; neg_mean_absolute_error: (test=-0.160) r2: (test=0.885) total time= 5.1min\n",
      "[CV 1/5] END model__colsample_bytree=0.7000000000000001, model__gamma=0.5555555555555556, model__learning_rate=0.004832930238571752, model__max_depth=6, model__min_child_weight=5.0, model__n_estimators=1000, model__subsample=0.7222222222222222; neg_mean_absolute_error: (test=-0.181) r2: (test=0.865) total time= 5.1min\n",
      "Fitting took 5423.701s.\n",
      "Best parameters found:\n",
      "model__subsample: 0.7222222222222222\n",
      "model__n_estimators: 700\n",
      "model__min_child_weight: 10.0\n",
      "model__max_depth: 4\n",
      "model__learning_rate: 0.03359818286283781\n",
      "model__gamma: 0.1111111111111111\n",
      "model__colsample_bytree: 0.5\n"
     ]
    }
   ],
   "source": [
    "seed = 4815162342 // 2\n",
    "np.random.seed(seed)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_data, test_size=0.4, random_state=seed)\n",
    "\n",
    "f_select_model = RandomForestRegressor(n_estimators=1000, n_jobs=64, random_state=1234)\n",
    "\n",
    "pipe_random = Pipeline(steps=[\n",
    "    ('preprocess', VarianceThreshold(1e-3)),\n",
    "    ('feature_selection', SelectFromModel(f_select_model, max_features=30)),\n",
    "    ('model', XGBRegressor(n_estimators=500, learning_rate=0.01))\n",
    "])\n",
    "\n",
    "param_dict = {\n",
    "    'model__learning_rate': np.logspace(-4, 0, 20),\n",
    "    'model__subsample': np.linspace(0.5, 1.0, 10),\n",
    "    'model__colsample_bytree': np.linspace(0.1, 1.0, 10),\n",
    "    'model__max_depth': [3, 4, 5, 6, 7, 8, 9, 10, None],\n",
    "    'model__min_child_weight': np.linspace(1, 10, 10),\n",
    "    'model__gamma': np.linspace(0, 1, 10),\n",
    "    'model__n_estimators': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(pipe_random, cv=5, param_distributions=param_dict,\n",
    "                            n_iter=100, n_jobs=64, verbose=3, refit='neg_mean_absolute_error',\n",
    "                            scoring=['neg_mean_absolute_error', 'r2'])\n",
    "\n",
    "t0 = time()\n",
    "print(\"Fitting started...\")\n",
    "search = search.fit(X_train, Y_train)\n",
    "print(f\"Fitting took {time() - t0:0.3f}s.\")\n",
    "\n",
    "best_model = search.best_estimator_\n",
    "\n",
    "print(\"Best parameters found:\")\n",
    "for param, value in search.best_params_.items():\n",
    "    print(f\"{param}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.93433, train MAE: 0.12510\n",
      "Test R^2: 0.90488, test MAE: 0.15197\n"
     ]
    }
   ],
   "source": [
    "Y_pred_train = best_model.predict(X_train)\n",
    "Y_pred_test = best_model.predict(X_test)\n",
    "\n",
    "train_r2 = r2_score(Y_train, Y_pred_train)\n",
    "train_mae = mean_absolute_error(Y_train, Y_pred_train)\n",
    "test_r2 = r2_score(Y_test, Y_pred_test)\n",
    "test_mae = mean_absolute_error(Y_test, Y_pred_test)\n",
    "\n",
    "print(f\"Train R^2: {train_r2:.5f}, train MAE: {train_mae:.5f}\")\n",
    "print(f\"Test R^2: {test_r2:.5f}, test MAE: {test_mae:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction for reaction 1_i_1_D: 1.1150\n"
     ]
    }
   ],
   "source": [
    "def predict_ddg(catalyst_id, imine_id, thiol_id, product_id):\n",
    "    if all(id in embeddings for id in [catalyst_id, imine_id, thiol_id, product_id]):\n",
    "        combined_embedding = np.concatenate([\n",
    "            embeddings[catalyst_id],\n",
    "            embeddings[imine_id],\n",
    "            embeddings[thiol_id],\n",
    "            embeddings[product_id]\n",
    "        ])\n",
    "        return best_model.predict([combined_embedding])[0]\n",
    "    else:\n",
    "        return \"One or more components not found in embeddings\"\n",
    "\n",
    "# Example usage\n",
    "example_row = Y_df.iloc[3]\n",
    "print(f\"Prediction for reaction {example_row['reaction_handle']}: \"\n",
    "      f\"{predict_ddg(example_row['catalyst_id'], example_row['imine_id'], example_row['thiol_id'], example_row['product_id']):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting results...\n",
      "EQUICAT Prediction\n",
      "Train R^2: 0.93433, train MAE: 0.12510\n",
      "Test R^2: 0.90488, test MAE: 0.15197\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_and_print(estimator, X_train, Y_train, X_test, Y_test, title, verbose=1, file_dpi=800):\n",
    "    predicted_train = estimator.predict(X_train)\n",
    "    r2_train = r2_score(Y_train, predicted_train)\n",
    "    mae_train = mean_absolute_error(Y_train, predicted_train)\n",
    "\n",
    "    predicted_test = estimator.predict(X_test)\n",
    "    r2_test = r2_score(Y_test, predicted_test)\n",
    "    mae_test = mean_absolute_error(Y_test, predicted_test)\n",
    "\n",
    "    if verbose:\n",
    "        print(title)\n",
    "        print(f\"Train R^2: {r2_train:0.5f}, train MAE: {mae_train:0.5f}\")\n",
    "        print(f\"Test R^2: {r2_test:0.5f}, test MAE: {mae_test:0.5f}\")\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    train_plot = ax.scatter(\n",
    "        Y_train,\n",
    "        predicted_train,\n",
    "        color=\"gray\",\n",
    "        label=f\"Train (r2={r2_train:0.3f}, MAE={mae_train:0.3f})\"\n",
    "    )\n",
    "\n",
    "    test_plot = ax.scatter(\n",
    "        Y_test,\n",
    "        predicted_test,\n",
    "        color=\"blue\",\n",
    "        label=f\"Test (r2={r2_test:0.3f}, MAE={mae_test:0.3f})\"\n",
    "    )\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Observed \")\n",
    "    ax.set_ylabel(\"Predicted \")\n",
    "    ax.set_ylim(-3, 3)\n",
    "    ax.set_xlim(-3, 3)\n",
    "        \n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(title + \".png\", dpi=file_dpi)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "# Plot and print results\n",
    "print(\"Plotting results...\")\n",
    "plot_and_print(best_model, X_train, Y_train, X_test, Y_test, \"EQUICAT Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
